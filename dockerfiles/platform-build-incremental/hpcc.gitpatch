diff --git a/.github/workflows/build-and-publish.yml b/.github/workflows/build-and-publish.yml
index 09dc4aeb7..1bcf26831 100644
--- a/.github/workflows/build-and-publish.yml
+++ b/.github/workflows/build-and-publish.yml
@@ -25,7 +25,7 @@ jobs:
         with:
           username: ${{ secrets.DOCKER_USERNAME }}
           password: ${{ secrets.DOCKER_PASSWORD }}
-          latest: 1   # this should only be set on the current minor branch
+          latest: 0   # this should only be set on the current minor branch
 
   ml-builds:
     needs: build
@@ -42,6 +42,6 @@ jobs:
       with:
         username: ${{ secrets.DOCKER_USERNAME }}
         password: ${{ secrets.DOCKER_PASSWORD }}
-        latest: 1   # this should only be set on the current minor branch
+        latest: 0   # this should only be set on the current minor branch
         build_ml: ${{ matrix.engine }}
 
diff --git a/CMakeLists.txt b/CMakeLists.txt
index 87ef10833..539e5a282 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -69,6 +69,7 @@
 
 project(hpccsystems-platform)
 
+# test comment
 # Stupid workaround. See https://gitlab.kitware.com/cmake/cmake/-/issues/21378
 # If cmake runs twice, cmake might not correctly set the compiler version variables
 unset ( ENV{CC} )
@@ -88,7 +89,7 @@ set(HPCC_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR})
 set(CMAKE_MODULE_PATH "${HPCC_SOURCE_DIR}/cmake_modules/")
 
 include(${HPCC_SOURCE_DIR}/version.cmake)
-
+#Test Message
 ###
 ## Build Level
 ###
diff --git a/common/thorhelper/CMakeLists.txt b/common/thorhelper/CMakeLists.txt
index 2b655f200..b01ce2ecb 100644
--- a/common/thorhelper/CMakeLists.txt
+++ b/common/thorhelper/CMakeLists.txt
@@ -31,6 +31,7 @@ set (    SRCS
          csvsplitter.cpp 
          thorcommon.cpp 
          thorfile.cpp 
+         thormeta.cpp
          thorparse.cpp 
          thorpipe.cpp 
          thorread.cpp
@@ -53,6 +54,7 @@ set (    SRCS
          csvsplitter.hpp 
          thorcommon.hpp 
          thorfile.hpp 
+         thormeta.hpp
          thorparse.hpp 
          thorpipe.hpp 
          thorread.hpp
@@ -70,6 +72,8 @@ set (    SRCS
          thorsort.hpp
          persistent.cpp
          persistent.hpp
+         thorstore.cpp
+         thorstore.hpp
          
          roxiedebug.hpp
          roxiedebug.ipp
diff --git a/common/thorhelper/roxiehelper.cpp b/common/thorhelper/roxiehelper.cpp
index bee55f200..dfabfae49 100644
--- a/common/thorhelper/roxiehelper.cpp
+++ b/common/thorhelper/roxiehelper.cpp
@@ -2669,12 +2669,16 @@ StringBuffer & mangleHelperFileName(StringBuffer & out, const char * in, const c
 {
     out = in;
     if (flags & (TDXtemporary | TDXjobtemp))
-        out.append("__").append(wuid);
+        out.append("__").appendLower(wuid);
     return out;
 }
 
-StringBuffer & mangleLocalTempFilename(StringBuffer & out, char const * in)
+
+//Replace any occurrences of :: in the logical name with __scope__, and optionally append with the wuid
+StringBuffer & mangleLocalTempFilename(StringBuffer & out, char const * in, const char * wuid)
 {
+    if (*in == '~')
+        in++;
     char const * start = in;
     while(true)
     {
@@ -2690,6 +2694,8 @@ StringBuffer & mangleLocalTempFilename(StringBuffer & out, char const * in)
             break;
         }
     }
+    if (wuid)
+        out.append("__").appendLower(wuid);
     return out;
 }
 
@@ -2735,6 +2741,10 @@ StringBuffer & expandLogicalFilename(StringBuffer & logicalName, const char * fn
         sb.replaceString("::",PATHSEPSTR);
         makeAbsolutePath(sb.str(), logicalName.clear());
     }
+    else if (strchr(fname, PATHSEPCHAR))
+    {
+        logicalName.append(fname);
+    }
     else
     {
         SCMStringBuffer lfn;
diff --git a/common/thorhelper/roxiehelper.hpp b/common/thorhelper/roxiehelper.hpp
index 6c7cc9190..336ecc7b0 100644
--- a/common/thorhelper/roxiehelper.hpp
+++ b/common/thorhelper/roxiehelper.hpp
@@ -564,7 +564,7 @@ private:
 //==============================================================================================================
 
 THORHELPER_API StringBuffer & mangleHelperFileName(StringBuffer & out, const char * in, const char * wuid, unsigned int flags);
-THORHELPER_API StringBuffer & mangleLocalTempFilename(StringBuffer & out, char const * in);
+THORHELPER_API StringBuffer & mangleLocalTempFilename(StringBuffer & out, char const * in, const char * optWuid);
 THORHELPER_API StringBuffer & expandLogicalFilename(StringBuffer & logicalName, const char * fname, IConstWorkUnit * wu, bool resolveLocally, bool ignoreForeignPrefix);
 
 THORHELPER_API ISectionTimer * queryNullSectionTimer();
diff --git a/common/thorhelper/thorcommon.cpp b/common/thorhelper/thorcommon.cpp
index 09292ee22..62927b960 100644
--- a/common/thorhelper/thorcommon.cpp
+++ b/common/thorhelper/thorcommon.cpp
@@ -2023,14 +2023,28 @@ static IOutputMetaData *_getDaliLayoutInfo(MemoryBuffer &layoutBin, IPropertyTre
                 error.setown(E); // Save to throw later if we can't recover via ECL
             }
         }
-        if (props.hasProp("ECL"))
+        if (props.hasProp("meta"))
+        {
+            props.getPropBin("meta", layoutBin);
+            try
+            {
+                return createTypeInfoOutputMetaData(layoutBin, isGrouped);
+            }
+            catch (IException *E)
+            {
+                EXCLOG(E);
+                error.setown(E); // Save to throw later if we can't recover via ECL
+            }
+        }
+        const char * layoutECL = props.queryProp("ECL");
+        if (!layoutECL)
+            layoutECL = props.queryProp("@ecl");
+        if (layoutECL)
         {
             const char *kind = props.queryProp("@kind");
             bool isIndex = (kind && streq(kind, "key"));
-            StringBuffer layoutECL;
-            props.getProp("ECL", layoutECL);
             MultiErrorReceiver errs;
-            Owned<IHqlExpression> expr = parseQuery(layoutECL.str(), &errs);
+            Owned<IHqlExpression> expr = parseQuery(layoutECL, &errs);
             if (expr && (errs.errCount() == 0))
             {
                 if (props.hasProp("_record_layout"))  // Some old indexes need the payload count patched in from here
diff --git a/common/thorhelper/thormeta.cpp b/common/thorhelper/thormeta.cpp
new file mode 100644
index 000000000..42c13c5a1
--- /dev/null
+++ b/common/thorhelper/thormeta.cpp
@@ -0,0 +1,531 @@
+/*##############################################################################
+
+    HPCC SYSTEMS software Copyright (C) 2020 HPCC SystemsÂ®.
+
+    Licensed under the Apache License, Version 2.0 (the "License");
+    you may not use this file except in compliance with the License.
+    You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
+############################################################################## */
+
+#include "jliball.hpp"
+#include "jsocket.hpp"
+#include "thorfile.hpp"
+
+#include "eclhelper.hpp"
+#include "eclrtl.hpp"
+#include "eclrtl_imp.hpp"
+
+#include "dautils.hpp"
+#include "dadfs.hpp"
+#include "dameta.hpp"
+
+#include "thormeta.hpp"
+#include "rtlcommon.hpp"
+#include "thorcommon.hpp"
+
+//Should be common with agentctx.hpp
+#define WRN_SkipMissingOptIndex             5400
+#define WRN_SkipMissingOptFile              5401
+#define WRN_UseLayoutTranslation            5402
+#define WRN_UnsupportedAlgorithm            5403
+#define WRN_MismatchGroupInfo               5404
+#define WRN_MismatchCompressInfo            5405
+#define WRN_RemoteReadFailure               5406
+
+//Default format - if not specified in ecl and not known to dali etc.
+static constexpr const char * defaultFileFormat = "flat";
+
+IPropertyTree * resolveLogicalFilename(const char * filename, IUserDescriptor * user, ResolveOptions options)
+{
+    //This may go via esp instead at some point....
+    return resolveLogicalFilenameFromDali(filename, user, options);
+}
+
+//---------------------------------------------------------------------------------------------------------------------
+
+CLogicalFile::CLogicalFile(const CStorageSystems & storage, const IPropertyTree * _metaXml, IOutputMetaData * _expectedMeta)
+: metaTree(_metaXml), expectedMeta(_expectedMeta)
+{
+    name = metaTree->queryProp("@name");
+    numParts = metaTree->getPropInt("@numParts", 1);
+    fileSize = metaTree->getPropInt64("@rawSize"); // logical file size - used for file positions
+    mergedMeta.set(metaTree);
+
+    parts.reserve(numParts);
+    Owned<IPropertyTreeIterator> partIter = metaTree->getElements("part");
+    if (partIter->first())
+    {
+        offset_t baseOffset = 0;
+        do
+        {
+            offset_t partSize = partIter->query().getPropInt("@rawSize");
+            offset_t numRows = partIter->query().getPropInt("@numRows");
+            parts.emplace_back(parts.size(), numRows, partSize, baseOffset);
+            baseOffset += partSize;
+        } while (partIter->next());
+        assertex(parts.size() == numParts);
+
+        if (baseOffset)
+        {
+            assertex(fileSize == 0 || fileSize == baseOffset);
+            fileSize = baseOffset;
+        }
+    }
+    else
+    {
+        for (unsigned part=0; part < numParts; part++)
+            parts.emplace_back(part, 0, 0, 0);
+    }
+
+    Owned<IPropertyTreeIterator> planeIter = metaTree->getElements("planes");
+    ForEach(*planeIter)
+    {
+        const char * planeName = planeIter->query().queryProp(nullptr);
+        planes.append(storage.queryPlane(planeName));
+    }
+    if (planes.ordinality() == 0)
+    {
+        throwUnexpectedX("No plane associated with file");
+    }
+
+    actualCrc = metaTree->getPropInt("@metaCrc");
+}
+
+
+void CLogicalFile::applyHelperOptions(const IPropertyTree * helperOptions)
+{
+    if (!helperOptions || isEmptyPTree(helperOptions))
+    {
+        mergedMeta.set(metaTree);
+    }
+    else
+    {
+        //Use mergeConfiguration() instead of synchronizePTree because it merges attributes, combines single elements, appends lists
+        Owned<IPropertyTree> merged = createPTreeFromIPT(metaTree);
+        mergeConfiguration(*merged, *helperOptions, nullptr, true);
+        mergedMeta.setown(merged.getClear());
+    }
+}
+
+
+void CLogicalFile::noteLocation(unsigned part, unsigned superPartNum, offset_t baseOffset)
+{
+    auto & cur = parts[part];
+    cur.superPartNum = superPartNum;
+    cur.baseOffset = baseOffset;
+}
+
+const IPropertyTree * CLogicalFile::queryFileMeta() const
+{
+    return mergedMeta;
+}
+
+offset_t CLogicalFile::queryOffsetOfPart(unsigned part) const
+{
+    return queryPart(part).baseOffset;
+}
+
+offset_t CLogicalFile::getPartSize(unsigned part) const
+{
+    if (part < parts.size())
+        return parts[part].fileSize;
+    return (offset_t)-1;
+}
+
+bool CLogicalFile::isLocal(unsigned part, unsigned copy) const
+{
+    return queryPlane(copy)->isLocal(part);
+}
+
+bool CLogicalFile::onAttachedStorage(unsigned copy) const
+{
+    return queryPlane(copy)->isAttachedStorage();
+}
+
+
+//expand name as path, e.g. copy and translate :: into /
+StringBuffer & CLogicalFile::expandLogicalAsPhysical(StringBuffer & target, unsigned copy) const
+{
+    const char * const separator = queryScopeSeparator(copy);
+    const char * cur = name;
+    for (;;)
+    {
+        const char * colon = strstr(cur, "::");
+        if (!colon)
+            break;
+
+        //MORE: Process special characters?  Revisit commoning up these functions as HPCC-25337
+        target.append(colon - cur, cur);
+        target.append(separator);
+        cur = colon + 2;
+    }
+
+    return target.append(cur);
+}
+
+StringBuffer & CLogicalFile::expandPath(StringBuffer & target, unsigned part, unsigned copy) const
+{
+    const char * separator = queryScopeSeparator(copy);
+    if (isExternal())
+    {
+        //expandExternalPath always adds a separator character at the start
+        if (endsWith(target.str(), separator))
+            target.setLength(target.length()-strlen(separator));
+
+        //skip file::
+        const char * coloncolon = strstr(name, "::");
+        assertex(coloncolon);
+        //skip ip::
+        const char * next = coloncolon+2;
+        const char * s = strstr(next, "::");
+        assertex(s);
+        IException * e = nullptr;
+        //Slightly strangely expandExternalPath() expects s to point to the leading ::
+        expandExternalPath(target, target, name, s, false, &e);
+        if (e)
+            throw e;
+    }
+    else
+    {
+        if (!endsWith(target.str(), separator))
+            target.append(separator);
+        expandLogicalAsPhysical(target, copy);
+    }
+
+    //Add part number suffix
+    if (includePartSuffix())
+    {
+        target.append("._").append(part+1).append("_of_").append(numParts);
+    }
+
+    return target;
+}
+
+StringBuffer & CLogicalFile::getURL(StringBuffer & target, unsigned part, unsigned copy) const
+{
+    if (planes.ordinality())
+    {
+        planes.item(copy)->getURL(target, part);
+    }
+    return expandPath(target, part, copy);
+}
+
+
+IOutputMetaData * CLogicalFile::queryActualMeta() const
+{
+    if (!actualMeta)
+    {
+        actualMeta.setown(getDaliLayoutInfo(*metaTree));
+        if (!actualMeta)
+        {
+            //MORE: Old files (pre 7.0) do not have the serialized file format, some new files cannot create them
+            //we should possibly have a way of distinguishing between the two
+            actualMeta.set(expectedMeta);
+        }
+    }
+    return actualMeta;
+}
+
+const char * CLogicalFile::queryFormat() const
+{
+    return metaTree->queryProp("@format");
+}
+
+unsigned CLogicalFile::getNumCopies() const
+{
+    return planes.ordinality();
+}
+
+const char * CLogicalFile::queryScopeSeparator(unsigned copy) const
+{
+    return planes.item(copy)->queryScopeSeparator();
+}
+
+bool CLogicalFile::includePartSuffix() const
+{
+    return !metaTree->getPropBool("@singlePartNoSuffix");
+}
+
+StringBuffer & CLogicalFile::getTracingFilename(StringBuffer & out, unsigned part) const
+{
+    return out.append(name).append(":").append(part);
+}
+
+const char * CLogicalFile::queryLogicalFilename() const
+{
+    return name ? name : "";
+}
+
+
+//---------------------------------------------------------------------------------------------------------------------
+
+CLogicalFileSlice::CLogicalFileSlice(CLogicalFile * _file, unsigned _part, offset_t _startOffset, offset_t _length)
+: file(_file), part(_part), startOffset(_startOffset), length(_length)
+{
+}
+
+bool CLogicalFileSlice::isWholeFile() const
+{
+    if ((startOffset == 0) && file)
+    {
+        if ((length == unknownFileSize) || (length == file->getPartSize(part)))
+            return true;
+    }
+    return false;
+}
+
+StringBuffer & CLogicalFileSlice::getTracingFilename(StringBuffer & out) const
+{
+    file->getTracingFilename(out, part);
+    out.append('{').append(startOffset).append("..");
+    if (length != unknownFileSize)
+        out.append(startOffset + length);
+    return out.append('}');
+}
+
+//---------------------------------------------------------------------------------------------------------------------
+
+void CLogicalFileCollection::appendFile(CLogicalFile & file)
+{
+    files.append(file);
+    totalSize += file.getFileSize();
+    unsigned numParts = file.getNumParts();
+    if (numParts > maxParts)
+        maxParts = numParts;
+}
+
+
+void CLogicalFileCollection::calcLocations()
+{
+    //If there is only a single file, then the global part numbers and base offsets match the values within the file.
+    if (files.ordinality() == 1)
+        return;
+
+    //If there are multiple parts then they need to be calculated within the interleaved files in the superfile.
+    unsigned superPartNum = 0;
+    offset_t baseOffset = 0;
+    for (unsigned part=0; part < maxParts; part++)
+    {
+        ForEachItemIn(i, files)
+        {
+            CLogicalFile & cur = files.item(i);
+            unsigned numParts = cur.getNumParts();
+            if (numParts > part)
+            {
+                cur.noteLocation(part, superPartNum, baseOffset);
+                superPartNum++;
+                baseOffset += cur.getPartSize(part);
+            }
+        }
+    }
+    //We may need a function to map from super part numbers to a file/part - in which case we'll need to create a reverse
+    //mapping {fileIndex,part} if it needs to be done efficiently
+}
+
+/*
+Calculate which parts of which files will be included in this channel
+
+There is an implicit ordering of the file parts - file1, part1, file2, part1, file<n> part1, file1, part2 etc.
+
+if distribution and ordering are preservered:
+    files are processed in order, multiple parts can be processed on a single node as long as global ordering is retained.
+
+if ordering is preserved and distribution does not need to be:
+    files must be processed in order, parts can be processed on any node as long as global ordering is retained.
+    e.g. if number of reading nodes is > number of file parts, then part1s can be split between nodes1 and 2, part2 between nodes 3 and 4
+         or if multiple files, node1 can process file1 part1, node2 file2 part1, node3 file1 part2, node4 file1 part2
+
+if distribution is preserved, but ordering does not need to be:
+    on bare metal, it might be better to have part1,part<n+1> on node1, part2,part<n+2> on node2 since first parts more likely to be local
+
+if neither distribution or ordering are preserved
+    if non local storage, could try and ensure that workload is even across the nodes.  Could split parts between nodes (but beware
+    of making the read parts too small e.g. for blob read granularity)
+
+on bare metal, if channels is a multiple of the maximum number of parts it is likely to be worth reading the same as inorder
+*/
+
+void CLogicalFileCollection::calcPartition(SliceVector & slices, unsigned numChannels, unsigned channel, bool preserveDistribution, bool preserveOrder)
+{
+    calcLocations();
+
+    //MORE: Revisit and improve the following code to optimize cases detailed above, once they are likely to occur.
+    //Likely to require code generator/language improvements first
+    unsigned partsPerNode = (maxParts < numChannels) ? 1 : (maxParts + numChannels - 1) / numChannels;
+    unsigned startPart = channel * partsPerNode;
+    unsigned endPart = startPart + partsPerNode;
+    if (endPart > maxParts)
+        endPart = maxParts;
+
+    for (unsigned part=startPart; part < endPart; part++)
+    {
+        collectPartSlices(slices, part);
+    }
+}
+
+
+void CLogicalFileCollection::collectPartSlices(SliceVector & slices, unsigned part)
+{
+    unsigned numFiles = files.ordinality();
+    for (unsigned from = 0; from < numFiles; from++)
+    {
+        CLogicalFile & cur = files.item(from);
+        unsigned numParts = cur.getNumParts();
+        if (part < numParts)
+            slices.emplace_back(&cur, part, 0, unknownFileSize);
+    }
+}
+
+
+void CLogicalFileCollection::reset()
+{
+    totalSize = 0;
+    files.kill();
+    maxParts = 0;
+}
+
+void CLogicalFileCollection::init(IFileCollectionContext * _context, const char * _wuid,  bool _isTemporary, bool _resolveLocally, bool _isCodeSigned, IUserDescriptor * _user, IOutputMetaData * _expectedMeta)
+{
+    context = _context;
+    wuid.set(_wuid);
+    isTemporary = _isTemporary;
+    resolveLocally = _resolveLocally;
+    isCodeSigned = _isCodeSigned;
+    user = _user;
+    expectedMeta = _expectedMeta;
+}
+
+
+//The following function is call each time the activity is started - more than once if in a child query
+void CLogicalFileCollection::setEclFilename(const char * _filename, IPropertyTree * _helperOptions)
+{
+    assertex(!isTemporary);
+    //Check if the same parameters have been passed, and if so avoid rebuilding the information
+    if (strisame(filename, _filename))
+    {
+        if (areMatchingPTrees(helperOptions, _helperOptions))
+            return;
+
+        //The file list can stay the same, but the options will need to be recalculated.
+        helperOptions.set(_helperOptions);
+    }
+    else
+    {
+        reset();
+        filename.set(_filename);
+        helperOptions.set(_helperOptions);
+
+        processLogicalFilename();
+    }
+
+    applyHelperOptions();
+}
+
+void CLogicalFileCollection::processLogicalFilename()
+{
+    Owned<IPropertyTree> resolvedMeta;
+    if (resolveLocally)
+    {
+        resolvedMeta.setown(createPTree("meta"));
+        IPropertyTree * storage = resolvedMeta->addPropTree("storage");
+        IPropertyTree * plane = storage->addPropTree("planes");
+        plane->setProp("@prefix", ".");
+        plane->setProp("@name", "local");
+
+        IPropertyTree * file = resolvedMeta->addPropTree("file");
+        file->setProp("@name", filename);
+        file->setProp("@prefix", ".");
+        file->setPropBool("@singlePartNoSuffix", true);
+        file->addProp("planes", "local");
+    }
+    else
+    {
+        //MORE: These options could be restricted e.g., ROpartinfo/ROsizes only if a count operation, or if virtual(fileposition) used
+        ResolveOptions options = ROincludeLocation|ROpartinfo|ROsizes;
+        resolvedMeta.setown(resolveLogicalFilename(filename, user, options));
+    }
+    processResolvedMeta(resolvedMeta);
+}
+
+//Walk the information that was generated by resolving the filename and generate a set of file objects
+void CLogicalFileCollection::processResolvedMeta(IPropertyTree * _resolved)
+{
+    resolved.set(_resolved);
+    storageSystems.setFromMeta(resolved);
+
+    bool expectedGrouped = helperOptions->getPropBool("@grouped");
+    Owned<IPropertyTreeIterator> fileIter = resolved->getElements("file");
+    ForEach(*fileIter)
+    {
+        IPropertyTree & cur = fileIter->query();
+        if (cur.getPropBool("@missing"))
+        {
+            const char * filename = cur.queryProp("@name");
+            if (!helperOptions->getPropBool("@optional", false))
+            {
+                StringBuffer errorMsg("");
+                throw makeStringException(0, errorMsg.append(": Logical file name '").append(filename).append("' could not be resolved").str());
+            }
+            else
+            {
+                StringBuffer buff;
+                buff.appendf("Input file '%s' was missing but declared optional", filename);
+                context->noteException(SeverityInformation, WRN_SkipMissingOptFile, buff.str());
+            }
+        }
+        else
+        {
+            CLogicalFile * file = new CLogicalFile(storageSystems, &cur, expectedMeta);
+            appendFile(*file);
+
+            bool isGrouped = file->isGrouped();
+            if (isGrouped != expectedGrouped)
+            {
+                StringBuffer msg;
+                msg.append("DFS and code generated group info for file ").append(filename).append(" differs: DFS(").append(isGrouped ? "grouped" : "ungrouped").append("), CodeGen(").append(expectedGrouped ? "ungrouped" : "grouped").append("), using DFS info");
+                throw makeStringException(WRN_MismatchGroupInfo, msg.str());
+            }
+        }
+    }
+}
+
+void CLogicalFileCollection::setTempFilename(const char * _filename, IPropertyTree * _helperOptions, const IPropertyTree * spillPlane)
+{
+    assertex(isTemporary);
+    //Temp file parameters should never change if they are called again in a child query
+    if (filename)
+    {
+        if (!strisame(filename, _filename) || !areMatchingPTrees(helperOptions, _helperOptions))
+            throwUnexpected();
+        return;
+    }
+
+    filename.set(_filename);
+    helperOptions.setown(createPTreeFromIPT(_helperOptions));
+    helperOptions->setProp("@name", filename);
+    //Partinfo does not need to be supplied for temporary files.  Deos the number of parts?
+
+    IPropertyTree * plane = helperOptions->addPropTreeArrayItem("planes", createPTree("planes"));
+    plane->setProp("", spillPlane->queryProp("@name"));
+
+    storageSystems.registerPlane(spillPlane);
+
+    CLogicalFile * file = new CLogicalFile(storageSystems, helperOptions, expectedMeta);
+    appendFile(*file);
+    file->applyHelperOptions(nullptr);
+}
+
+
+void CLogicalFileCollection::applyHelperOptions()
+{
+    ForEachItemIn(i, files)
+        files.item(i).applyHelperOptions(helperOptions);
+}
diff --git a/common/thorhelper/thormeta.hpp b/common/thorhelper/thormeta.hpp
new file mode 100644
index 000000000..af120dbb8
--- /dev/null
+++ b/common/thorhelper/thormeta.hpp
@@ -0,0 +1,211 @@
+/*##############################################################################
+
+    HPCC SYSTEMS software Copyright (C) 2020 HPCC SystemsÂ®.
+
+    Licensed under the Apache License, Version 2.0 (the "License");
+    you may not use this file except in compliance with the License.
+    You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
+############################################################################## */
+
+#ifndef __THORMETA_HPP_
+#define __THORMETA_HPP_
+
+#ifdef THORHELPER_EXPORTS
+ #define THORHELPER_API DECL_EXPORT
+#else
+ #define THORHELPER_API DECL_IMPORT
+#endif
+
+#include "jrowstream.hpp"
+#include "rtlkey.hpp"
+#include <vector>
+#include "thorstore.hpp"
+
+
+interface IDistributedFile;
+
+//--------------------------------------------------------------------------------------------------------------------
+
+
+//This class represents a logical file part.
+//The superPartNum/baseOffset may not match the values for the file if this file is part of a superfile.
+class CLogicalFilePart
+{
+public:
+    CLogicalFilePart() = default;
+    CLogicalFilePart(unsigned _superPartNum, offset_t _numRows, offset_t _fileSize, offset_t _baseOffset)
+    : superPartNum(_superPartNum), numRows(_numRows), fileSize(_fileSize), baseOffset(_baseOffset)
+    {
+    }
+
+public://should be private
+    unsigned superPartNum;
+    offset_t numRows = 0;
+    offset_t fileSize = 0;
+    offset_t baseOffset = 0; // sum of previous file sizes
+//  Owned<CSplitPointTable> splits;   // This is where split points would be saved and accessed
+};
+
+class THORHELPER_API CLogicalFile : public CInterface
+{
+public:
+    CLogicalFile(const CStorageSystems & storage, const IPropertyTree * xml, IOutputMetaData * _expectedMeta);
+
+    StringBuffer & getURL(StringBuffer & target, unsigned part, unsigned copy) const;
+    offset_t getFileSize() const { return fileSize; }
+    unsigned getNumCopies() const;
+    unsigned getNumParts() const { return numParts; }
+    offset_t getPartSize(unsigned part) const;
+    bool isDistributed() const { return numParts > 1; }  // MORE: Only if originally a logical file...
+    bool isExternal() const { return metaTree->getPropBool("@external"); }
+    bool isGrouped() const { return metaTree->getPropBool("@grouped"); }
+    bool isLogicalFile() const { return name != nullptr; }
+    bool isLocal(unsigned part, unsigned copy) const;
+    bool isMissing() const { return metaTree->getPropBool("@missing"); }
+    bool onAttachedStorage(unsigned copy) const;
+    const CStoragePlane * queryPlane(unsigned idx) const { return planes.item(idx); }
+
+    unsigned queryActualCrc() const { return actualCrc; }
+    IOutputMetaData * queryActualMeta() const;
+    const char * queryFormat() const;
+    const IPropertyTree * queryFileMeta() const;
+    const char * queryLogicalFilename() const;
+    offset_t queryOffsetOfPart(unsigned part) const;
+    const CLogicalFilePart & queryPart(unsigned part) const
+    {
+        assertex(part < parts.size());
+        return parts[part];
+    }
+    StringBuffer & getTracingFilename(StringBuffer & out, unsigned part) const;
+
+    const char * queryPhysicalPath() const { UNIMPLEMENTED; }    // MORE!!!
+    bool includePartSuffix() const;
+
+    void applyHelperOptions(const IPropertyTree * helperOptions);
+    void noteLocation(unsigned part, unsigned superPartNum, offset_t baseOffset);
+
+protected:
+    StringBuffer & expandLogicalAsPhysical(StringBuffer & target, unsigned copy) const;
+    StringBuffer & expandPath(StringBuffer & target, unsigned part, unsigned copy) const;
+    const char * queryScopeSeparator(unsigned copy) const;
+
+private:
+    const IPropertyTree * metaTree = nullptr;
+    Owned<const IPropertyTree> mergedMeta;
+    IOutputMetaData * expectedMeta = nullptr;  // same as CLogicalFileCollection::expectedMeta
+    //All of the following are derived from the xml
+    const char * name = nullptr;
+    unsigned numParts = 0;
+    offset_t fileSize = 0;
+    std::vector<CLogicalFilePart> parts;
+    ConstPointerArrayOf<CStoragePlane> planes; // An array of locations the file is stored.  replicas are expanded out.
+    mutable Owned<IOutputMetaData> actualMeta;
+    mutable unsigned actualCrc = 0;
+};
+
+//This class is the unit that is passed to the disk reading classes to represent a section from a filepart.
+class THORHELPER_API CLogicalFileSlice
+{
+    friend class CLogicalFileCollection;
+public:
+    CLogicalFileSlice(CLogicalFile * _file, unsigned _part, offset_t _startOffset = 0, offset_t _length = unknownFileSize);
+
+    StringBuffer & getURL(StringBuffer & url, unsigned copy) const { return file->getURL(url, part, copy); }
+
+    unsigned getNumCopies() const { return file->getNumCopies(); }
+    bool isEmpty() const { return !file || length == 0; }
+    bool isLogicalFile() const { return file->isLogicalFile(); }
+    bool isRemoteReadCandidate(unsigned copy) const;
+    bool isWholeFile() const;
+    bool isLocal(unsigned copy) const { return file->isLocal(part, copy); }
+    bool onAttachedStorage(unsigned copy) const { return file->onAttachedStorage(copy); }
+
+    CLogicalFile * queryFile() const { return file; }
+    const char * queryFormat() const { return file->queryFormat(); }
+    const IPropertyTree * queryFileMeta() const { return file->queryFileMeta(); }
+    offset_t queryLength() const { return length; }
+    unsigned queryPartNumber() const { return file->queryPart(part).superPartNum; }
+    offset_t queryOffsetOfPart() const { return file->queryOffsetOfPart(part); }
+    offset_t queryStartOffset() const { return startOffset; }
+    const char * queryLogicalFilename() const { return file->queryLogicalFilename(); }
+    StringBuffer & getTracingFilename(StringBuffer & out) const;
+
+    void setAccessed() {}  // MORE:
+
+private:
+    CLogicalFileSlice() = default;
+
+private:
+    CLogicalFile * file = nullptr;
+    unsigned part = 0;
+    offset_t startOffset = 0;
+    offset_t length = unknownFileSize;
+    //MORE: What about HDFS records that are split over multiple files??
+};
+
+//MORE: Should this be a vector of owned pointers instead?
+using SliceVector = std::vector<CLogicalFileSlice>;
+
+class IFileCollectionContext
+{
+public:
+    virtual void noteException(unsigned severity, unsigned code, const char * text) = 0;
+};
+
+//The following class is always used to access a collection of files - even if it is only a single physical file.
+class CDfsLogicalFileName;
+class THORHELPER_API CLogicalFileCollection
+{
+public:
+    CLogicalFileCollection() = default;
+    CLogicalFileCollection(MemoryBuffer & in);
+
+    void init(IFileCollectionContext * _context, const char * _wuid,  bool _isTemporary,  bool _resolveLocally, bool _isCodeSigned, IUserDescriptor * _user, IOutputMetaData * _expectedMeta); // called once
+    void calcPartition(SliceVector & slices, unsigned numChannels, unsigned channel, bool preserveDistribution, bool preserveOrder);
+    void serialize(MemoryBuffer & out) const;
+    void setEclFilename(const char * filename, IPropertyTree * helperOptions);
+    void setTempFilename(const char * filename, IPropertyTree * helperOptions, const IPropertyTree * spillPlane);
+
+protected:
+    void appendFile(CLogicalFile & file);
+    void applyHelperOptions();
+    void calcLocations();
+    void collectPartSlices(SliceVector & slices, unsigned part);
+    void processFile(IDistributedFile * file, IOutputMetaData * expectedMeta, IPropertyTree * inputOptions, IPropertyTree * formatOptions);
+    void processFilename(CDfsLogicalFileName & logicalFilename, IUserDescriptor *user, bool isTemporary, IOutputMetaData * expectedMeta, IPropertyTree * inputOptions, IPropertyTree * formatOptions);
+    void processMissing(const char * filename, IPropertyTree * inputOptions);
+    void processPhysicalFilename(const char * path, IOutputMetaData * expectedMeta, IPropertyTree * inputOptions, IPropertyTree * formatOptions);
+    void processProtocolFilename(const char * name, const char * colon, const char * slash, IOutputMetaData * expectedMeta, IPropertyTree * inputOptions, IPropertyTree * formatOptions);
+    void processLogicalFilename();
+    void processResolvedMeta(IPropertyTree * _resolved);
+    void reset();
+
+private:
+    //Options that are constant for the lifetime of the class - not linked because they are owned by something else.
+    StringAttr wuid;
+    IFileCollectionContext * context = nullptr;
+    IUserDescriptor * user = nullptr;
+    IOutputMetaData * expectedMeta = nullptr;
+    bool isTemporary = false;
+    bool isCodeSigned = false;
+    bool resolveLocally = false;
+    //The following may be reset e.g. if used within a child query
+    StringAttr filename;
+    Owned<IPropertyTree> helperOptions;    // defined by the helper functions
+    //derived information
+    Owned<IPropertyTree> resolved;
+    CStorageSystems storageSystems;
+    CIArrayOf<CLogicalFile> files;
+    offset_t totalSize = 0;
+    unsigned maxParts = 0;
+};
+
+#endif
diff --git a/common/thorhelper/thormeta.txt b/common/thorhelper/thormeta.txt
new file mode 100644
index 000000000..c0c0a3a3c
--- /dev/null
+++ b/common/thorhelper/thormeta.txt
@@ -0,0 +1,8 @@
+Questions arising out of walking through the sketched out implementation:
+
+How do split points fit in?   They can be used when distribution does not need to be preserved.
+When are locations resolved?  Likely to be late on the agent nodes which allows better fallback, and potentially hot swapping to a backup copy.
+What information is signed?  The entire blob of xml that comes back from the esp service is signed.
+How do we reuse buffering classes cleanly?
+
+Implementing FETCH and partition reading required basic interface to request reading for a range of the file.  Fits in well with the range support of S3/azure
diff --git a/common/thorhelper/thorread.cpp b/common/thorhelper/thorread.cpp
index d9dfa1c0b..ae823477f 100644
--- a/common/thorhelper/thorread.cpp
+++ b/common/thorhelper/thorread.cpp
@@ -34,6 +34,7 @@
 #include "rtlcommon.hpp"
 #include "thorcommon.hpp"
 #include "csvsplitter.hpp"
+#include "thormeta.hpp"
 
 //---------------------------------------------------------------------------------------------------------------------
 
@@ -44,8 +45,8 @@
 class DiskReadMapping : public CInterfaceOf<IDiskReadMapping>
 {
 public:
-    DiskReadMapping(RecordTranslationMode _mode, const char * _format, unsigned _actualCrc, IOutputMetaData & _actual, unsigned _expectedCrc, IOutputMetaData & _expected, unsigned _projectedCrc, IOutputMetaData & _output, const IPropertyTree * _options)
-    : mode(_mode), format(_format), actualCrc(_actualCrc), actualMeta(&_actual), expectedCrc(_expectedCrc), expectedMeta(&_expected), projectedCrc(_projectedCrc), projectedMeta(&_output), options(_options)
+    DiskReadMapping(RecordTranslationMode _mode, const char * _format, unsigned _actualCrc, IOutputMetaData & _actual, unsigned _expectedCrc, IOutputMetaData & _expected, unsigned _projectedCrc, IOutputMetaData & _output, const IPropertyTree * _fileOptions)
+    : mode(_mode), format(_format), actualCrc(_actualCrc), actualMeta(&_actual), expectedCrc(_expectedCrc), expectedMeta(&_expected), projectedCrc(_projectedCrc), projectedMeta(&_output), fileOptions(_fileOptions)
     {}
 
     virtual const char * queryFormat() const override { return format; }
@@ -55,7 +56,7 @@ public:
     virtual IOutputMetaData * queryActualMeta() const override { return actualMeta; }
     virtual IOutputMetaData * queryExpectedMeta() const override{ return expectedMeta; }
     virtual IOutputMetaData * queryProjectedMeta() const override{ return projectedMeta; }
-    virtual const IPropertyTree * queryOptions() const override { return options; }
+    virtual const IPropertyTree * queryFileOptions() const override { return fileOptions; }
     virtual RecordTranslationMode queryTranslationMode() const override { return mode; }
 
     virtual const IDynamicTransform * queryTranslator() const override
@@ -71,11 +72,18 @@ public:
 
     virtual bool matches(const IDiskReadMapping * other) const
     {
-        return mode == other->queryTranslationMode() && streq(format, other->queryFormat()) &&
-                ((actualCrc && actualCrc == other->getActualCrc()) || (actualMeta == other->queryActualMeta())) &&
-                ((expectedCrc && expectedCrc == other->getExpectedCrc()) || (expectedMeta == other->queryExpectedMeta())) &&
-                ((projectedCrc && projectedCrc == other->getProjectedCrc()) || (projectedMeta == other->queryProjectedMeta())) &&
-                areMatchingPTrees(options, other->queryOptions());
+        if ((mode != other->queryTranslationMode()) || !streq(format, other->queryFormat()))
+            return false;
+        //if crc is set, then a matching crc counts as a match, otherwise meta must be identical
+        if (((actualCrc && actualCrc == other->getActualCrc()) || (actualMeta == other->queryActualMeta())) &&
+            ((expectedCrc && expectedCrc == other->getExpectedCrc()) || (expectedMeta == other->queryExpectedMeta())) &&
+            ((projectedCrc && projectedCrc == other->getProjectedCrc()) || (projectedMeta == other->queryProjectedMeta())))
+        {
+            if (!areMatchingPTrees(fileOptions->queryPropTree("formatOptions"), other->queryFileOptions()->queryPropTree("formatOptions")))
+                return false;
+            return true;
+        }
+        return false;
     }
 
     virtual bool expectedMatchesProjected() const
@@ -96,7 +104,7 @@ protected:
     Linked<IOutputMetaData> actualMeta;
     Linked<IOutputMetaData> expectedMeta;
     Linked<IOutputMetaData> projectedMeta;
-    Linked<const IPropertyTree> options;
+    Linked<const IPropertyTree> fileOptions;
     mutable Owned<const IDynamicTransform> translator;
     mutable Owned<const IKeyTranslator> keyedTranslator;
     mutable SpinLock translatorLock; // use a spin lock since almost certainly not going to contend
@@ -135,7 +143,8 @@ void DiskReadMapping::ensureTranslators() const
     const RtlRecord & sourceRecord = sourceMeta->queryRecordAccessor(true);
     if (strsame(format, "csv"))
     {
-        type_vals format = options->hasProp("ascii") ? type_string : type_utf8;
+        const IPropertyTree * formatOptions = fileOptions->queryPropTree("formatOptions");
+        type_vals format = formatOptions->hasProp("ascii") ? type_string : type_utf8;
         translator.setown(createRecordTranslatorViaCallback(projectedRecord, sourceRecord, format));
     }
     else if (strsame(format, "xml"))
@@ -145,7 +154,14 @@ void DiskReadMapping::ensureTranslators() const
     else
     {
         if ((projectedMeta != sourceMeta) && (projectedCrc != sourceCrc))
-            translator.setown(createRecordTranslator(projectedRecord, sourceRecord));
+        {
+            //Special case the situation where the output record matches the input record with some virtual fields
+            //appended.  This allows alien datatypes or ifblocks in records to also hav virtual file positions/
+            if (fileOptions->getPropBool("@cloneAppendVirtuals"))
+                translator.setown(createCloneVirtualRecordTranslator(projectedRecord, *sourceMeta));
+            else
+                translator.setown(createRecordTranslator(projectedRecord, sourceRecord));
+        }
     }
 
     if (translator)
@@ -173,16 +189,16 @@ void DiskReadMapping::ensureTranslators() const
     checkedTranslators = true;
 }
 
-THORHELPER_API IDiskReadMapping * createDiskReadMapping(RecordTranslationMode mode, const char * format, unsigned actualCrc, IOutputMetaData & actual, unsigned expectedCrc, IOutputMetaData & expected, unsigned projectedCrc, IOutputMetaData & projected, const IPropertyTree * options)
+THORHELPER_API IDiskReadMapping * createDiskReadMapping(RecordTranslationMode mode, const char * format, unsigned actualCrc, IOutputMetaData & actual, unsigned expectedCrc, IOutputMetaData & expected, unsigned projectedCrc, IOutputMetaData & projected, const IPropertyTree * fileOptions)
 {
     assertex(expectedCrc);
-    assertex(options);
-    return new DiskReadMapping(mode, format, actualCrc, actual, expectedCrc, expected, projectedCrc, projected, options);
+    assertex(fileOptions);
+    return new DiskReadMapping(mode, format, actualCrc, actual, expectedCrc, expected, projectedCrc, projected, fileOptions);
 }
 
 THORHELPER_API IDiskReadMapping * createUnprojectedMapping(IDiskReadMapping * mapping)
 {
-    return createDiskReadMapping(mapping->queryTranslationMode(), mapping->queryFormat(), mapping->getActualCrc(), *mapping->queryActualMeta(), mapping->getExpectedCrc(), *mapping->queryExpectedMeta(), mapping->getExpectedCrc(), *mapping->queryExpectedMeta(), mapping->queryOptions());
+    return createDiskReadMapping(mapping->queryTranslationMode(), mapping->queryFormat(), mapping->getActualCrc(), *mapping->queryActualMeta(), mapping->getExpectedCrc(), *mapping->queryExpectedMeta(), mapping->getExpectedCrc(), *mapping->queryExpectedMeta(), mapping->queryFileOptions());
 }
 
 
@@ -250,7 +266,7 @@ DiskRowReader::DiskRowReader(IDiskReadMapping * _mapping)
     //Options contain information that is the same for each file that is being read, and potentially expensive to reconfigure.
     translator = mapping->queryTranslator();
     keyedTranslator = mapping->queryKeyedTranslator();
-    const IPropertyTree * options = mapping->queryOptions();
+    const IPropertyTree * options = mapping->queryFileOptions();
     if (options->hasProp("encryptionKey"))
     {
         encryptionKey.resetBuffer();
@@ -283,7 +299,7 @@ bool DiskRowReader::matches(const char * format, bool streamRemote, IDiskReadMap
     //if ((expectedDiskMeta != &_expected) || (projectedDiskMeta != &_projected) || (actualDiskMeta != &_actual))
     //    return false;
 
-    const IPropertyTree * options = otherMapping->queryOptions();
+    const IPropertyTree * options = otherMapping->queryFileOptions();
     if (options->hasProp("encryptionKey"))
     {
         MemoryBuffer tempEncryptionKey;
@@ -343,11 +359,12 @@ public:
     LocalDiskRowReader(IDiskReadMapping * _mapping);
 
     virtual bool matches(const char * format, bool streamRemote, IDiskReadMapping * otherMapping) override;
-    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter) override;
-    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter) override;
+    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override;
+    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override;
+    virtual bool setInputFile(const CLogicalFileSlice & slice, const FieldFilterArray & expectedFilter, unsigned copy) override;
 
 protected:
-    virtual bool setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter);
+    virtual bool setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, offset_t startOffset, offset_t length, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter);
     virtual bool isBinary() const = 0;
 
 protected:
@@ -370,13 +387,13 @@ bool LocalDiskRowReader::matches(const char * format, bool streamRemote, IDiskRe
 }
 
 
-bool LocalDiskRowReader::setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & _expectedFilter)
+bool LocalDiskRowReader::setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, offset_t startOffset, offset_t length, const IPropertyTree * inputMeta, const FieldFilterArray & _expectedFilter)
 {
-    assertex(meta);
-    grouped = meta->getPropBool("grouped");
-    compressed = meta->getPropBool("compressed", false);
-    blockcompressed = meta->getPropBool("blockCompressed", false);
-    bool forceCompressed = meta->getPropBool("forceCompressed", false);
+    assertex(inputMeta);
+    grouped = inputMeta->getPropBool("@grouped");
+    compressed = inputMeta->getPropBool("@compressed", false);
+    blockcompressed = inputMeta->getPropBool("@blockCompressed", false);
+    bool forceCompressed = inputMeta->getPropBool("@forceCompressed", false);
 
     logicalFilename.set(_logicalFilename);
     filePart = _partNumber;
@@ -396,7 +413,7 @@ bool LocalDiskRowReader::setInputFile(IFile * inputFile, const char * _logicalFi
 
     if (isBinary())
     {
-        size32_t dfsRecordSize = meta->getPropInt("dfsRecordSize");
+        size32_t dfsRecordSize = inputMeta->getPropInt("@recordSize");
         size32_t fixedDiskRecordSize = actualDiskMeta->getFixedSize();
         if (dfsRecordSize)
         {
@@ -447,9 +464,15 @@ bool LocalDiskRowReader::setInputFile(IFile * inputFile, const char * _logicalFi
     if (!inputfileio)
         return false;
 
-    unsigned __int64 filesize = inputfileio->size();
+    if (length == unknownFileSize)
+    {
+        offset_t filesize = inputfileio->size();
+        assertex(startOffset <= filesize);
+        length = filesize - startOffset;
+    }
+
     //MORE: Allow a previously created input stream to be reused to avoid reallocating the buffer
-    inputStream.setown(createFileSerialStream(inputfileio, 0, filesize, readBufferSize));
+    inputStream.setown(createFileSerialStream(inputfileio, startOffset, length, readBufferSize));
 
     expectedFilter.clear();
     ForEachItemIn(i, _expectedFilter)
@@ -457,18 +480,32 @@ bool LocalDiskRowReader::setInputFile(IFile * inputFile, const char * _logicalFi
     return true;
 }
 
-bool LocalDiskRowReader::setInputFile(const char * localFilename, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter)
+bool LocalDiskRowReader::setInputFile(const char * localFilename, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter)
 {
     Owned<IFile> inputFile = createIFile(localFilename);
-    return setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, meta, expectedFilter);
+    return setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, 0, unknownFileSize, inputOptions, expectedFilter);
 }
 
-bool LocalDiskRowReader::setInputFile(const RemoteFilename & filename, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter)
+bool LocalDiskRowReader::setInputFile(const RemoteFilename & filename, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter)
 {
     Owned<IFile> inputFile = createIFile(filename);
-    return setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, meta, expectedFilter);
+    return setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, 0, unknownFileSize, inputOptions, expectedFilter);
 }
 
+bool LocalDiskRowReader::setInputFile(const CLogicalFileSlice & slice, const FieldFilterArray & expectedFilter, unsigned copy)
+{
+    const char * logicalFilename = slice.queryLogicalFilename();
+    offset_t baseOffset = slice.queryOffsetOfPart();
+
+    StringBuffer url;
+    slice.getURL(url, copy);
+    Owned<IFile> inputFile = createIFile(url);
+
+    //MORE: These need to be passed on to the input reader
+    offset_t startOffset = slice.queryStartOffset();
+    offset_t length = slice.queryLength();
+    return setInputFile(inputFile, logicalFilename, slice.queryPartNumber(), baseOffset, startOffset, length, slice.queryFileMeta(), expectedFilter);
+}
 
 
 //---------------------------------------------------------------------------------------------------------------------
@@ -492,7 +529,7 @@ public:
     virtual bool matches(const char * format, bool streamRemote, IDiskReadMapping * otherMapping) override;
 
 protected:
-    virtual bool setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter) override;
+    virtual bool setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, offset_t startOffset, offset_t length, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override;
     virtual bool isBinary() const { return true; }
 
     inline bool fieldFilterMatch(const void * buffer)
@@ -516,7 +553,7 @@ private:
     inline const void * inlineNextRow(PROCESS processor) __attribute__((always_inline));
 
 protected:
-    ISourceRowPrefetcher * actualRowPrefetcher = nullptr;
+    Owned<ISourceRowPrefetcher> actualRowPrefetcher;
     const RtlRecord  * actualRecord = nullptr;
     RowFilter actualFilter;               // This refers to the actual disk layout
     bool eogPending = false;
@@ -527,7 +564,7 @@ protected:
 BinaryDiskRowReader::BinaryDiskRowReader(IDiskReadMapping * _mapping)
 : LocalDiskRowReader(_mapping)
 {
-    actualRowPrefetcher = actualDiskMeta->createDiskPrefetcher();
+    actualRowPrefetcher.setown(actualDiskMeta->createDiskPrefetcher());
     actualRecord = &actualDiskMeta->queryRecordAccessor(true);
     needToTranslate = (translator && translator->needsTranslate());
 }
@@ -546,9 +583,9 @@ bool BinaryDiskRowReader::matches(const char * format, bool streamRemote, IDiskR
     return LocalDiskRowReader::matches(format, streamRemote, otherMapping);
 }
 
-bool BinaryDiskRowReader::setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter)
+bool BinaryDiskRowReader::setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, offset_t startOffset, offset_t length, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter)
 {
-    if (!LocalDiskRowReader::setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, meta, expectedFilter))
+    if (!LocalDiskRowReader::setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, startOffset, length, inputOptions, expectedFilter))
         return false;
 
     actualFilter.clear().appendFilters(expectedFilter);
@@ -737,9 +774,9 @@ public:
         projectedRecord = &mapping->queryProjectedMeta()->queryRecordAccessor(true);
     }
 
-    virtual bool setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & _expectedFilter) override
+    virtual bool setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, offset_t startOffset, offset_t length, const IPropertyTree * inputOptions, const FieldFilterArray & _expectedFilter) override
     {
-        if (!LocalDiskRowReader::setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, meta, _expectedFilter))
+        if (!LocalDiskRowReader::setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, startOffset, length, inputOptions, _expectedFilter))
             return false;
 
         projectedFilter.clear().appendFilters(_expectedFilter);
@@ -836,9 +873,9 @@ public:
     virtual bool matches(const char * format, bool streamRemote, IDiskReadMapping * otherMapping) override;
 
 protected:
-    virtual bool setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter) override;
+    virtual bool setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, offset_t startOffset, offset_t length, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override;
 
-    void processOption(CSVSplitter::MatchItem element, const IPropertyTree & config, const char * option, const char * dft, const char * dft2 = nullptr);
+    void processOption(CSVSplitter::MatchItem element, const IPropertyTree & csvOptions, const char * option, const char * dft, const char * dft2 = nullptr);
 
     inline bool fieldFilterMatchProjected(const void * buffer)
     {
@@ -869,24 +906,25 @@ protected:
 CsvDiskRowReader::CsvDiskRowReader(IDiskReadMapping * _mapping)
 : ExternalFormatDiskRowReader(_mapping)
 {
-    const IPropertyTree & config = *mapping->queryOptions();
+    const IPropertyTree & fileOptions = *mapping->queryFileOptions();
+    const IPropertyTree & csvOptions = *fileOptions.queryPropTree("formatOptions");
 
-    maxRowSize = config.getPropInt64("maxRowSize", defaultMaxCsvRowSizeMB) * 1024 * 1024;
-    preserveWhitespace = config.getPropBool("preserveWhitespace", false);
-    preserveWhitespace = config.getPropBool("notrim", preserveWhitespace);
+    maxRowSize = csvOptions.getPropInt64("maxRowSize", defaultMaxCsvRowSizeMB) * 1024 * 1024;
+    preserveWhitespace = csvOptions.getPropBool("preserveWhitespace", false);
+    preserveWhitespace = csvOptions.getPropBool("notrim", preserveWhitespace);
 
     const RtlRecord * inputRecord = &mapping->queryActualMeta()->queryRecordAccessor(true);
     unsigned numInputFields = inputRecord->getNumFields();
     csvSplitter.init(numInputFields, maxRowSize, csvQuote, csvSeparate, csvTerminate, csvEscape, preserveWhitespace);
 
     //MORE: How about options from the file? - test writing with some options and then reading without specifying them
-    processOption(CSVSplitter::QUOTE, config, "quote", "\"");
-    processOption(CSVSplitter::SEPARATOR, config, "separator", ",");
-    processOption(CSVSplitter::TERMINATOR, config, "terminator", "\n", "\r\n");
-    if (config.getProp("escape", csvEscape))
+    processOption(CSVSplitter::QUOTE, csvOptions, "quote", "\"");
+    processOption(CSVSplitter::SEPARATOR, csvOptions, "separator", ",");
+    processOption(CSVSplitter::TERMINATOR, csvOptions, "terminator", "\n", "\r\n");
+    if (csvOptions.getProp("escape", csvEscape))
         csvSplitter.addEscape(csvEscape);
 
-    headerLines = config.getPropInt64("heading");
+    headerLines = csvOptions.getPropInt64("heading");
     fieldFetcher.setown(new CFieldFetcher(csvSplitter, numInputFields));
 }
 
@@ -898,12 +936,12 @@ bool CsvDiskRowReader::matches(const char * format, bool streamRemote, IDiskRead
     return ExternalFormatDiskRowReader::matches(format, streamRemote, otherMapping);
 }
 
-void CsvDiskRowReader::processOption(CSVSplitter::MatchItem element, const IPropertyTree & config, const char * option, const char * dft, const char * dft2)
+void CsvDiskRowReader::processOption(CSVSplitter::MatchItem element, const IPropertyTree & csvOptions, const char * option, const char * dft, const char * dft2)
 {
-    if (config.hasProp(option))
+    if (csvOptions.hasProp(option))
     {
-        bool useAscii = mapping->queryOptions()->hasProp("ascii");
-        Owned<IPropertyTreeIterator> iter = config.getElements(option);
+        bool useAscii = csvOptions.hasProp("ascii");
+        Owned<IPropertyTreeIterator> iter = csvOptions.getElements(option);
         ForEach(*iter)
         {
             const char * value = iter->query().queryProp("");
@@ -926,9 +964,9 @@ void CsvDiskRowReader::processOption(CSVSplitter::MatchItem element, const IProp
     }
 }
 
-bool CsvDiskRowReader::setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & _expectedFilter)
+bool CsvDiskRowReader::setInputFile(IFile * inputFile, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, offset_t startOffset, offset_t length, const IPropertyTree * inputOptions, const FieldFilterArray & _expectedFilter)
 {
-    if (!ExternalFormatDiskRowReader::setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, meta, _expectedFilter))
+    if (!ExternalFormatDiskRowReader::setInputFile(inputFile, _logicalFilename, _partNumber, _baseOffset, startOffset, length, inputOptions, _expectedFilter))
         return false;
 
     //Skip any header lines..
@@ -1048,7 +1086,7 @@ class CompoundProjectRowReader : extends CInterfaceOf<IDiskRowStream>, implement
     MemoryBufferBuilder bufferBuilder;
     RtlDynamicRowBuilder allocatedBuilder;
     Linked<IEngineRowAllocator> outputAllocator;
-    IDiskRowStream * rawInputStream;
+    IDiskRowStream * rawInputStream = nullptr;
 public:
     CompoundProjectRowReader(IDiskRowReader * _input, IDiskReadMapping * _mapping)
     : inputReader(_input), mapping(_mapping), bufferBuilder(tempOutputBuffer, 0), allocatedBuilder(nullptr)
@@ -1059,27 +1097,27 @@ public:
     }
     IMPLEMENT_IINTERFACE_USING(CInterfaceOf<IDiskRowStream>)
 
-    virtual IDiskRowStream * queryAllocatedRowStream(IEngineRowAllocator * _outputAllocator)
+    virtual IDiskRowStream * queryAllocatedRowStream(IEngineRowAllocator * _outputAllocator) override
     {
         allocatedBuilder.setAllocator(_outputAllocator);
         outputAllocator.set(_outputAllocator);
         return this;
     }
 
-    virtual bool matches(const char * _format, bool _streamRemote, IDiskReadMapping * _mapping)
+    virtual bool matches(const char * _format, bool _streamRemote, IDiskReadMapping * _mapping) override
     {
         return false;
     }
 
-    virtual void clearInput()
+    virtual void clearInput() override
     {
         inputReader->clearInput();
         rawInputStream = nullptr;
     }
 
-    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter)
+    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override
     {
-        if (inputReader->setInputFile(localFilename, logicalFilename, partNumber, baseOffset, meta, expectedFilter))
+        if (inputReader->setInputFile(localFilename, logicalFilename, partNumber, baseOffset, inputOptions, expectedFilter))
         {
             rawInputStream = inputReader->queryAllocatedRowStream(nullptr);
             return true;
@@ -1087,9 +1125,19 @@ public:
         return false;
     }
 
-    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter)
+    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override
     {
-        if (inputReader->setInputFile(filename, logicalFilename, partNumber, baseOffset, meta, expectedFilter))
+        if (inputReader->setInputFile(filename, logicalFilename, partNumber, baseOffset, inputOptions, expectedFilter))
+        {
+            rawInputStream = inputReader->queryAllocatedRowStream(nullptr);
+            return true;
+        }
+        return false;
+    }
+
+    virtual bool setInputFile(const CLogicalFileSlice & slice, const FieldFilterArray & expectedFilter, unsigned copy) override
+    {
+        if (inputReader->setInputFile(slice, expectedFilter, copy))
         {
             rawInputStream = inputReader->queryAllocatedRowStream(nullptr);
             return true;
@@ -1098,9 +1146,9 @@ public:
     }
 
 //interface IRowReader
-    virtual bool getCursor(MemoryBuffer & cursor) { return rawInputStream->getCursor(cursor); }
-    virtual void setCursor(MemoryBuffer & cursor) { rawInputStream->setCursor(cursor); }
-    virtual void stop() { rawInputStream->stop(); }
+    virtual bool getCursor(MemoryBuffer & cursor) override { return rawInputStream->getCursor(cursor); }
+    virtual void setCursor(MemoryBuffer & cursor) override { rawInputStream->setCursor(cursor); }
+    virtual void stop() override { rawInputStream->stop(); }
 
     virtual const void *nextRow(size32_t & resultSize) override
     {
@@ -1158,13 +1206,13 @@ public:
         compoundReader.setown(new CompoundProjectRowReader(expectedReader, mapping));
     }
 
-    virtual IDiskRowStream * queryAllocatedRowStream(IEngineRowAllocator * _outputAllocator)
+    virtual IDiskRowStream * queryAllocatedRowStream(IEngineRowAllocator * _outputAllocator) override
     {
         assertex(activeReader);
         return activeReader->queryAllocatedRowStream(_outputAllocator);
     }
 
-    virtual bool matches(const char * _format, bool _streamRemote, IDiskReadMapping * _mapping)
+    virtual bool matches(const char * _format, bool _streamRemote, IDiskReadMapping * _mapping) override
     {
         return directReader->matches(_format, _streamRemote, _mapping);
     }
@@ -1172,31 +1220,41 @@ public:
     //Specify where the raw binary input for a particular file is coming from, together with its actual format.
     //Does this make sense, or should it be passed a filename?  an actual format?
     //Needs to specify a filename rather than a ISerialStream so that the interface is consistent for local and remote
-    virtual void clearInput()
+    virtual void clearInput() override
     {
         directReader->clearInput();
         compoundReader->clearInput();
         activeReader = nullptr;
     }
 
-    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter)
+    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override
     {
         bool useProjected = canFilterDirectly(expectedFilter);
         if (useProjected)
             activeReader = directReader;
         else
             activeReader = compoundReader;
-        return activeReader->setInputFile(localFilename, logicalFilename, partNumber, baseOffset, meta, expectedFilter);
+        return activeReader->setInputFile(localFilename, logicalFilename, partNumber, baseOffset, inputOptions, expectedFilter);
     }
 
-    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter)
+    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override
     {
         bool useProjected = canFilterDirectly(expectedFilter);
         if (useProjected)
             activeReader = directReader;
         else
             activeReader = compoundReader;
-        return activeReader->setInputFile(filename, logicalFilename, partNumber, baseOffset, meta, expectedFilter);
+        return activeReader->setInputFile(filename, logicalFilename, partNumber, baseOffset, inputOptions, expectedFilter);
+    }
+
+    virtual bool setInputFile(const CLogicalFileSlice & slice, const FieldFilterArray & expectedFilter, unsigned copy) override
+    {
+        bool useProjected = canFilterDirectly(expectedFilter);
+        if (useProjected)
+            activeReader = directReader;
+        else
+            activeReader = compoundReader;
+        return activeReader->setInputFile(slice, expectedFilter, copy);
     }
 
 protected:
@@ -1238,8 +1296,9 @@ public:
     virtual bool matches(const char * _format, bool _streamRemote, IDiskReadMapping * _mapping) override;
 
 // IDiskRowReader
-    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter) override;
-    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter) override;
+    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override;
+    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) override;
+    virtual bool setInputFile(const CLogicalFileSlice & slice, const FieldFilterArray & expectedFilter, unsigned copy) override;
 
 private:
     template <class PROCESS>
@@ -1275,7 +1334,7 @@ bool RemoteDiskRowReader::matches(const char * _format, bool _streamRemote, IDis
     return DiskRowReader::matches(_format, _streamRemote, _mapping);
 }
 
-bool RemoteDiskRowReader::setInputFile(const RemoteFilename & rfilename, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilters)
+bool RemoteDiskRowReader::setInputFile(const RemoteFilename & rfilename, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilters)
 {
     // NB: only binary handles can be remotely processed by dafilesrv at the moment
 
@@ -1332,11 +1391,15 @@ bool RemoteDiskRowReader::setInputFile(const RemoteFilename & rfilename, const c
     return true;
 }
 
-bool RemoteDiskRowReader::setInputFile(const char * localFilename, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter)
+bool RemoteDiskRowReader::setInputFile(const char * localFilename, const char * _logicalFilename, unsigned _partNumber, offset_t _baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter)
 {
     throwUnexpected();
 }
 
+bool RemoteDiskRowReader::setInputFile(const CLogicalFileSlice & slice, const FieldFilterArray & expectedFilter, unsigned copy)
+{
+    UNIMPLEMENTED;
+}
 
 template <class PROCESS>
 const void *RemoteDiskRowReader::inlineNextRow(PROCESS processor)
diff --git a/common/thorhelper/thorread.hpp b/common/thorhelper/thorread.hpp
index 6896b11e9..ab6101e2a 100644
--- a/common/thorhelper/thorread.hpp
+++ b/common/thorhelper/thorread.hpp
@@ -27,6 +27,7 @@
 #include "jrowstream.hpp"
 #include "rtlkey.hpp"
 
+//--- Classes and interfaces for reading instances of files
 //The following is constant for the life of a disk read activity
 interface IDiskReadOutputMapping : public IInterface
 {
@@ -51,7 +52,7 @@ public:
     virtual IOutputMetaData * queryActualMeta() const = 0;
     virtual IOutputMetaData * queryExpectedMeta() const = 0;
     virtual IOutputMetaData * queryProjectedMeta() const = 0;
-    virtual const IPropertyTree * queryOptions() const = 0;
+    virtual const IPropertyTree * queryFileOptions() const = 0;
     virtual RecordTranslationMode queryTranslationMode() const = 0;
 
     virtual bool matches(const IDiskReadMapping * other) const = 0;
@@ -61,7 +62,7 @@ public:
     virtual const IKeyTranslator *queryKeyedTranslator() const = 0; // translates from expected to actual
 };
 
-THORHELPER_API IDiskReadMapping * createDiskReadMapping(RecordTranslationMode mode, const char * format, unsigned actualCrc, IOutputMetaData & actual, unsigned expectedCrc, IOutputMetaData & expected, unsigned projectedCrc, IOutputMetaData & projected, const IPropertyTree * options);
+THORHELPER_API IDiskReadMapping * createDiskReadMapping(RecordTranslationMode mode, const char * format, unsigned actualCrc, IOutputMetaData & actual, unsigned expectedCrc, IOutputMetaData & expected, unsigned projectedCrc, IOutputMetaData & projected, const IPropertyTree * fileOptions);
 
 
 typedef IConstArrayOf<IFieldFilter> FieldFilterArray;
@@ -73,6 +74,7 @@ public:
 };
 
 interface ITranslator;
+class CLogicalFileSlice;
 interface IDiskRowReader : extends IRowReader
 {
 public:
@@ -82,8 +84,9 @@ public:
     //Does this make sense, or should it be passed a filename?  an actual format?
     //Needs to specify a filename rather than a ISerialStream so that the interface is consistent for local and remote
     virtual void clearInput() = 0;
-    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter) = 0;
-    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * meta, const FieldFilterArray & expectedFilter) = 0;
+    virtual bool setInputFile(const char * localFilename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) = 0;
+    virtual bool setInputFile(const RemoteFilename & filename, const char * logicalFilename, unsigned partNumber, offset_t baseOffset, const IPropertyTree * inputOptions, const FieldFilterArray & expectedFilter) = 0;
+    virtual bool setInputFile(const CLogicalFileSlice & slice, const FieldFilterArray & expectedFilter, unsigned copy) = 0;
 };
 
 //Create a row reader for a thor binary file.  The expected, projected, actual and options never change.  The file providing the data can change.
diff --git a/common/thorhelper/thorsoapcall.cpp b/common/thorhelper/thorsoapcall.cpp
index b75d9c19a..e1340ac86 100644
--- a/common/thorhelper/thorsoapcall.cpp
+++ b/common/thorhelper/thorsoapcall.cpp
@@ -505,11 +505,10 @@ void initPersistentHandler()
     if (!persistentInitDone)
     {
 #ifndef _CONTAINERIZED
-        const IProperties &conf = queryEnvironmentConf();
-        int maxPersistentRequests = conf.getPropInt("maxPersistentRequests", DEFAULT_MAX_PERSISTENT_REQUESTS);
+        int maxPersistentRequests = queryEnvironmentConf().getPropInt("maxPersistentRequests", DEFAULT_MAX_PERSISTENT_REQUESTS);
 #else
-        const IPropertyTree& conf = queryComponentConfig();
-        int maxPersistentRequests = conf.getPropInt("@maxPersistentRequests", DEFAULT_MAX_PERSISTENT_REQUESTS);
+        Owned<IPropertyTree> conf = getComponentConfig();
+        int maxPersistentRequests = conf->getPropInt("@maxPersistentRequests", DEFAULT_MAX_PERSISTENT_REQUESTS);
 #endif
         if (maxPersistentRequests != 0)
             persistentHandler = createPersistentHandler(nullptr, DEFAULT_MAX_PERSISTENT_IDLE_TIME, maxPersistentRequests, PersistentLogLevel::PLogMin, true);
diff --git a/common/thorhelper/thorstore.cpp b/common/thorhelper/thorstore.cpp
new file mode 100644
index 000000000..db90c654f
--- /dev/null
+++ b/common/thorhelper/thorstore.cpp
@@ -0,0 +1,286 @@
+/*##############################################################################
+
+    HPCC SYSTEMS software Copyright (C) 2020 HPCC SystemsÂ®.
+
+    Licensed under the Apache License, Version 2.0 (the "License");
+    you may not use this file except in compliance with the License.
+    You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
+############################################################################## */
+
+#include "jliball.hpp"
+#include "jsocket.hpp"
+#include "thorfile.hpp"
+
+#include "eclhelper.hpp"
+#include "eclrtl.hpp"
+#include "eclrtl_imp.hpp"
+
+#include "dautils.hpp"
+#include "dadfs.hpp"
+
+#include "thorstore.hpp"
+
+
+//If the path associated with a plane contains one or more hashes in a row those hashes
+//are replaced with the device number, padded with 0s to the width of the number of hashes
+StringBuffer & expandPlanePath(StringBuffer & target, const char * path, unsigned device)
+{
+    for (;;)
+    {
+        const char * hash = strchr(path, '#');
+        if (!hash)
+            break;
+
+        target.append(hash-path, path);
+        unsigned width = 1;
+        while (hash[1] == '#')
+        {
+            hash++;
+            width++;
+        }
+
+        target.appendf("%0*u", width, device);
+        path = hash+1;
+    }
+    target.append(path);
+    return target;
+}
+
+CStorageHostGroup::CStorageHostGroup(const IPropertyTree * _xml)
+: xml(_xml)
+{
+}
+
+const char * CStorageHostGroup::queryName() const
+{
+    return xml->queryProp("@name");
+}
+
+const char * CStorageHostGroup::queryHost(unsigned idx) const
+{
+    VStringBuffer xpath("hosts[%u]", idx+1);
+    return xml->queryProp(xpath);
+}
+
+bool CStorageHostGroup::isLocal(unsigned device) const
+{
+    const char * hostname = queryHost(device);
+    if (hostname)
+    {
+        //MORE: Likely to be inefficient - should search differently?
+        IpAddress ip(hostname);
+        return ip.isLocal();
+    }
+    return false;
+}
+
+/*
+ * A StoragePlane represents a set of storage devices that are used together to store a distributed file.  Each
+ * storage plane has a fixed number of logical devices.  If there are > 1 then the storage plane index can be included
+ * within the file path - which allows data to be striped across multiple devices.
+ *
+ * For S3 etc. it specifies the region, bucket and root path.
+ * For local NFS mounted NAS it specifies the mount point.
+ * For other NAS solutions it could indicate a list of ips, and root paths.
+ * For locally attached storage it specifies the root path, and a set of hostnames.  Also whether dafilesrv is allowed/required.
+ *
+ * For NAS/cloud situation, each cluster should define the default location the data is stored (although it can be overridden in the OUTPUT)..
+ *
+ * For an attached storage scheme, each cluster defined in the environment implicitly defines a locally attached storage plane.  It would
+ * be useful for any cluster to be able to specify a separate plane for the spill files e.g., ramdisk/faster disks.
+ * It could alternatively rely on an implicit plane (for the current node),
+ *
+ * There should be a special local plane for spill files and other temporary files.  How do these fit in?  Should
+ * there be a special ip group ('!') that refers to the cluster for the current component?
+ *
+ * What problems are there resolving ips - e.g. in the globally shared storage plane?  Is it done in the plane or in the logical file?
+ */
+
+
+CStoragePlane::CStoragePlane(const IPropertyTree * _xml, const CStorageHostGroup * _host)
+ : xml(_xml), hostGroup(_host)
+{
+    name = xml->queryProp("@name");
+    numDevices = xml->getPropInt("@numDevices", 1);
+    size = xml->getPropInt("@size", numDevices);
+    offset = xml->getPropInt("@offset", 0);
+    startDelta = xml->getPropInt("@start", 0);
+    startDrive = 0; // Not sure if we really want to support multiple drives..
+}
+
+bool CStoragePlane::containsHost(const char * host) const
+{
+    Owned<IPropertyTreeIterator> iter = xml->getElements("hosts");
+    ForEach(*iter)
+    {
+        if (streq(iter->query().queryProp(""), host))
+            return true;
+    }
+    return false;
+}
+
+bool CStoragePlane::containsPath(const char * path)
+{
+    return startsWith(path, queryPath());
+}
+
+bool CStoragePlane::matchesHost(const char * host)
+{
+    return (xml->getCount("hosts") == 1) && containsHost(host);
+}
+
+const char * CStoragePlane::queryPath() const
+{
+    const char * path = xml->queryProp("@prefix");
+    return path ? path : "/";
+}
+
+const char * CStoragePlane::queryScopeSeparator() const
+{
+    //MORE: Could support it set via a property
+    return "/";
+}
+
+StringBuffer & CStoragePlane::getURL(StringBuffer & target, unsigned part) const
+{
+    unsigned device = getDevice(part);
+    if (hostGroup)
+    {
+        target.append("//");
+        target.append(hostGroup->queryHost(device));
+    }
+
+    //MORE: Should this allow drive to modify and use $D<n>$ syntax instead?  I think that functionality  can be lost.
+    //unsigned drive = getDrive(part);
+    expandPlanePath(target, queryPath(), device);
+    return target;
+}
+
+
+unsigned CStoragePlane::getWidth() const
+{
+    return numDevices;  // Could subdivide even if not done by ip
+}
+
+#if 0
+//What is the cost of accessing part "part" from host "accessIp"
+unsigned CStoragePlane::getCost(unsigned part, const const char * accessIp) const
+{
+    if (!hostGroup)
+        return xml->getPropInt("@accessCost", remoteCost);
+    unsigned device = getDevice(part);
+    if (hosts->isLocal(device, accessIp))
+        return directCost;
+    if (hostGroup->isSameNetwork(device, accessIp))
+        return localDCost;
+    return remoteCost;
+}
+#endif
+
+unsigned CStoragePlane::getDevice(unsigned part) const
+{
+    unsigned nodeDelta = (part + startDelta) % size;
+    unsigned device = (nodeDelta + offset);
+    assertex(device < getWidth());
+    return device;
+}
+
+unsigned CStoragePlane::getDrive(unsigned part) const
+{
+    unsigned driveDelta = (part + startDelta) / size;
+    unsigned drive = (startDrive + driveDelta) % getNumDrives();
+    return drive;
+}
+
+bool CStoragePlane::isLocal(unsigned part) const
+{
+    if (hostGroup)
+        return hostGroup->isLocal(getDevice(part));
+    return false;
+}
+
+bool CStoragePlane::isAttachedStorage() const
+{
+    return (hostGroup != nullptr);
+}
+
+//---------------------------------------------------------------------------------------------------------------------
+
+const CStorageHostGroup * CStorageSystems::queryHostGroup(const char * search) const
+{
+    if (!search)
+        return nullptr;
+
+    ForEachItemIn(i, hostGroups)
+    {
+        CStorageHostGroup & cur = hostGroups.item(i);
+        if (strsame(search, cur.queryName()))
+            return &cur;
+    }
+    return nullptr;
+}
+
+const CStoragePlane * CStorageSystems::queryPlane(const char * search) const
+{
+    if (!search)
+        return nullptr;
+
+    ForEachItemIn(i, planes)
+    {
+        CStoragePlane & cur = planes.item(i);
+        if (strsame(search, cur.queryName()))
+            return &cur;
+    }
+    return nullptr;
+}
+
+const CStoragePlane * CStorageSystems::queryNullPlane() const
+{
+    if (!nullPlaneXml)
+    {
+        nullPlaneXml.setown(createPTree("plane"));
+        nullPlaneXml->setProp("@name", "implicitExternalPlane");
+        nullPlane.setown(new CStoragePlane(nullPlaneXml, nullptr));
+    }
+
+    return nullPlane;
+}
+
+void CStorageSystems::setFromMeta(const IPropertyTree * xml)
+{
+    const IPropertyTree * storage = xml->queryPropTree("storage");
+
+    //MORE: Is it worth checking if the hostGroups and storageplanes are the same as last time?
+    //if areMatchingPTrees(storage, savedStorage) return;
+    hostGroups.kill();
+    planes.kill();
+
+    if (!storage)
+        return;
+
+    Owned<IPropertyTreeIterator> hostIter = storage->getElements("hostGroups");
+    ForEach(*hostIter)
+        hostGroups.append(*new CStorageHostGroup(&hostIter->query()));
+
+    Owned<IPropertyTreeIterator> planeIter = storage->getElements("planes");
+    ForEach(*planeIter)
+    {
+        IPropertyTree * cur = &planeIter->query();
+        const CStorageHostGroup * hosts = queryHostGroup(cur->queryProp("@hosts"));
+        planes.append(*new CStoragePlane(cur, hosts));
+    }
+}
+
+void CStorageSystems::registerPlane(const IPropertyTree * plane)
+{
+    assertex(planes.empty());
+    planes.append(*new CStoragePlane(plane, nullptr));
+}
diff --git a/common/thorhelper/thorstore.hpp b/common/thorhelper/thorstore.hpp
new file mode 100644
index 000000000..009a75fa0
--- /dev/null
+++ b/common/thorhelper/thorstore.hpp
@@ -0,0 +1,170 @@
+/*##############################################################################
+
+    HPCC SYSTEMS software Copyright (C) 2020 HPCC SystemsÂ®.
+
+    Licensed under the Apache License, Version 2.0 (the "License");
+    you may not use this file except in compliance with the License.
+    You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
+############################################################################## */
+
+#ifndef __THORSTORE_HPP_
+#define __THORSTORE_HPP_
+
+#ifdef THORHELPER_EXPORTS
+ #define THORHELPER_API DECL_EXPORT
+#else
+ #define THORHELPER_API DECL_IMPORT
+#endif
+
+#include <vector>
+
+//All of the following will move to a different location (?dali) once the proof of concept is completed.
+
+//=====================================================================================================================
+
+/*
+ * File processing sequence:
+ *
+ * a) create a CLogicalFileCollection
+ *   A) with an implicit superfile
+ *      process each of the implicit subfiles in turn
+ *      Do we allow logical files and
+ *   B) with a logical super file
+ *      process each of the subfiles in turn
+ *   C) With a logical file
+ *      - Resolve the file
+ *      - extract the file information from dali
+ *      - extract the split points (from dali/disk).
+ *        potentially quite large, and expensive?  May want a hint to indicate how many ways the file will be read
+ *        to avoid retrieving if there will be no benefit.
+ *   D) With a absolute filename  [<host>|group?][:port]//path   (or local path if contains a /)
+ *      - NOTE: ./abc can be used to refer to a physical file in the current directory
+ *      - Add as a single (or multiple) part physical file, no logical distribution.
+ *      - not sure if we should allow the port or not.  Could be used to force use of dafilesrv??
+ *      - Need to check access rights - otherwise could extract security keys etc.
+ *   E) As a URL transport-protocol://path
+ *      - Expand wild cards (or other magic) to produce a full list of parts and nodes.  No logical distribution.
+ *      - Retrieve meta information for the file
+ *      - Retrieve partition information for the parts.
+ *      - possibly allow thor:array//path as another representation for (D).  What would make sense?
+ *   F) FILE::...
+ *      Check access rights, then translate to same as (D)
+ *   G) REMOTE::...
+ *      Call into the remote esp to extract the file information and merge it with the location information
+ *
+ * b) perform protocol dependent processing
+ *    - possibly part of stage (a) or a separate phase
+ *    - passing #parts that it will be read from to allow split information to be optimized.
+ *    A) thor
+         - Translate logical nodes to physical ips.
+         - gather any missing file sizes
+      B) s3/azure blobs
+         - Expand any wildcards in the filenames and create entries for each expanded file.
+         - gather file sizes
+      C) HDFS
+         - gather files sizes
+         - gather split points
+ * c) serialize to the slaves
+ * d) deserialize from the master
+ * e) call fileCollection::partition(numChannels, myChannel) to get a list of partitions
+ * f) iterate though the partitions for the current channel
+ *    a) need a reader for the format - how determine?
+ *    b) Where we determine if it should be read directly or via dafilesrv?
+ *    c) request a row reader for the
+ *
+ * Questions:
+ *    Where are the translators created?
+ *    What is signed?  It needs to be a self contained block of data that can easily be serialized and deserialized.
+ *      I don't think it needs to contain information about the storage array - only the logical file.
+ */
+
+class CStorageSystems;
+
+//What is a good term for a collection of drives
+//storage array/system/
+
+//This describes a set of disks that can be used to store a logical file.
+//  "device" is used to represent the index within the storage plane
+class THORHELPER_API CStorageHostGroup : public CInterface
+{
+public:
+    CStorageHostGroup(const IPropertyTree * _xml);
+
+    const char * queryName() const;
+    const char * queryHost(unsigned idx) const;
+    bool isLocal(unsigned device) const;
+
+private:
+    const IPropertyTree * xml = nullptr;
+};
+
+
+//This describes the a set of disks that can be used to store a logical file.
+//  "device" is used to represent the index within the storage plane
+class THORHELPER_API CStoragePlane : public CInterface
+{
+    friend class CStorageSystems;
+
+public:
+    CStoragePlane() = default;
+    CStoragePlane(const IPropertyTree * _xml, const CStorageHostGroup * _host);
+
+    bool containsHost(const char * host) const;
+    bool containsPath(const char * path);
+    bool matches(const char * search) const { return strsame(name, search); }
+    bool matchesHost(const char * host);
+
+//    unsigned getCost(unsigned device, const IpAddress & accessIp, PhysicalGroup & peerIPs) const;
+    StringBuffer & getURL(StringBuffer & target, unsigned part) const;
+    unsigned getWidth() const;
+    bool isLocal(unsigned part) const;
+    bool isAttachedStorage() const;
+    const char * queryName() const { return name; }
+    const char * queryPath() const;
+    const char * queryScopeSeparator() const;
+
+protected:
+    unsigned getNumDrives() const { return 1; }  // MORE: Should we allow support for drives as well as devices?
+    unsigned getDevice(unsigned part) const;
+    unsigned getDrive(unsigned part) const;
+
+private:
+    const IPropertyTree * xml = nullptr;
+    const char * name = nullptr;
+    const CStorageHostGroup * hostGroup = nullptr;
+    unsigned numDevices = 0;
+    unsigned offset = 0;  // offset + size <= plane->getWidth();
+    unsigned size = 0;  // size <= plane->getWidth();
+    unsigned startDelta = 0;  // allows different replication to be represented 0|1|width|....  Can be > size if plane has multiple drives
+    unsigned startDrive = 0;
+};
+
+class CStorageSystems
+{
+public:
+    void registerPlane(const IPropertyTree * _meta);
+    void setFromMeta(const IPropertyTree * _meta);
+
+    const CStorageHostGroup * queryHostGroup(const char * search) const;
+    const CStoragePlane * queryPlane(const char * search) const;
+    const CStoragePlane * queryNullPlane() const;
+
+protected:
+    CIArrayOf<CStorageHostGroup> hostGroups;
+    CIArrayOf<CStoragePlane> planes;
+    mutable Owned<IPropertyTree> nullPlaneXml;
+    mutable Owned<CStoragePlane> nullPlane;
+};
+
+//Exapand the a string, substituting hashes for the device number.  Default number of digits matches the number of hashes
+extern THORHELPER_API StringBuffer & expandPlanePath(StringBuffer & target, const char * path, unsigned device);
+
+#endif
diff --git a/common/workunit/workunit.cpp b/common/workunit/workunit.cpp
index e17925e78..cd414a7dd 100644
--- a/common/workunit/workunit.cpp
+++ b/common/workunit/workunit.cpp
@@ -7612,7 +7612,7 @@ bool extractFromWorkunitDAToken(const char * distributedAccessToken, StringBuffe
 wuTokenStates verifyWorkunitDAToken(const char * ctxUser, const char * daToken)
 {
     #ifdef _CONTAINERIZED
-    if (!queryComponentConfig().getPropBool("@wuTokens", false))
+    if (!getComponentConfigSP()->getPropBool("@wuTokens", false))
         return wuTokenInvalid;
     #endif
     if (isEmptyString(daToken))
@@ -13420,7 +13420,8 @@ extern WORKUNIT_API void addTimeStamp(IWorkUnit * wu, StatisticScopeType scopeTy
 
 static double getCpuSize(const char *resourceName)
 {
-    const char * cpuRequestedStr = queryComponentConfig().queryProp(resourceName);
+    Owned<IPropertyTree> compConfig = getComponentConfig();
+    const char * cpuRequestedStr = compConfig->queryProp(resourceName);
     if (!cpuRequestedStr)
         return 0.0;
     char * endptr;
@@ -13434,7 +13435,7 @@ static double getCpuSize(const char *resourceName)
 
 static double getCostCpuHour()
 {
-    double costCpuHour = queryGlobalConfig().getPropReal("cost/@perCpu");
+    double costCpuHour = getGlobalConfigSP()->getPropReal("cost/@perCpu");
     if (costCpuHour < 0.0)
         return 0.0;
     return costCpuHour;
@@ -14235,17 +14236,17 @@ bool applyK8sYaml(const char *componentName, const char *wuid, const char *job,
         E->Release();
         return false;
     }
-    jobYaml.replaceString("%jobname", jobname.str());
+    jobYaml.replaceString("_HPCC_JOBNAME_", jobname.str());
 
     VStringBuffer args("\"--workunit=%s\"", wuid);
     for (const auto &p: extraParams)
     {
-        if ('%' == p.first[0]) // jobspec substituion
+        if (hasPrefix(p.first.c_str(), "_HPCC_", false)) // jobspec substituion
             jobYaml.replaceString(p.first.c_str(), p.second.c_str());
         else
             args.append(" \"--").append(p.first.c_str()).append('=').append(p.second.c_str()).append("\"");
     }
-    jobYaml.replaceString("%args", args.str());
+    jobYaml.replaceString("_HPCC_ARGS_", args.str());
 
 // Disable ability change resources from within workunit
 // - all values are unquoted by toYAML.  This caused problems when previous string values are
@@ -14281,8 +14282,9 @@ bool applyK8sYaml(const char *componentName, const char *wuid, const char *job,
 static constexpr unsigned defaultPendingTimeSecs = 600;
 void runK8sJob(const char *componentName, const char *wuid, const char *job, const std::list<std::pair<std::string, std::string>> &extraParams)
 {
-    KeepK8sJobs keepJob = translateKeepJobs(queryComponentConfig().queryProp("@keepJobs"));
-    unsigned pendingTimeoutSecs = queryComponentConfig().getPropInt("@pendingTimeoutSecs", defaultPendingTimeSecs);
+    Owned<IPropertyTree> compConfig = getComponentConfig();
+    KeepK8sJobs keepJob = translateKeepJobs(compConfig->queryProp("@keepJobs"));
+    unsigned pendingTimeoutSecs = compConfig->getPropInt("@pendingTimeoutSecs", defaultPendingTimeSecs);
 
     bool removeNetwork = applyK8sYaml(componentName, wuid, job, "networkspec", extraParams, true);
     applyK8sYaml(componentName, wuid, job, "jobspec", extraParams, false);
diff --git a/dali/base/dadfs.cpp b/dali/base/dadfs.cpp
index a8f73800f..434c13db8 100644
--- a/dali/base/dadfs.cpp
+++ b/dali/base/dadfs.cpp
@@ -179,7 +179,7 @@ static IPropertyTree *getEmptyAttr()
 
 static double calcFileCost(const char * cluster, double sizeGB, double fileAgeDays)
 {
-    IPropertyTree * plane = queryStoragePlane(cluster);
+    Owned<IPropertyTree> plane = getStoragePlane(cluster);
     if (!plane)
         return 0.0;
     double storageCostDaily = plane->getPropReal("cost/@storageAtRest", 0.0) * 12 / 365;
@@ -10141,8 +10141,7 @@ public:
 
     void constructStorageGroups(bool force, StringBuffer &messages)
     {
-        IPropertyTree & global = queryGlobalConfig();
-        IPropertyTree * storage = global.queryPropTree("storage");
+        Owned<IPropertyTree> storage = getGlobalConfigSP()->getPropTree("storage");
         if (storage)
         {
             normalizeHostGroups();
@@ -10165,7 +10164,7 @@ public:
                 Owned<IPropertyTree> newClusterGroup;
                 if (hostGroup)
                 {
-                    IPropertyTree * match = queryHostGroup(hostGroup, true);
+                    Owned<IPropertyTree> match = getHostGroup(hostGroup, true);
                     std::vector<std::string> hosts;
                     Owned<IPropertyTreeIterator> hostIter = match->getElements("hosts");
                     ForEach (*hostIter)
diff --git a/dali/base/dafdesc.cpp b/dali/base/dafdesc.cpp
index 850fbc7ff..06c71aa10 100644
--- a/dali/base/dafdesc.cpp
+++ b/dali/base/dafdesc.cpp
@@ -3125,7 +3125,7 @@ static void setupContainerizedStorageLocations()
 {
     try
     {
-        IPropertyTree * storage = queryGlobalConfig().queryPropTree("storage");
+        Owned<IPropertyTree> storage = getGlobalConfigSP()->getPropTree("storage");
         if (storage)
         {
             IPropertyTree * defaults = storage->queryPropTree("default");
@@ -3339,13 +3339,25 @@ static void generateHosts(IPropertyTree * storage, GroupInfoArray & groups)
     }
 }
 
+
+static std::atomic<unsigned> normalizeHostGroupUpdateCBId{(unsigned)-1};
+MODULE_INIT(INIT_PRIORITY_STANDARD)
+{
+    return true;
+}
+MODULE_EXIT()
+{
+    if ((unsigned)-1 != normalizeHostGroupUpdateCBId)
+        removeConfigUpdateHook(normalizeHostGroupUpdateCBId);
+}
 static CriticalSection storageCS;
-void initializeStorageGroups(bool createPlanesFromGroups)
+static void doInitializeStorageGroups(bool createPlanesFromGroups)
 {
     CriticalBlock block(storageCS);
-    IPropertyTree * storage = queryGlobalConfig().queryPropTree("storage");
+    Owned<IPropertyTree> globalConfig = getGlobalConfig();
+    Owned<IPropertyTree> storage = globalConfig->getPropTree("storage");
     if (!storage)
-        storage = queryGlobalConfig().addPropTree("storage");
+        storage.set(globalConfig->addPropTree("storage"));
 
 #ifndef _CONTAINERIZED
     if (createPlanesFromGroups && !storage->hasProp("planes"))
@@ -3449,32 +3461,44 @@ void initializeStorageGroups(bool createPlanesFromGroups)
     setupContainerizedStorageLocations();
 }
 
-const char * queryDefaultStoragePlane()
+void initializeStorageGroups(bool createPlanesFromGroups)
+{
+    doInitializeStorageGroups(createPlanesFromGroups);
+    unsigned uninitialized = (unsigned)-1;
+    if (normalizeHostGroupUpdateCBId.compare_exchange_strong(uninitialized, 0))
+    {
+        auto updateFunc = [createPlanesFromGroups](const IPropertyTree *oldComponentConfiguration, const IPropertyTree *oldGlobalConfiguration)
+        {
+            PROGLOG("initializeStorageGroups update");
+            doInitializeStorageGroups(createPlanesFromGroups);
+        };
+        normalizeHostGroupUpdateCBId = installConfigUpdateHook(updateFunc);
+    }
+}
+
+bool getDefaultStoragePlane(StringBuffer &ret)
 {
     // If the plane is specified for the component, then use that
-    IPropertyTree & config = queryComponentConfig();
-    const char * plane = config.queryProp("@storagePlane");
-    if (plane)
-        return plane;
+    if (getComponentConfigSP()->getProp("@storagePlane", ret))
+        return true;
 
     //Otherwise check what the default plane for data storage is configured to be
-    plane = queryGlobalConfig().queryProp("storage/@dataPlane");
-    if (plane)
-        return plane;
+    if (getGlobalConfigSP()->getProp("storage/@dataPlane", ret))
+        return true;
 
 #ifdef _CONTAINERIZED
     throwUnexpectedX("Default data plane not specified"); // The default should always have been configured by the helm charts
 #else
-    return nullptr;
+    return false;
 #endif
 }
 
 //---------------------------------------------------------------------------------------------------------------------
 
-class CStoragePlane : public CInterfaceOf<IStoragePlane>
+class CStoragePlaneInfo : public CInterfaceOf<IStoragePlane>
 {
 public:
-    CStoragePlane(IPropertyTree * _xml) : xml(_xml) {}
+    CStoragePlaneInfo(IPropertyTree * _xml) : xml(_xml) {}
 
     virtual const char * queryPrefix() const override { return xml->queryProp("@prefix"); }
     virtual unsigned numDevices() const override { return xml->getPropInt("@numDevices", 1); }
@@ -3493,7 +3517,7 @@ IStoragePlane * getStoragePlane(const char * name, bool required)
     group.append(name).toLowerCase();
 
     VStringBuffer xpath("storage/planes[@group='%s']", group.str());
-    IPropertyTree * match = queryGlobalConfig().queryPropTree(xpath);
+    Owned<IPropertyTree> match = getGlobalConfigSP()->getPropTree(xpath);
     if (!match)
     {
         if (required)
@@ -3501,5 +3525,5 @@ IStoragePlane * getStoragePlane(const char * name, bool required)
         return nullptr;
     }
 
-    return new CStoragePlane(match);
+    return new CStoragePlaneInfo(match);
 }
\ No newline at end of file
diff --git a/dali/base/dafdesc.hpp b/dali/base/dafdesc.hpp
index 7fa53b521..532244fd0 100644
--- a/dali/base/dafdesc.hpp
+++ b/dali/base/dafdesc.hpp
@@ -332,7 +332,7 @@ extern da_decl void setPartMask(const char * mask);
 extern da_decl bool setReplicateDir(const char *name,StringBuffer &out, bool isrep=true,const char *baseDir=NULL,const char *repDir=NULL); // changes directory of name passed to backup directory
 
 extern da_decl void initializeStorageGroups(bool createPlanesFromGroups);
-extern da_decl const char * queryDefaultStoragePlane();
+extern da_decl bool getDefaultStoragePlane(StringBuffer &ret);
 extern da_decl IStoragePlane * getStoragePlane(const char * name, bool required);
 
 extern da_decl IFileDescriptor *createFileDescriptor();
diff --git a/dali/base/dameta.cpp b/dali/base/dameta.cpp
index b3dff18a7..a4ad4bacd 100644
--- a/dali/base/dameta.cpp
+++ b/dali/base/dameta.cpp
@@ -22,13 +22,13 @@
 
 
 //More to a more central location
-IPropertyTree * queryHostGroup(const char * name, bool required)
+IPropertyTree * getHostGroup(const char * name, bool required)
 {
     if (!isEmptyString(name))
     {
         VStringBuffer xpath("storage/hostGroups[@name='%s']", name);
-        IPropertyTree & global = queryGlobalConfig();
-        IPropertyTree * match = global.queryPropTree(xpath);
+        Owned<IPropertyTree> global = getGlobalConfig();
+        IPropertyTree * match = global->getPropTree(xpath);
         if (match)
             return match;
     }
@@ -37,18 +37,18 @@ IPropertyTree * queryHostGroup(const char * name, bool required)
     return nullptr;
 }
 
-IPropertyTree * queryStoragePlane(const char * name)
+IPropertyTree * getStoragePlane(const char * name)
 {
     VStringBuffer xpath("storage/planes[@name='%s']", name);
-    IPropertyTree & global = queryGlobalConfig();
-    return global.queryPropTree(xpath);
+    Owned<IPropertyTree> global = getGlobalConfig();
+    return global->getPropTree(xpath);
 }
 
 
 // Expand indirect hostGroups so each hostGroups has an expanded list of host names
 void normalizeHostGroups()
 {
-    Owned<IPropertyTreeIterator> hostGroupIter = queryGlobalConfig().getElements("storage/hostGroups");
+    Owned<IPropertyTreeIterator> hostGroupIter = getGlobalConfigSP()->getElements("storage/hostGroups");
     //Process the groups in order - so that multiple levels of indirection are supported
     ForEach (*hostGroupIter)
     {
@@ -57,7 +57,7 @@ void normalizeHostGroups()
         {
             const char * name = cur.queryProp("@name");
             const char * baseGroup = cur.queryProp("@hostGroup");
-            IPropertyTree * match = queryHostGroup(baseGroup, true);
+            Owned<IPropertyTree> match = getHostGroup(baseGroup, true);
             StringArray hosts;
             Owned<IPropertyTreeIterator> hostIter = match->getElements("hosts");
             ForEach (*hostIter)
@@ -83,21 +83,6 @@ void normalizeHostGroups()
 
 //Cloned for now - export and use from elsewhere
 
-static void copyPropIfMissing(IPropertyTree & target, const char * targetName, IPropertyTree & source, const char * sourceName)
-{
-    if (source.hasProp(sourceName) && !target.hasProp(targetName))
-    {
-        if (source.isBinary(sourceName))
-        {
-            MemoryBuffer value;
-            source.getPropBin(sourceName, value);
-            target.setPropBin(targetName, value.length(), value.toByteArray());
-        }
-        else
-            target.setProp(targetName, source.queryProp(sourceName));
-    }
-}
-
 static void copySeparatorPropIfMissing(IPropertyTree & target, const char * targetName, IPropertyTree & source, const char * sourceName)
 {
     //Legacy - commas are quoted if they occur in a separator list, so need to remove the leading backslashes
@@ -135,7 +120,9 @@ public:
 protected:
     void ensureHostGroup(const char * name);
     void ensurePlane(const char * plane);
-    IPropertyTree * processExternalFile(CDfsLogicalFileName & logicalFilename);
+    void ensureExternalPlane(const char * name, const char * host);
+    IPropertyTree * processExternal(CDfsLogicalFileName & logicalFilename);
+    void processExternalFile(CDfsLogicalFileName & logicalFilename);
     void processExternalPlane(CDfsLogicalFileName & logicalFilename);
     void processFile(IDistributedFile & file);
     void processFilename(CDfsLogicalFileName & logicalFilename);
@@ -159,8 +146,8 @@ void LogicalFileResolver::ensureHostGroup(const char * name)
     if (storage->hasProp(xpath))
         return;
 
-    IPropertyTree * hosts = queryHostGroup(name, true);
-    storage->addPropTreeArrayItem("hostGroups", LINK(hosts));
+    Owned<IPropertyTree> hosts = getHostGroup(name, true);
+    storage->addPropTreeArrayItem("hostGroups", hosts.getClear());
 }
 
 void LogicalFileResolver::ensurePlane(const char * name)
@@ -170,7 +157,7 @@ void LogicalFileResolver::ensurePlane(const char * name)
     if (storage->hasProp(xpath))
         return;
 
-    IPropertyTree * plane = queryStoragePlane(name);
+    Owned<IPropertyTree> plane = getStoragePlane(name);
     if (!plane)
         throw makeStringExceptionV(0, "No entry found for plane: '%s'", name);
 
@@ -179,20 +166,62 @@ void LogicalFileResolver::ensurePlane(const char * name)
 }
 
 
-IPropertyTree * LogicalFileResolver::processExternalFile(CDfsLogicalFileName & logicalFilename)
+void LogicalFileResolver::ensureExternalPlane(const char * name, const char * host)
+{
+    VStringBuffer xpath("planes[@name='%s']", name);
+    IPropertyTree * storage = ensurePTree(meta, "storage");
+    if (storage->hasProp(xpath))
+        return;
+
+    Owned<IPropertyTree> plane = createPTree("planes");
+    plane->setProp("@name", name);
+    plane->setProp("@hosts", name);
+    Owned<IPropertyTree> hostGroup = createPTree("hostGroups");
+    hostGroup->setProp("@name", name);
+    hostGroup->setProp("@hosts", name);
+    IPropertyTree * hosts = createPTree("hosts");
+    hosts->setProp("", host);
+    hostGroup->addPropTreeArrayItem("hosts", hosts);
+
+    storage->addPropTreeArrayItem("planes", plane.getClear());
+    storage->addPropTreeArrayItem("hostGroups", hostGroup.getClear());
+}
+
+
+IPropertyTree * LogicalFileResolver::processExternal(CDfsLogicalFileName & logicalFilename)
 {
     IPropertyTree * fileMeta = meta->addPropTree("file");
     fileMeta->setProp("@name", logicalFilename.get(false));
     fileMeta->setPropInt("@numParts", 1);
     fileMeta->setProp("@format", "unknown");
     fileMeta->setPropBool("@external", true);
+    fileMeta->setPropBool("@singlePartNoSuffix", true);
 
     return fileMeta;
 }
 
+void LogicalFileResolver::processExternalFile(CDfsLogicalFileName & logicalFilename)
+{
+    IPropertyTree * fileMeta = processExternal(logicalFilename);
+
+    //MORE: In the future we could go and grab the meta information from disk for a file and determine the number of parts etc.
+    //to provide an implicit multi part file import
+    if (options & ROincludeLocation)
+    {
+        StringBuffer hostName;
+        logicalFilename.getExternalHost(hostName);
+        StringBuffer planeName;
+        planeName.append("external_").append(hostName);
+        IPropertyTree * plane = createPTree("planes");
+        plane = fileMeta->addPropTreeArrayItem("planes", plane);
+        plane->setProp("", planeName);
+        ensureExternalPlane(planeName, hostName);
+    }
+}
+
 void LogicalFileResolver::processExternalPlane(CDfsLogicalFileName & logicalFilename)
 {
-    IPropertyTree * fileMeta = processExternalFile(logicalFilename);
+    IPropertyTree * fileMeta = processExternal(logicalFilename);
 
     //MORE: In the future we could go and grab the meta information from disk for a file and determine the number of parts etc.
     //to provide an implicit multi part file import
diff --git a/dali/base/dameta.hpp b/dali/base/dameta.hpp
index fada83b75..20b257f91 100644
--- a/dali/base/dameta.hpp
+++ b/dali/base/dameta.hpp
@@ -58,8 +58,8 @@ constexpr ResolveOptions operator &(ResolveOptions l, ResolveOptions r) { return
  */
 
 extern da_decl IPropertyTree * resolveLogicalFilenameFromDali(const char * filename, IUserDescriptor * user, ResolveOptions options);
-extern da_decl IPropertyTree * queryHostGroup(const char * name, bool required);
-extern da_decl IPropertyTree * queryStoragePlane(const char * name);
+extern da_decl IPropertyTree * getHostGroup(const char * name, bool required);
+extern da_decl IPropertyTree * getStoragePlane(const char * name);
 extern da_decl void normalizeHostGroups();  // Expand indirect hostGroups so each hostGroups has an expanded list of host names
 
 #endif
diff --git a/dali/base/dasess.cpp b/dali/base/dasess.cpp
index 8551badac..32fb11d87 100644
--- a/dali/base/dasess.cpp
+++ b/dali/base/dasess.cpp
@@ -1262,7 +1262,7 @@ class CCovenSessionManager: public CSessionManagerBase, implements ISessionManag
     Owned<IDaliLdapConnection> ldapconn;
     Owned<CLdapWorkItem> ldapworker;
     Semaphore ldapsig;
-    atomic_t ldapwaiting;
+    std::atomic<unsigned> ldapwaiting{0};
     Semaphore workthreadsem;
     bool stopping;
 
@@ -1293,7 +1293,6 @@ public:
     {
         mySessionId = queryCoven().getUniqueId(); // tell others in coven TBD
         registerSubscriptionManager(SESSION_PUBLISHER,this);
-        atomic_set(&ldapwaiting,0);
         workthreadsem.signal(10);
         stopping = false;
         ldapsig.signal();
@@ -1463,11 +1462,11 @@ public:
 #endif
         if ((ldapconn->getLDAPflags()&(DLF_SAFE|DLF_ENABLED))!=(DLF_SAFE|DLF_ENABLED))
             return ldapconn->getPermissions(key,obj,udesc,flags);
-        atomic_inc(&ldapwaiting);
+        ldapwaiting++;
         unsigned retries = 0;
         while (!stopping) {
             if (ldapsig.wait(1000)) {
-                atomic_dec(&ldapwaiting);
+                ldapwaiting--;
                 if (!ldapworker)
                     ldapworker.setown(CLdapWorkItem::get(ldapconn,workthreadsem));
                 if (ldapworker) {
@@ -1489,7 +1488,7 @@ public:
                                 return ret;
                             }
                         }
-                        if (atomic_read(&ldapwaiting)>10)   // give up quicker if piling up
+                        if (ldapwaiting>10)   // give up quicker if piling up
                             break;
                         if (i==5) { // one retry
                             ldapworker->stop(); // abandon thread
@@ -1510,7 +1509,7 @@ public:
                 return SecAccess_None;
             }
             else {
-                unsigned waiting = atomic_read(&ldapwaiting);
+                unsigned waiting = ldapwaiting;
                 static unsigned last=0;
                 static unsigned lasttick=0;
                 static unsigned first50=0;
@@ -1533,7 +1532,7 @@ public:
                     first50 = 0;
             }
         }
-        atomic_dec(&ldapwaiting);
+        ldapwaiting--;
         return SecAccess_None;
 #endif
     }
diff --git a/dali/base/dautils.cpp b/dali/base/dautils.cpp
index 6cf5fb9a5..b2d9672af 100644
--- a/dali/base/dautils.cpp
+++ b/dali/base/dautils.cpp
@@ -55,7 +55,7 @@ IPropertyTreeIterator * getDropZonePlanesIterator(const char * name)
     StringBuffer xpath(lz_plane_path);
     if (!isEmptyString(name))
         xpath.appendf("[@name='%s']", name);
-    return queryGlobalConfig().getElements(xpath);
+    return getGlobalConfigSP()->getElements(xpath);
 }
 IPropertyTree * getDropZonePlane(const char * name)
 {
@@ -63,7 +63,7 @@ IPropertyTree * getDropZonePlane(const char * name)
         throw makeStringException(-1, "Drop zone name required");
     StringBuffer xpath(lz_plane_path);
     xpath.appendf("[@name='%s']", name);
-    return queryGlobalConfig().getPropTree(xpath);
+    return getGlobalConfigSP()->getPropTree(xpath);
 }
 
 extern da_decl const char *queryDfsXmlBranchName(DfsXmlBranchKind kind)
@@ -323,6 +323,24 @@ bool CDfsLogicalFileName::getExternalPlane(StringBuffer & plane) const
 }
 
 
+bool CDfsLogicalFileName::isExternalFile() const
+{
+    return external && startsWithIgnoreCase(lfn, EXTERNAL_SCOPE "::");
+}
+
+bool CDfsLogicalFileName::getExternalHost(StringBuffer & host) const
+{
+    if (!isExternalFile())
+        return false;
+
+    const char * start = lfn.str() + strlen(EXTERNAL_SCOPE "::");
+    const char * end = strstr(start,"::");
+    assertex(end);
+    host.append(end-start, start);
+    return true;
+}
+
+
 void CDfsLogicalFileName::set(const CDfsLogicalFileName &other)
 {
     lfn.set(other.lfn);
@@ -435,6 +453,94 @@ void normalizeNodeName(const char *node, unsigned len, SocketEndpoint &ep, bool
     ep.set(nodename.str());
 }
 
+
+//s points to the second "::" in the external filename (file::ip or plane::<plane>::)
+bool expandExternalPath(StringBuffer &dir, StringBuffer &tail, const char * filename, const char * s, bool iswin, IException **e)
+{
+    if (e)
+        *e = NULL;
+    if (!s) {
+        if (e)
+            *e = MakeStringException(-1,"Invalid format for external file (%s)",filename);
+        return false;
+    }
+    if (s[2]=='>') {
+        dir.append('/');
+        tail.append(s+2);
+        return true;
+    }
+
+    // check for ::c$/
+    if (iswin&&(s[3]=='$'))
+        s += 2;                 // no leading '\'
+    const char *s1=s;
+    const char *t1=NULL;
+    for (;;) {
+        s1 = strstr(s1,"::");
+        if (!s1)
+            break;
+        t1 = s1;
+        s1 = s1+2;
+    }
+    //The following code is never actually executed, since s always points at the leading '::'
+    if (!t1||!*t1) {
+        if (e)
+            *e = MakeStringException(-1,"No directory specified in external file name (%s)",filename);
+        return false;
+    }
+    size32_t odl = dir.length();
+    bool start=true;
+    while (s!=t1) {
+        char c=*(s++);
+        if (isPathSepChar(c)) {
+            if (e)
+                *e = MakeStringException(-1,"Path cannot contain separators, use '::' to separate directories: (%s)",filename);
+            return false;
+        }
+        if ((c==':')&&(s!=t1)&&(*s==':')) {
+            dir.append(iswin?'\\':'/');
+            s++;
+            //Disallow ::..:: to gain access to parent subdirectories
+            if (strncmp(s, "..::", 4) == 0)
+            {
+                if (e)
+                    *e = MakeStringException(-1,"External filename cannot contain relative path '..' (%s)", filename);
+                return false;
+            }
+        }
+        else if (c==':') {
+            if (e)
+                *e = MakeStringException(-1,"Path cannot contain single ':', use 'c$' to indicate 'c:' (%s)",filename);
+            return false;
+        }
+        else if (iswin&&start&&(s!=t1)&&(*s=='$')) {
+            dir.append(c).append(':');
+            s++;
+        }
+        else {
+            if ((c=='^')&&(s!=t1)) {
+                c = toupper(*s);
+                s++;
+            }
+            dir.append(c);
+        }
+        start = false;
+    }
+    t1+=2; // skip ::
+    //Always ensure there is a // - if not directory is provided it will be in the root
+    if ((dir.length()==0)||(!isPathSepChar(dir.charAt(dir.length()-1))))
+        dir.append(iswin?'\\':'/');
+    while (*t1) {
+        char c = *(t1++);
+        if ((c=='^')&&*t1) {
+            c = toupper(*t1);
+            t1++;
+        }
+        tail.append(c);
+    }
+    return true;
+}
+
 void CDfsLogicalFileName::normalizeName(const char *name, StringAttr &res, bool strict)
 {
     // NB: If !strict(default) allows spaces to exist either side of scopes (no idea why would want to permit that, but preserving for bwrd compat.)
@@ -1197,7 +1303,6 @@ bool CDfsLogicalFileName::getExternalPath(StringBuffer &dir, StringBuffer &tail,
     if (multi)
         DBGLOG("CDfsLogicalFileName::makeFullnameQuery called on multi-lfn %s",get());
 
-    size32_t odl = dir.length();
     const char *s = skipScope(lfn,EXTERNAL_SCOPE);
     if (s)
     {
@@ -1231,83 +1336,7 @@ bool CDfsLogicalFileName::getExternalPath(StringBuffer &dir, StringBuffer &tail,
             }
         }
     }
-    if (!s) {
-        if (e)
-            *e = MakeStringException(-1,"Invalid format for external file (%s)",get());
-        return false;
-    }
-    if (s[2]=='>') {
-        dir.append('/');
-        tail.append(s+2);
-        return true;
-    }
-
-    // check for ::c$/
-    if (iswin&&(s[3]=='$'))
-        s += 2;                 // no leading '\'
-    const char *s1=s;
-    const char *t1=NULL;
-    for (;;) {
-        s1 = strstr(s1,"::");
-        if (!s1)
-            break;
-        t1 = s1;
-        s1 = s1+2;
-    }
-    if (!t1||!*t1) {
-        if (e)
-            *e = MakeStringException(-1,"No directory specified in external file name (%s)",get());
-        return false;
-    }
-    bool start=true;
-    while (s!=t1) {
-        char c=*(s++);
-        if (isPathSepChar(c)) {
-            if (e)
-                *e = MakeStringException(-1,"Path cannot contain separators, use '::' to separate directories: (%s)",get());
-            return false;
-        }
-        if ((c==':')&&(s!=t1)&&(*s==':')) {
-            dir.append(iswin?'\\':'/');
-            s++;
-            //Disallow ::..:: to gain access to parent subdirectories
-            if (strncmp(s, "..::", 4) == 0)
-            {
-                if (e)
-                    *e = MakeStringException(-1,"External filename cannot contain relative path '..' (%s)", get());
-                return false;
-            }
-        }
-        else if (c==':') {
-            if (e)
-                *e = MakeStringException(-1,"Path cannot contain single ':', use 'c$' to indicate 'c:' (%s)",get());
-            return false;
-        }
-        else if (iswin&&start&&(s!=t1)&&(*s=='$')) {
-            dir.append(c).append(':');
-            s++;
-        }
-        else {
-            if ((c=='^')&&(s!=t1)) {
-                c = toupper(*s);
-                s++;
-            }
-            dir.append(c);
-        }
-        start = false;
-    }
-    t1+=2; // skip ::
-    if ((dir.length()!=odl)&&(!isPathSepChar(dir.charAt(dir.length()-1))))
-        dir.append(iswin?'\\':'/');
-    while (*t1) {
-        char c = *(t1++);
-        if ((c=='^')&&*t1) {
-            c = toupper(*t1);
-            t1++;
-        }
-        tail.append(c);
-    }
-    return true;
+    return expandExternalPath(dir, tail, get(), s, iswin, e);
 }
 
 bool CDfsLogicalFileName::getExternalFilename(RemoteFilename &rfn) const
@@ -3165,7 +3194,7 @@ public:
         return dfile.get(); 
     }
 
-    bool init(const char *fname,IUserDescriptor *user,bool onlylocal,bool onlydfs, bool write, bool isPrivilegedUser)
+    bool init(const char *fname,IUserDescriptor *user,bool onlylocal,bool onlydfs, bool write, bool isPrivilegedUser, const StringArray *clusters)
     {
         fileExists = false;
         if (!onlydfs)
@@ -3216,9 +3245,24 @@ public:
                 if (dfile.get())
                     return true;
             }
+
+            StringBuffer dir;
+#ifdef _CONTAINERIZED
+            StringBuffer cluster;
+            if (clusters)
+            {
+                if (clusters->ordinality()>1)
+                    throw makeStringExceptionV(0, "Container mode does not yet support output to multiple clusters while writing file %s)", fname);
+                cluster.append(clusters->item(0));
+            }
+            else
+                getDefaultStoragePlane(cluster);
+            Owned<IStoragePlane> plane = getStoragePlane(cluster, true);
+            dir.append(plane->queryPrefix());
+#endif
             // MORE - should we create the IDistributedFile here ready for publishing (and/or to make sure it's locked while we write)?
             StringBuffer physicalPath;
-            makePhysicalPartName(lfn.get(), 1, 1, physicalPath, false); // more - may need to override path for roxie
+            makePhysicalPartName(lfn.get(), 1, 1, physicalPath, false, DFD_OSdefault, dir); // more - may need to override path for roxie
             localpath.set(physicalPath);
             fileExists = (dfile != NULL);
             return write;
@@ -3364,10 +3408,10 @@ public:
 
 };
 
-ILocalOrDistributedFile* createLocalOrDistributedFile(const char *fname,IUserDescriptor *user,bool onlylocal,bool onlydfs, bool iswrite, bool isPrivilegedUser)
+ILocalOrDistributedFile* createLocalOrDistributedFile(const char *fname,IUserDescriptor *user,bool onlylocal,bool onlydfs, bool iswrite, bool isPrivilegedUser, const StringArray *clusters)
 {
     Owned<CLocalOrDistributedFile> ret = new CLocalOrDistributedFile();
-    if (ret->init(fname,user,onlylocal,onlydfs,iswrite,isPrivilegedUser))
+    if (ret->init(fname,user,onlylocal,onlydfs,iswrite,isPrivilegedUser,clusters))
         return ret.getClear();
     return NULL;
 }
diff --git a/dali/base/dautils.hpp b/dali/base/dautils.hpp
index bf6c0a547..ba9493356 100644
--- a/dali/base/dautils.hpp
+++ b/dali/base/dautils.hpp
@@ -95,6 +95,8 @@ public:
     bool isExternal() const { return external; }
     bool isExternalPlane() const;
     bool getExternalPlane(StringBuffer & plane) const;
+    bool isExternalFile() const;
+    bool getExternalHost(StringBuffer & host) const;
     /*
      * Multi files are temporary SuperFiles only. SuperFiles created
      * by the user do not fit into this category and are created
@@ -154,14 +156,14 @@ protected:
 class da_decl CTransactionLogTracker
 {
     unsigned max;
-    atomic_t *counts;
+    std::atomic<unsigned> * counts;
 public:
     CTransactionLogTracker(int _max) : max(_max)
     {
-        counts = new atomic_t[max+1]; // +1 reserve for unknown commands
+        counts = new std::atomic<unsigned>[max+1]; // +1 reserve for unknown commands
         unsigned t=0;
         for (; t<=max; t++)
-            atomic_set(&counts[t],0);
+            counts[t] = 0;
     }
     ~CTransactionLogTracker()
     {
@@ -170,15 +172,15 @@ public:
     inline const unsigned &getMax() const { return max; }
     inline void startTransaction(unsigned cmd)
     {
-        atomic_inc(&counts[cmd]);
+        counts[cmd]++;
     }
     inline void endTransaction(unsigned cmd)
     {
-        atomic_dec(&counts[cmd]);
+        counts[cmd]--;
     }
     unsigned getTransactionCount(unsigned cmd) const
     {
-        return (unsigned)atomic_read(&counts[cmd]);
+        return counts[cmd].load();
     }
     virtual StringBuffer &getCmdText(unsigned cmd, StringBuffer &ret) const = 0;
 };
@@ -442,7 +444,7 @@ interface ILocalOrDistributedFile: extends IInterface
     virtual bool isExternal() const = 0;
 };
 
-extern da_decl ILocalOrDistributedFile* createLocalOrDistributedFile(const char *fname,IUserDescriptor *user,bool onlylocal,bool onlydfs,bool iswrite, bool isPrivilegedUser);
+extern da_decl ILocalOrDistributedFile* createLocalOrDistributedFile(const char *fname,IUserDescriptor *user,bool onlylocal,bool onlydfs,bool iswrite, bool isPrivilegedUser, const StringArray *clusters);
 
 typedef __int64 ConnectionId;
 
@@ -539,5 +541,6 @@ extern da_decl IPropertyTree * getDropZonePlane(const char * name);
 extern da_decl void setPageCacheTimeoutMilliSeconds(unsigned timeoutSeconds);
 extern da_decl void setMaxPageCacheItems(unsigned _maxPageCacheItems);
 extern da_decl IRemoteConnection* connectXPathOrFile(const char* path, bool safe, StringBuffer& xpath);
+extern da_decl bool expandExternalPath(StringBuffer &dir, StringBuffer &tail, const char * filename, const char * s, bool iswin, IException **e);
 
 #endif
diff --git a/dali/daliadmin/daadmin.cpp b/dali/daliadmin/daadmin.cpp
index b8180a297..5b6c5131c 100644
--- a/dali/daliadmin/daadmin.cpp
+++ b/dali/daliadmin/daadmin.cpp
@@ -476,9 +476,8 @@ unsigned count(const char *path)
 
 //=============================================================================
 
-void dfsfile(const char *lname,IUserDescriptor *userDesc, UnsignedArray *partslist)
+bool dfsfile(const char *lname, IUserDescriptor *userDesc, StringBuffer &out, UnsignedArray *partslist)
 {
-    StringBuffer str;
     CDfsLogicalFileName lfn;
     lfn.set(lname);
     if (!lfn.isExternal()) {
@@ -486,11 +485,10 @@ void dfsfile(const char *lname,IUserDescriptor *userDesc, UnsignedArray *partsli
         if (partslist)
             filterParts(tree,*partslist);
         if (!tree) {
-            UERRLOG("%s not found",lname);
-            return;
+            out.appendf("%s not found",lname);
+            return false;
         }
-        toXML(tree, str);
-        outln(str.str());
+        toXML(tree,out);
     }
     else {
         Owned<IDistributedFile> file = queryDistributedFileDirectory().lookup(lname,userDesc,false,false,false,nullptr,defaultPrivilegedUser);
@@ -499,19 +497,19 @@ void dfsfile(const char *lname,IUserDescriptor *userDesc, UnsignedArray *partsli
             Owned<IPropertyTree> t = createPTree("File");
             fdesc->serializeTree(*t);
             filterParts(t,*partslist);
-            toXML(t, str.clear());
-            outln(str.str());
+            toXML(t,out);
         }
     }
+    return true;
 }
 
 //=============================================================================
 
-void dfspart(const char *lname,IUserDescriptor *userDesc, unsigned partnum)
+bool dfspart(const char *lname, IUserDescriptor *userDesc, unsigned partnum, StringBuffer &out)
 {
     UnsignedArray partslist;
     partslist.append(partnum);
-    dfsfile(lname,userDesc,&partslist);
+    return dfsfile(lname,userDesc,out,&partslist);
 }
 
 //=============================================================================
@@ -529,7 +527,7 @@ void dfsmeta(const char *filename,IUserDescriptor *userDesc, bool includeStorage
 
 //=============================================================================
 
-void setdfspartattr(const char *lname, unsigned partNum, const char *attr, const char *value, IUserDescriptor *userDesc)
+void setdfspartattr(const char *lname, unsigned partNum, const char *attr, const char *value, IUserDescriptor *userDesc, StringBuffer &out)
 {
     StringBuffer str;
     CDfsLogicalFileName lfn;
@@ -559,35 +557,31 @@ void setdfspartattr(const char *lname, unsigned partNum, const char *attr, const
     if (value)
     {
         part.queryAttributes().setProp(attrProp.str(), value);
-        PROGLOG("Set property '%s' to '%s' for file %s, part# %u", attrProp.str(), value, lname, partNum);
+        out.appendf("Set property '%s' to '%s' for file %s, part# %u", attrProp.str(), value, lname, partNum);
     }
     else
     {
         part.queryAttributes().removeProp(attrProp.str());
-        PROGLOG("Removed property '%s' from file %s, part# %u", attrProp.str(), lname, partNum);
+        out.appendf("Removed property '%s' from file %s, part# %u", attrProp.str(), lname, partNum);
     }
     part.unlockProperties();
 
     if (oldValue)
-        PROGLOG("Prev. value = '%s'", oldValue);
+        out.appendf("\nPrev. value = '%s'", oldValue);
 }
 
 //=============================================================================
 
-void dfscsv(const char *dali,IUserDescriptor *udesc)
+void dfscsv(const char *logicalNameMask,IUserDescriptor *udesc,StringBuffer &out)
 {
 
     const char *fields[] = {
         "name","group","directory","partmask","modified","job","owner","workunit","numparts","size","recordCount","recordSize","compressedSize",NULL
     };
+    const char *mask = isEmptyString(logicalNameMask) ? "*" : logicalNameMask;
 
-    Owned<INode> foreigndali;
-    if (dali&&*dali&&(*dali!='*')) {
-        SocketEndpoint ep(dali,DALI_SERVER_PORT);
-        foreigndali.setown(createINode(ep));
-    }
     unsigned start = msTick();
-    IDFAttributesIterator *iter = queryDistributedFileDirectory().getDFAttributesIterator("*",udesc,true,false,foreigndali);
+    IDFAttributesIterator *iter = queryDistributedFileDirectory().getDFAttributesIterator(mask,udesc,true,false,nullptr);
     StringBuffer ln;
     unsigned i;
     for (i=0;fields[i];i++) {
@@ -595,7 +589,7 @@ void dfscsv(const char *dali,IUserDescriptor *udesc)
             ln.append(',');
         ln.append('"').append(fields[i]).append('"');
     }
-    outln(ln.str());
+    out.append(ln);
     if (iter) {
         StringBuffer aname;
         StringBuffer vals;
@@ -614,7 +608,7 @@ void dfscsv(const char *dali,IUserDescriptor *udesc)
                         val++;
                     }
             }
-            outln(ln.str());
+            out.append("\n").append(ln);
         }
     }
 }
@@ -645,41 +639,40 @@ static void writeGroup(IGroup *group, const char *name, const char *outputFilena
     }
 }
 
-unsigned dfsCheck(StringBuffer & path, IPropertyTree * tree)
+void dfsCheck(StringBuffer & path, IPropertyTree * tree, StringBuffer &out)
 {
     const char * name = tree->queryProp("@name");
     //MORE: What other consistency checks can be added here?
     if (tree->hasProp("Attr[2]"))
     {
-        printf("%s%s - duplicate Attr tag\n", path.str(), name ? name : "");
-        return 1;
+        out.appendf("%s%s - duplicate Attr tag\n", path.str(), name ? name : "");
+        return;
     }
 
-    unsigned issues = 0;
     unsigned prevLength = path.length();
     if (name)
         path.append(name).append("::");
     Owned<IPropertyTreeIterator> elems = tree->getElements("*");
     ForEach(*elems)
     {
-        issues += dfsCheck(path, &elems->query());
+        dfsCheck(path, &elems->query(), out);
     }
     path.setLength(prevLength);
-    return issues;
 }
 
-void dfsCheck()
+bool dfsCheck(StringBuffer &out)
 {
     StringBuffer xpath;
     Owned<IRemoteConnection> conn = querySDS().connect("Files",myProcessSession(),0, daliConnectTimeoutMs);
     if (!conn)
     {
-        UERRLOG("Could not connect to %s","/Files");
-        return;
+        out.append("Could not connect to /Files");
+        return false;
     }
 
     StringBuffer path;
-    dfsCheck(path, conn->queryRoot());
+    dfsCheck(path, conn->queryRoot(), out);
+    return true;
 }
 
 
@@ -748,7 +741,7 @@ static IPropertyTree * selectPath(IPropertyTree * root, const char * path)
     return selectLevel(root, path);
 }
 
-static void displayDirectory(IPropertyTree * directory, const char * options, unsigned depth)
+static void displayDirectory(IPropertyTree * directory, const char * options, unsigned depth, StringBuffer &out)
 {
     Owned<IPropertyTreeIterator> elems = directory->getElements("*");
     ForEach(*elems)
@@ -761,66 +754,67 @@ static void displayDirectory(IPropertyTree * directory, const char * options, un
         {
             if (strieq(tag, "Scope"))
             {
-                OUTLOG("%*sD %s", depth, "", name);
+                out.appendf("%*sD %s\n", depth, "", name);
                 if (options && strchr(options, 'r'))
-                    displayDirectory(&cur, options, depth+1);
+                    displayDirectory(&cur, options, depth+1, out);
             }
             else if (strieq(tag, "File"))
             {
                 const char * group = cur.queryProp("@group");
                 const char * size = cur.queryProp("Attr[1]/@size");
                 if (options && strchr(options, 'l'))
-                    OUTLOG("%*s  %-30s %12s %s %s", depth, "", name, size ? size : "", group ? group : "?", modified ? modified : "");
+                    out.appendf("%*s  %-30s %12s %s %s\n", depth, "", name, size ? size : "", group ? group : "?", modified ? modified : "");
                 else
-                    OUTLOG("%*s  %s", depth, "", name);
+                    out.appendf("%*s  %s\n", depth, "", name);
             }
             else if (strieq(tag, "SuperFile"))
             {
                 if (options && strchr(options, 'l'))
-                    OUTLOG("%*sS %s %s (%d)", depth, "", name, modified ? modified : "", cur.getPropInt("@numsubfiles"));
+                    out.appendf("%*sS %s %s (%d)\n", depth, "", name, modified ? modified : "", cur.getPropInt("@numsubfiles"));
                 else
-                    OUTLOG("%*sS %s", depth, "", name);
+                    out.appendf("%*sS %s\n", depth, "", name);
 
                 if (options && strchr(options, 's'))
                 {
                     Owned<IPropertyTreeIterator> subs = cur.getElements("SubFile");
                     ForEach(*subs)
                     {
-                        OUTLOG("%*s->%s", depth, "", subs->query().queryProp("@name"));
+                        out.appendf("%*s->%s\n", depth, "", subs->query().queryProp("@name"));
                     }
                 }
             }
             else
-                OUTLOG("? %s %s", name, tag);
+                out.appendf("? %s %s\n", name, tag);
         }
     }
 }
 
-void dfsLs(const char *name, const char *options, bool safe)
+bool dfsLs(const char *name, const char *options, StringBuffer &out)
 {
     StringBuffer xpath;
     Owned<IRemoteConnection> conn = querySDS().connect("Files",myProcessSession(),0, daliConnectTimeoutMs);
     if (!conn)
     {
-        UERRLOG("Could not connect to %s","/Files");
-        return;
+        out.append("Could not connect to /Files");
+        return false;
     }
 
     {
         Owned<IPropertyTree> directory = selectPath(conn->queryRoot(), name);
         if (directory)
-            displayDirectory(directory, options, 0);
+            displayDirectory(directory, options, 0, out);
     }
+    return true;
 }
 
 //=============================================================================
 
-void dfsmap(const char *lname, IUserDescriptor *user)
+bool dfsmap(const char *lname, IUserDescriptor *user, StringBuffer &out)
 {
     Owned<IDistributedFile> file = queryDistributedFileDirectory().lookup(lname,user,false,false,false,nullptr,defaultPrivilegedUser);
     if (!file) {
-        UERRLOG("File %s not found",lname);
-        return;
+        out.appendf("File %s not found",lname);
+        return false;
     }
     Owned<IDistributedFilePartIterator> pi = file->getIterator();
     unsigned pn=1;
@@ -835,9 +829,10 @@ void dfsmap(const char *lname, IUserDescriptor *user)
                 ln.append(", ");
             rfn.getRemotePath(ln);
         }
-        outln(ln.str());
+        out.append(ln).append("\n");
         pn++;
     }
+    return true;
 }
 
 //=============================================================================
@@ -848,13 +843,13 @@ int dfsexists(const char *lname,IUserDescriptor *user)
 }
 //=============================================================================
 
-void dfsparents(const char *lname, IUserDescriptor *user)
+void dfsparents(const char *lname, IUserDescriptor *user, StringBuffer &out)
 {
     Owned<IDistributedFile> file = queryDistributedFileDirectory().lookup(lname,user,false,false,true,nullptr,defaultPrivilegedUser);
     if (file) {
         Owned<IDistributedSuperFileIterator> iter = file->getOwningSuperFiles();
         ForEach(*iter) 
-            OUTLOG("%s,%s",iter->query().queryLogicalName(),lname);
+            out.appendf("%s,%s\n",iter->query().queryLogicalName(),lname);
     }
 }
 
diff --git a/dali/daliadmin/daadmin.hpp b/dali/daliadmin/daadmin.hpp
index e719dccbd..b9d121f0a 100644
--- a/dali/daliadmin/daadmin.hpp
+++ b/dali/daliadmin/daadmin.hpp
@@ -43,18 +43,18 @@ extern DALIADMIN_API bool add(const char *path, const char *val, StringBuffer &o
 extern DALIADMIN_API void delv(const char *path);
 extern DALIADMIN_API unsigned count(const char *path);
 
-extern DALIADMIN_API void dfsfile(const char *lname, IUserDescriptor *userDesc, UnsignedArray *partslist = nullptr);
-extern DALIADMIN_API void dfspart(const char *lname,IUserDescriptor *userDesc, unsigned partnum);
+extern DALIADMIN_API bool dfsfile(const char *lname, IUserDescriptor *userDesc, StringBuffer &out, UnsignedArray *partslist = nullptr);
+extern DALIADMIN_API bool dfspart(const char *lname,IUserDescriptor *userDesc, unsigned partnum, StringBuffer &out);
 extern DALIADMIN_API void dfsmeta(const char *filename,IUserDescriptor *userDesc, bool includeStorage);
-extern DALIADMIN_API void setdfspartattr(const char *lname, unsigned partNum, const char *attr, const char *value, IUserDescriptor *userDesc);
-extern DALIADMIN_API void dfscsv(const char *dali, IUserDescriptor *udesc);
-extern DALIADMIN_API void dfsCheck();
+extern DALIADMIN_API void setdfspartattr(const char *lname, unsigned partNum, const char *attr, const char *value, IUserDescriptor *userDesc, StringBuffer &out);
+extern DALIADMIN_API void dfscsv(const char *dali, IUserDescriptor *udesc, StringBuffer &out);
+extern DALIADMIN_API bool dfsCheck(StringBuffer &out);
 extern DALIADMIN_API void dfsGroup(const char *name, const char *outputFilename);
 extern DALIADMIN_API int clusterGroup(const char *name, const char *outputFilename);
-extern DALIADMIN_API void dfsLs(const char *name, const char *options, bool safe = false);
-extern DALIADMIN_API void dfsmap(const char *lname, IUserDescriptor *user);
+extern DALIADMIN_API bool dfsLs(const char *name, const char *options, StringBuffer &out);
+extern DALIADMIN_API bool dfsmap(const char *lname, IUserDescriptor *user, StringBuffer &out);
 extern DALIADMIN_API int dfsexists(const char *lname, IUserDescriptor *user);
-extern DALIADMIN_API void dfsparents(const char *lname, IUserDescriptor *user);
+extern DALIADMIN_API void dfsparents(const char *lname, IUserDescriptor *user, StringBuffer &out);
 extern DALIADMIN_API void dfsunlink(const char *lname, IUserDescriptor *user);
 extern DALIADMIN_API int dfsverify(const char *name, CDateTime *cutoff, IUserDescriptor *user);
 extern DALIADMIN_API int dfsperm(const char *obj, IUserDescriptor *user);
diff --git a/dali/daliadmin/daliadmin.cpp b/dali/daliadmin/daliadmin.cpp
index 295975ac1..1526cf1b4 100644
--- a/dali/daliadmin/daliadmin.cpp
+++ b/dali/daliadmin/daliadmin.cpp
@@ -136,7 +136,7 @@ int main(int argc, const char* argv[])
         return -1;
     }
 
-    Owned<IPropertyTree> globals = loadConfiguration(defaultYaml, argv, "daliadmin", "DALIADMIN", "daliadmin.xml", nullptr);
+    Owned<IPropertyTree> globals = loadConfiguration(defaultYaml, argv, "daliadmin", "DALIADMIN", "daliadmin.xml", nullptr, nullptr, false);
     Owned<IProperties> props = createProperties("daliadmin.ini");
     StringArray params;
     SocketEndpoint ep;
@@ -314,7 +314,7 @@ int main(int argc, const char* argv[])
                     }
                     else if (strieq(cmd,"dfsfile")) {
                         CHECKPARAMS(1,1);
-                        dfsfile(params.item(1),userDesc);
+                        doLog(dfsfile(params.item(1),userDesc,out),out);
                     }
                     else if (strieq(cmd,"dfsmeta")) {
                         CHECKPARAMS(1,3);
@@ -323,19 +323,21 @@ int main(int argc, const char* argv[])
                     }
                     else if (strieq(cmd,"dfspart")) {
                         CHECKPARAMS(2,2);
-                        dfspart(params.item(1),userDesc,atoi(params.item(2)));
+                        doLog(dfspart(params.item(1),userDesc,atoi(params.item(2)),out),out);                        
                     }
                     else if (strieq(cmd,"setdfspartattr")) {
                         CHECKPARAMS(3,4);
-                        setdfspartattr(params.item(1), atoi(params.item(2)), params.item(3), np>3 ? params.item(4) : nullptr, userDesc);
+                        setdfspartattr(params.item(1),atoi(params.item(2)),params.item(3),np>3?params.item(4):nullptr,userDesc,out);
+                        PROGLOG("%s", out.str());
                     }
                     else if (strieq(cmd,"dfscheck")) {
                         CHECKPARAMS(0,0);
-                        dfsCheck();
+                        doLog(dfsCheck(out),out);
                     }
                     else if (strieq(cmd,"dfscsv")) {
                         CHECKPARAMS(1,1);
-                        dfscsv(params.item(1),userDesc);
+                        dfscsv(params.item(1),userDesc,out);
+                        PROGLOG("%s",out.str());
                     }
                     else if (strieq(cmd,"dfsgroup")) {
                         CHECKPARAMS(1,2);
@@ -347,11 +349,11 @@ int main(int argc, const char* argv[])
                     }
                     else if (strieq(cmd,"dfsls")) {
                         CHECKPARAMS(0,2);
-                        dfsLs((np>0)?params.item(1):NULL,(np>1)?params.item(2):NULL);
+                        doLog(dfsLs((np>0)?params.item(1):nullptr,(np>1)?params.item(2):nullptr,out),out);
                     }
                     else if (strieq(cmd,"dfsmap")) {
                         CHECKPARAMS(1,1);
-                        dfsmap(params.item(1), userDesc);
+                        doLog(dfsmap(params.item(1),userDesc,out),out);
                     }
                     else if (strieq(cmd,"dfsexists") || strieq(cmd,"dfsexist")) {
                         // NB: "dfsexist" typo', kept for backward compatibility only (<7.12)
@@ -360,7 +362,8 @@ int main(int argc, const char* argv[])
                     }
                     else if (strieq(cmd,"dfsparents")) {
                         CHECKPARAMS(1,1);
-                        dfsparents(params.item(1),userDesc);
+                        dfsparents(params.item(1),userDesc,out);
+                        PROGLOG("%s",out.str());
                     }
                     else if (strieq(cmd,"dfsunlink")) {
                         CHECKPARAMS(1,1);
diff --git a/dali/dfu/dfurepl.cpp b/dali/dfu/dfurepl.cpp
index ec9435057..e9a367d54 100644
--- a/dali/dfu/dfurepl.cpp
+++ b/dali/dfu/dfurepl.cpp
@@ -415,7 +415,8 @@ bool ReplicatePartCopyItem::doneCopy(unsigned timeout)
                 0,
                 (offset_t)-1, // all file
                 NULL, // no progress needed (yet)
-                timeout))
+                timeout,
+                CFflush_rdwr))
                     state = RPCS_tempcopied;  // done
         }
         catch (IException *e) {
diff --git a/dali/dfu/dfurun.cpp b/dali/dfu/dfurun.cpp
index 05411b8c0..f981ecdde 100644
--- a/dali/dfu/dfurun.cpp
+++ b/dali/dfu/dfurun.cpp
@@ -533,7 +533,7 @@ class CDFUengine: public CInterface, implements IDFUengine
 
     CriticalSection monitorsect;
     CriticalSection subcopysect;
-    atomic_t runningflag;
+    std::atomic<unsigned> runningflag;
 
 public:
     IMPLEMENT_IINTERFACE;
@@ -541,7 +541,7 @@ public:
     CDFUengine()
     {
         defaultTransferBufferSize = 0;
-        atomic_set(&runningflag,1);
+        runningflag = 1;
         eventpusher.setown(getScheduleEventPusher());
     }
 
@@ -1069,12 +1069,12 @@ public:
         // only clear cache when nothing running (bit of a kludge)
         class CenvClear
         {
-            atomic_t &running;
+            std::atomic<unsigned> &running;
         public:
-            CenvClear(atomic_t &_running)
+            CenvClear(std::atomic<unsigned> &_running)
                 : running(_running)
             {
-                if (atomic_dec_and_test(&running)) {
+                if (--running == 0) {
                     Owned<IEnvironmentFactory> envf = getEnvironmentFactory(false);
                     Owned<IConstEnvironment> env = envf->openEnvironment();
                     env->clearCache();
@@ -1082,7 +1082,7 @@ public:
             }
             ~CenvClear()
             {
-                atomic_inc(&running);
+                ++running;
             }
         } cenvclear(runningflag);
         Owned<IDFUWorkUnitFactory> factory = getDFUWorkUnitFactory();
diff --git a/dali/dfu/dfuserver.cpp b/dali/dfu/dfuserver.cpp
index 660bac85e..ba205bf10 100644
--- a/dali/dfu/dfuserver.cpp
+++ b/dali/dfu/dfuserver.cpp
@@ -46,7 +46,6 @@
 #include "dfuerror.hpp"
 #include "daqueue.hpp"
 
-static Owned<IPropertyTree> globals;
 ILogMsgHandler * fileMsgHandler;
 Owned<IDFUengine> engine;
 
@@ -109,20 +108,15 @@ dfuserver:
 
 int main(int argc, const char *argv[])
 {
-    for (unsigned i=0;i<(unsigned)argc;i++) {
-        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-            if (daemon(1,0) || write_pidfile(argv[++i])) {
-                perror("Failed to daemonize");
-                return EXIT_FAILURE;
-            }
-            break;
-        }
-    }
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
+
     InitModuleObjects();
     EnableSEHtoExceptionMapping();
 
     NoQuickEditSection xxx;
 
+    Owned<IPropertyTree> globals;
     try
     {
         globals.setown(loadConfiguration(defaultYaml, argv, "dfuserver", "DFUSERVER", "dfuserver.xml", nullptr));
diff --git a/dali/dfu/dfuutil.cpp b/dali/dfu/dfuutil.cpp
index d2ec91672..0f1f4fe04 100644
--- a/dali/dfu/dfuutil.cpp
+++ b/dali/dfu/dfuutil.cpp
@@ -69,7 +69,8 @@ static bool physicalPartCopy(IFile *from,const char *tofile, Owned<IException> &
                 0,
                 (offset_t)-1, // all file
                 NULL,
-                PHYSICAL_COPY_POLL_TIME)) {
+                PHYSICAL_COPY_POLL_TIME,
+                CFflush_rdwr)) {
             // Abort check TBD
         }
     }
@@ -1265,11 +1266,17 @@ public:
     {
         DBGLOG("cloneRoxieSubFile src=%s@%s, dst=%s@%s, prefix=%s, ow=%d, docopy=false", srcLFN, srcCluster, dstLFN, dstCluster, prefix, overwriteFlags);
         CFileCloner cloner;
-        cloner.init(dstCluster, DFUcpdm_c_replicated_by_d, true, NULL, userdesc, foreigndali, NULL, NULL, false, false);
+        bool copyPhysical = false;
+        // MORE: Would the following be better to ensure files are copied when queries are deployed?
+        // bool copyPhysical = isContainerized() && (foreigndali != nullptr);
+        cloner.init(dstCluster, DFUcpdm_c_replicated_by_d, true, NULL, userdesc, foreigndali, NULL, NULL, false, copyPhysical);
         cloner.overwriteFlags = overwriteFlags;
+#ifndef _CONTAINERIZED
+        //In containerized mode there is no need to replicate files to the local disks of the roxie cluster - so don't set the special flag
         cloner.spec1.setRoxie(redundancy, channelsPerNode, replicateOffset);
         if (defReplicateFolder)
             cloner.spec1.setDefaultReplicateDir(defReplicateFolder);
+#endif
         cloner.srcCluster.set(srcCluster);
         cloner.prefix.set(prefix);
         cloner.cloneRoxieFile(srcLFN, dstLFN);
diff --git a/dali/sasha/saserver.cpp b/dali/sasha/saserver.cpp
index 598a6a3c3..29068f4cd 100644
--- a/dali/sasha/saserver.cpp
+++ b/dali/sasha/saserver.cpp
@@ -50,14 +50,14 @@ extern void LDStest();
 
 Owned<IPropertyTree> serverConfig;
 static IArrayOf<ISashaServer> servers;
-static atomic_t StopSuspendCount = ATOMIC_INIT(0);
+static std::atomic<unsigned> StopSuspendCount{0};
 static bool stopped = false;
 static Semaphore stopSem;
 
 const char *sashaProgramName;
 
-CSuspendAutoStop::CSuspendAutoStop() { atomic_inc(&StopSuspendCount); }
-CSuspendAutoStop::~CSuspendAutoStop() { atomic_dec(&StopSuspendCount); }
+CSuspendAutoStop::CSuspendAutoStop() { StopSuspendCount++; }
+CSuspendAutoStop::~CSuspendAutoStop() { StopSuspendCount--; }
 
 #ifdef _CONTAINERIZED
 const char *service = nullptr;
@@ -265,7 +265,7 @@ void SashaMain()
                 stopped = true;
             }
             else if (timeout&&(timeout<msTick()-start)) {
-                if (atomic_read(&StopSuspendCount)==0) {
+                if (StopSuspendCount==0) {
                     PROGLOG("Auto Restart");
                     stopped = true;
                 }
@@ -304,17 +304,9 @@ sasha:
 
 int main(int argc, const char* argv[])
 {
-#ifndef _CONTAINERIZED
-    for (unsigned i=0;i<(unsigned)argc;i++) {
-        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-            if (daemon(1,0) || write_pidfile(argv[++i])) {
-                perror("Failed to daemonize");
-                return EXIT_FAILURE;
-            }
-            break;
-        }
-    }
-#endif
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
+
     InitModuleObjects();
     EnableSEHtoExceptionMapping();
 
diff --git a/dali/server/daserver.cpp b/dali/server/daserver.cpp
index 8861022d0..d4cfad88c 100644
--- a/dali/server/daserver.cpp
+++ b/dali/server/daserver.cpp
@@ -424,13 +424,11 @@ int main(int argc, const char* argv[])
         Owned<IFile> sentinelFile = createSentinelTarget();
         removeSentinelFile(sentinelFile);
 #ifndef _CONTAINERIZED
+        if (!checkCreateDaemon(argc, argv))
+            return EXIT_FAILURE;
 
         for (unsigned i=1;i<(unsigned)argc;i++) {
             if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-                if (daemon(1,0) || write_pidfile(argv[++i])) {
-                    perror("Failed to daemonize");
-                    return EXIT_FAILURE;
-                }
             }
             else if (streq(argv[i],"--server") || streq(argv[i],"-s"))
                 server = argv[++i];
diff --git a/ecl/agentexec/agentexec.cpp b/ecl/agentexec/agentexec.cpp
index 416863a36..12e9db9c8 100644
--- a/ecl/agentexec/agentexec.cpp
+++ b/ecl/agentexec/agentexec.cpp
@@ -244,10 +244,11 @@ public:
                 jobSpecName.set("thormanager");
                 processName.set("thormaster_lcr");
             }
-            if (!queryComponentConfig().getPropBool("@useChildProcesses", false))
+            Owned<const IPropertyTree> compConfig = getComponentConfig();
+            if (!compConfig->getPropBool("@useChildProcesses", false))
             {
                 std::list<std::pair<std::string, std::string>> params = { };
-                if (queryComponentConfig().getPropBool("@useThorQueue", true))
+                if (compConfig->getPropBool("@useThorQueue", true))
                     params.push_back({ "queue", queue.get() });
                 StringBuffer jobName(wuid);
                 if (isThorJob)
@@ -260,12 +261,12 @@ public:
             else
             {
                 VStringBuffer exec("%s --workunit=%s --daliServers=%s", processName.get(), wuid.str(), dali.str());
-                if (queryComponentConfig().hasProp("@config"))
+                if (compConfig->hasProp("@config"))
                 {
                     exec.append(" --config=");
-                    queryComponentConfig().getProp("@config", exec);
+                    compConfig->getProp("@config", exec);
                 }
-                if (queryComponentConfig().getPropBool("@useThorQueue", true))
+                if (compConfig->getPropBool("@useThorQueue", true))
                     exec.append(" --queue=").append(queue);
                 if (isThorJob)
                     exec.appendf(" --graphName=%s", graphName.get());
@@ -382,17 +383,9 @@ eclagent:
 
 int main(int argc, const char *argv[]) 
 { 
-#ifndef _CONTAINERIZED
-    for (unsigned i=0;i<(unsigned)argc;i++) {
-        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-            if (daemon(1,0) || write_pidfile(argv[++i])) {
-                perror("Failed to daemonize");
-                return EXIT_FAILURE;
-            }
-            break;
-        }
-    }
-#endif
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
+
     InitModuleObjects();
 
     Owned<IPropertyTree> config;
diff --git a/ecl/eclagent/eclagent.cpp b/ecl/eclagent/eclagent.cpp
index 47ec63ef6..da2488ad9 100644
--- a/ecl/eclagent/eclagent.cpp
+++ b/ecl/eclagent/eclagent.cpp
@@ -560,7 +560,7 @@ EclAgent::EclAgent(IConstWorkUnit *wu, const char *_wuid, bool _checkVersion, bo
     agentMachineCost = getMachineCostRate();
     if (agentMachineCost > 0.0)
     {
-        IPropertyTree *costs = queryCostsConfiguration();
+        Owned<const IPropertyTree> costs = getCostsConfiguration();
         if (costs)
         {
             double softCostLimit = costs->getPropReal("@limit");
@@ -619,7 +619,7 @@ const char *EclAgent::queryTempfilePath()
 
 StringBuffer & EclAgent::getTempfileBase(StringBuffer & buff)
 {
-    return buff.append(queryTempfilePath()).append(PATHSEPCHAR).append(wuid);
+    return buff.append(queryTempfilePath()).append(PATHSEPCHAR).appendLower(wuid);
 }
 
 const char *EclAgent::queryTemporaryFile(const char *fname)
@@ -1394,7 +1394,12 @@ ILocalOrDistributedFile *EclAgent::resolveLFN(const char *fname, const char *err
     }
     if (expandedlfn)
         *expandedlfn = lfn;
-    Owned<ILocalOrDistributedFile> ldFile = createLocalOrDistributedFile(lfn.str(), queryUserDescriptor(), resolveFilesLocally, !resolveFilesLocally, isWrite, isPrivilegedUser);
+    /*
+     * NB: this code and ILocalOrDistributedFile should be revisited when DFS is refactored
+     * hthor doesn't use it to write, but instead uses createClusterWriteHandler to handle cluster writing.
+     * See code in e.g.: CHThorDiskWriteActivity::resolve
+     */
+    Owned<ILocalOrDistributedFile> ldFile = createLocalOrDistributedFile(lfn.str(), queryUserDescriptor(), resolveFilesLocally, !resolveFilesLocally, isWrite, isPrivilegedUser, nullptr);
     if (ldFile)
     {
         IDistributedFile * dFile = ldFile->queryDistributedFile();
@@ -3488,7 +3493,7 @@ extern int HTHOR_API eclagent_main(int argc, const char *argv[], StringBuffer *
         }
         try
         {
-            agentTopology.setown(loadConfiguration(defaultYaml, argv, "hthor", "ECLAGENT", "agentexec.xml", nullptr));
+            agentTopology.setown(loadConfiguration(defaultYaml, argv, "hthor", "ECLAGENT", "agentexec.xml", nullptr, nullptr, false));
         }
         catch (IException *E)
         {
@@ -3497,7 +3502,7 @@ extern int HTHOR_API eclagent_main(int argc, const char *argv[], StringBuffer *
         }
     }
     else
-        agentTopology.setown(loadConfiguration(defaultYaml, argv, "hthor", "ECLAGENT", nullptr, nullptr));
+        agentTopology.setown(loadConfiguration(defaultYaml, argv, "hthor", "ECLAGENT", nullptr, nullptr, nullptr, false));
 
     installDefaultFileHooks(agentTopology);
 
diff --git a/ecl/eclagent/eclgraph.cpp b/ecl/eclagent/eclgraph.cpp
index 460fc192c..c61409b0e 100644
--- a/ecl/eclagent/eclgraph.cpp
+++ b/ecl/eclagent/eclgraph.cpp
@@ -240,7 +240,12 @@ static IHThorActivity * createActivity(IAgentContext & agent, unsigned activityI
     case TAKspillread:
         return createDiskReadActivity(agent, activityId, subgraphId, (IHThorDiskReadArg &)arg, kind, graph, node);
     case TAKnewdiskread:
-        return createNewDiskReadActivity(agent, activityId, subgraphId, (IHThorNewDiskReadArg &)arg, kind, graph, node);
+        {
+            bool isGeneric = (((IHThorNewDiskReadArg &)arg).getFlags() & TDXgeneric) != 0;
+            if (isGeneric)
+                return createGenericDiskReadActivity(agent, activityId, subgraphId, (IHThorNewDiskReadArg &)arg, kind, graph, node);
+            return createNewDiskReadActivity(agent, activityId, subgraphId, (IHThorNewDiskReadArg &)arg, kind, graph, node);
+        }
     case TAKdisknormalize:
         return createDiskNormalizeActivity(agent, activityId, subgraphId, (IHThorDiskNormalizeArg &)arg, kind, graph, node);
     case TAKdiskaggregate:
diff --git a/ecl/eclcc/eclcc.cpp b/ecl/eclcc/eclcc.cpp
index a806f6b1a..3a05248f8 100644
--- a/ecl/eclcc/eclcc.cpp
+++ b/ecl/eclcc/eclcc.cpp
@@ -521,7 +521,7 @@ int main(int argc, const char *argv[])
     unsigned exitCode = 0;
     try
     {
-        configuration.setown(loadConfiguration(defaultYaml, argv, "eclccserver", "ECLCCSERVER", nullptr, nullptr));
+        configuration.setown(loadConfiguration(defaultYaml, argv, "eclccserver", "ECLCCSERVER", nullptr, nullptr, nullptr, false));
 
 #ifndef _CONTAINERIZED
         // Turn logging down (we turn it back up if -v option seen)
diff --git a/ecl/eclccserver/eclccserver.cpp b/ecl/eclccserver/eclccserver.cpp
index 86ce18b47..104fa4847 100644
--- a/ecl/eclccserver/eclccserver.cpp
+++ b/ecl/eclccserver/eclccserver.cpp
@@ -38,7 +38,6 @@
 #include <string>
 #include "codesigner.hpp"
 
-static Owned<IPropertyTree> globals;
 static const char * * globalArgv = nullptr;
 
 //------------------------------------------------------------------------------------------------------------------
@@ -489,9 +488,10 @@ class EclccCompileThread : implements IPooledThread, implements IErrorReporter,
         if (syntaxCheck)
             eclccCmd.appendf(" -syntax");
 
-        if (globals->getPropBool("@enableEclccDali", true))
+        Owned<IPropertyTree> config = getComponentConfig();
+        if (config->getPropBool("@enableEclccDali", true))
         {
-            const char *daliServers = globals->queryProp("@daliServers");
+            const char *daliServers = config->queryProp("@daliServers");
             if (!daliServers)
                 daliServers = ".";
             eclccCmd.appendf(" -dfs=%s", daliServers);
@@ -506,7 +506,7 @@ class EclccCompileThread : implements IPooledThread, implements IErrorReporter,
         }
         Owned<IPipeProcess> pipe = createPipeProcess();
         pipe->setenv("ECLCCSERVER_THREAD_INDEX", idxStr.str());
-        Owned<IPropertyTreeIterator> options = globals->getElements("./Option");
+        Owned<IPropertyTreeIterator> options = config->getElements("./Option");
         ForEach(*options)
         {
             IPropertyTree &option = options->query();
@@ -528,7 +528,7 @@ class EclccCompileThread : implements IPooledThread, implements IErrorReporter,
             workunit->getDebugValue(debugStr.str(), valueStr);
             processOption(debugStr.str(), valueStr.str(), eclccCmd, eclccProgName, *pipe, true);
         }
-        bool compileCppSeparately = globals->getPropBool("@compileCppSeparately", true);
+        bool compileCppSeparately = config->getPropBool("@compileCppSeparately", true);
         if (compileCppSeparately)
         {
             workunit->setStatistic(queryStatisticsComponentType(), queryStatisticsComponentName(), SSTcompilestage, "compile", StWhenStarted, NULL, getTimeStampNowValue(), 1, 0, StatsMergeAppend);
@@ -667,8 +667,9 @@ public:
     virtual void threadmain() override
     {
         DBGLOG("Compile request processing for workunit %s", wuid.get());
+        Owned<IPropertyTree> config = getComponentConfig();
 #ifdef _CONTAINERIZED
-        if (!globals->getPropBool("@useChildProcesses", false) && !globals->hasProp("@workunit"))
+        if (!config->getPropBool("@useChildProcesses", false) && !config->hasProp("@workunit"))
         {
             Owned<IException> error;
             try
@@ -717,15 +718,15 @@ public:
             return;
         }
         CSDSServerStatus serverstatus("ECLCCserverThread");
-        serverstatus.queryProperties()->setProp("@cluster",globals->queryProp("@name"));
+        serverstatus.queryProperties()->setProp("@cluster", config->queryProp("@name"));
         serverstatus.queryProperties()->setProp("@thread", idxStr.str());
-        serverstatus.queryProperties()->setProp("WorkUnit",wuid.get());
+        serverstatus.queryProperties()->setProp("WorkUnit", wuid.get());
         serverstatus.commitProperties();
         workunit->setAgentSession(myProcessSession());
         StringAttr clusterName(workunit->queryClusterName());
 #ifdef _CONTAINERIZED
         VStringBuffer xpath("queues[@name='%s']", clusterName.str());
-        Owned<IPropertyTree> queueInfo = globals->getBranch(xpath);
+        Owned<IPropertyTree> queueInfo = config->getBranch(xpath);
         assertex(queueInfo);
         const char *platformName = queueInfo->queryProp("@type");
 #else
@@ -869,6 +870,43 @@ static void removePrecompiledHeader()
 // Class EclccServer manages a pool of compile threads
 //------------------------------------------------------------------------------------------------------------------
 
+static StringBuffer &getQueues(StringBuffer &queueNames)
+{
+    Owned<IPropertyTree> config = getComponentConfig();
+#ifdef _CONTAINERIZED
+    bool filtered = false;
+    std::unordered_map<std::string, bool> listenQueues;
+    Owned<IPTreeIterator> listening = config->getElements("listen");
+    ForEach (*listening)
+    {
+        const char *lq = listening->query().queryProp(".");
+        if (lq)
+        {
+            listenQueues[lq] = true;
+            filtered = true;
+        }
+    }
+    Owned<IPTreeIterator> queues = config->getElements("queues");
+    ForEach(*queues)
+    {
+        IPTree &queue = queues->query();
+        const char *qname = queue.queryProp("@name");
+        if (!filtered || listenQueues.count(qname))
+        {
+            if (queueNames.length())
+                queueNames.append(",");
+            getClusterEclCCServerQueueName(queueNames, qname);
+        }
+    }
+#else
+    const char * processName = config->queryProp("@name");
+    SCMStringBuffer scmQueueNames;
+    getEclCCServerQueueNames(scmQueueNames, processName);
+    queueNames.append(scmQueueNames.str());
+#endif
+    return queueNames;
+}
+
 class EclccServer : public CInterface, implements IThreadFactory, implements IAbortHandler
 {
     StringAttr queueNames;
@@ -880,39 +918,82 @@ class EclccServer : public CInterface, implements IThreadFactory, implements IAb
     bool running;
     CSDSServerStatus serverstatus;
     Owned<IJobQueue> queue;
+    CriticalSection queueUpdateCS;
+    StringAttr updatedQueueNames;
+    unsigned reloadConfigCBId = 0;
+
 
+    void configUpdate()
+    {
+        StringBuffer newQueueNames;
+        getQueues(newQueueNames);
+        if (!newQueueNames.length())
+            ERRLOG("No queues found to listen on");
+        Linked<IJobQueue> currentQueue;
+        {
+            CriticalBlock b(queueUpdateCS);
+            if (strsame(queueNames, newQueueNames))
+                return;
+            updatedQueueNames.set(newQueueNames);
+            currentQueue.set(queue);
+            PROGLOG("Updating queue due to queue names change from '%s' to '%s'", queueNames.str(), newQueueNames.str());
+        }
+        if (currentQueue)
+            currentQueue->cancelAcceptConversation();
+    }
 public:
     IMPLEMENT_IINTERFACE;
     EclccServer(const char *_queueName, unsigned _poolSize)
-        : queueNames(_queueName), poolSize(_poolSize), serverstatus("ECLCCserver")
+        : updatedQueueNames(_queueName), poolSize(_poolSize), serverstatus("ECLCCserver")
     {
         threadsActive = 0;
         running = false;
         pool.setown(createThreadPool("eclccServerPool", this, NULL, poolSize, INFINITE));
-        serverstatus.queryProperties()->setProp("@cluster", globals->queryProp("@name"));
-        serverstatus.queryProperties()->setProp("@queue", queueNames.get());
+        serverstatus.queryProperties()->setProp("@cluster", getComponentConfigSP()->queryProp("@name"));
         serverstatus.commitProperties();
+        reloadConfigCBId = installConfigUpdateHook(std::bind(&EclccServer::configUpdate, this));
     }
 
     ~EclccServer()
     {
+        if (reloadConfigCBId)
+            removeConfigUpdateHook(reloadConfigCBId);
         pool->joinAll(false, INFINITE);
     }
 
     void run()
     {
-        DBGLOG("eclccServer (%d threads) waiting for requests on queue(s) %s", poolSize, queueNames.get());
-        queue.setown(createJobQueue(queueNames.get()));
-        queue->connect(false);
         running = true;
         LocalIAbortHandler abortHandler(*this);
         while (running)
         {
             try
             {
+                bool newQueues = false;
+                {
+                    CriticalBlock b(queueUpdateCS);
+                    if (updatedQueueNames)
+                    {
+                        queueNames.set(updatedQueueNames);
+                        updatedQueueNames.clear();
+                        queue.clear();
+                        queue.setown(createJobQueue(queueNames.get()));
+                        newQueues = true;
+                    }
+                    // onAbort could have triggered before or during the above switch, if so, we do no want to connect/block on new queue
+                    if (!running)
+                        break;
+                }
+                if (newQueues)
+                {
+                    queue->connect(false);
+                    serverstatus.queryProperties()->setProp("@queue", queueNames.get());
+                    serverstatus.commitProperties();
+                    DBGLOG("eclccServer (%d threads) waiting for requests on queue(s) %s", poolSize, queueNames.get());
+                }
                 if (!pool->waitAvailable(10000))
                 {
-                    if (globals->getPropInt("@traceLevel", 0) > 2)
+                    if (getComponentConfigSP()->getPropInt("@traceLevel", 0) > 2)
                         DBGLOG("Blocked for 10 seconds waiting for an available compiler thread");
                     continue;
                 }
@@ -962,8 +1043,14 @@ public:
     virtual bool onAbort() 
     {
         running = false;
-        if (queue)
-            queue->cancelAcceptConversation();
+        Linked<IJobQueue> currentQueue;
+        {
+            CriticalBlock b(queueUpdateCS);
+            if (queue)
+                currentQueue.set(queue);
+        }
+        if (currentQueue)
+            currentQueue->cancelAcceptConversation();
         return false;
     }
 };
@@ -972,7 +1059,7 @@ void openLogFile()
 {
 #ifndef _CONTAINERIZED
     StringBuffer logname;
-    envGetConfigurationDirectory("log","eclccserver",globals->queryProp("@name"),logname);
+    envGetConfigurationDirectory("log","eclccserver", getComponentConfigSP()->queryProp("@name"),logname);
     Owned<IComponentLogFileCreator> lf = createComponentLogFileCreator(logname.str(), "eclccserver");
     lf->beginLogging();
 #else
@@ -1023,17 +1110,9 @@ eclccserver:
 
 int main(int argc, const char *argv[])
 {
-#ifndef _CONTAINERIZED
-    for (unsigned i=0;i<(unsigned)argc;i++) {
-        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-            if (daemon(1,0) || write_pidfile(argv[++i])) {
-                perror("Failed to daemonize");
-                return EXIT_FAILURE;
-            }
-            break;
-        }
-    }
-#endif
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
+
     InitModuleObjects();
     initSignals();
     NoQuickEditSection x;
@@ -1042,6 +1121,7 @@ int main(int argc, const char *argv[])
     // We remove any existing sentinel until we have validated that we can successfully start (i.e. all options are valid...)
     removeSentinelFile(sentinelFile);
 
+    Owned<IPropertyTree> globals;
     try
     {
         globalArgv = argv;
@@ -1098,42 +1178,14 @@ int main(int argc, const char *argv[])
                 startPerformanceMonitor(optMonitorInterval*1000, PerfMonStandard, nullptr);
 #endif
 
-#ifdef _CONTAINERIZED
-            queryCodeSigner().initForContainer();
-
-            bool filtered = false;
-            std::unordered_map<std::string, bool> listenQueues;
-            Owned<IPTreeIterator> listening = globals->getElements("listen");
-            ForEach (*listening)
-            {
-                const char *lq = listening->query().queryProp(".");
-                if (lq)
-                {
-                    listenQueues[lq] = true;
-                    filtered = true;
-                }
-            }
-
             StringBuffer queueNames;
-            Owned<IPTreeIterator> queues = globals->getElements("queues");
-            ForEach(*queues)
-            {
-                IPTree &queue = queues->query();
-                const char *qname = queue.queryProp("@name");
-                if (!filtered || listenQueues.count(qname))
-                {
-                    if (queueNames.length())
-                        queueNames.append(",");
-                    getClusterEclCCServerQueueName(queueNames, qname);
-                }
-            }
-#else
-            SCMStringBuffer queueNames;
-            getEclCCServerQueueNames(queueNames, processName);
-#endif
+            getQueues(queueNames);
             if (!queueNames.length())
                 throw MakeStringException(0, "No queues found to listen on");
+
 #ifdef _CONTAINERIZED
+            queryCodeSigner().initForContainer();
+
             bool useChildProcesses = globals->getPropInt("@useChildProcesses", false);
             unsigned maxThreads = globals->getPropInt("@maxActive", 4);
 #else
@@ -1160,7 +1212,6 @@ int main(int argc, const char *argv[])
 #ifndef _CONTAINERIZED
     stopPerformanceMonitor();
 #endif
-    globals.clear();
     UseSysLogForOperatorMessages(false);
     ::closedownClientProcess(); // dali client closedown
     releaseAtoms();
diff --git a/ecl/eclscheduler/eclscheduler.cpp b/ecl/eclscheduler/eclscheduler.cpp
index 0712a6275..288bbfdef 100644
--- a/ecl/eclscheduler/eclscheduler.cpp
+++ b/ecl/eclscheduler/eclscheduler.cpp
@@ -32,7 +32,6 @@
 #include "eventqueue.hpp"
 
 static unsigned traceLevel;
-Owned<IPropertyTree> globals;
 
 //=========================================================================================
 //////////////////////////////////////////////////////////////////////////////////////////////
@@ -165,7 +164,8 @@ private:
 void openLogFile()
 {
 #ifndef _CONTAINERIZED
-    Owned<IComponentLogFileCreator> lf = createComponentLogFileCreator(globals, "eclscheduler");
+    Owned<IPropertyTree> config = getComponentConfig();
+    Owned<IComponentLogFileCreator> lf = createComponentLogFileCreator(config, "eclscheduler");
     lf->beginLogging();
 #else
     setupContainerizedLogMsgHandler();
@@ -184,17 +184,8 @@ eclscheduler:
 
 int main(int argc, const char *argv[])
 {
-#ifndef _CONTAINERIZED
-    for (unsigned i=0;i<(unsigned)argc;i++) {
-        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-            if (daemon(1,0) || write_pidfile(argv[++i])) {
-                perror("Failed to daemonize");
-                return EXIT_FAILURE;
-            }
-            break;
-        }
-    }
-#endif
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
 
     InitModuleObjects();
     initSignals();
@@ -210,6 +201,7 @@ int main(int argc, const char *argv[])
     else if (checkFileExists("eclccserver.xml") )
         iniFileName = "eclccserver.xml";
 
+    Owned<IPropertyTree> globals;
     try
     {
         globals.setown(loadConfiguration(defaultYaml, argv, "eclscheduler", "ECLSCHEDULER", iniFileName, nullptr));
diff --git a/ecl/hql/hqlutil.cpp b/ecl/hql/hqlutil.cpp
index 3a9b290e4..ea516897a 100644
--- a/ecl/hql/hqlutil.cpp
+++ b/ecl/hql/hqlutil.cpp
@@ -10273,6 +10273,10 @@ void getFieldTypeInfo(FieldTypeInfoStruct &out, ITypeInfo *type)
                 out.fieldType |= RFTMlinkcounted;
                 out.fieldType &= ~RFTMunknownsize;
             }
+
+            // DATASET(record, COUNT()/SIZEOF) cannot currently be serialized/deserialized
+            if (queryAttributeModifier(type, _childAttr_Atom))
+                out.fieldType |= RFTMnoserialize;
             break;
         }
     case type_dictionary:
@@ -10586,3 +10590,24 @@ const RtlTypeInfo *buildRtlType(IRtlFieldTypeDeserializer &deserializer, ITypeIn
 
     return deserializer.addType(info, type);
 }
+
+
+IHqlExpression * queryAttributeModifier(ITypeInfo * type, IAtom * name)
+{
+    ITypeInfo * cur = type;
+    for(;;)
+    {
+        typemod_t mod = cur->queryModifier();
+        if (mod == typemod_none)
+            break;
+        if (mod == typemod_attr)
+        {
+            IHqlExpression * attr = (IHqlExpression *)cur->queryModifierExtra();
+            if (!name || (name == attr->queryName()))
+                return attr;
+        }
+
+        cur = cur->queryTypeBase();
+    }
+    return nullptr;
+}
diff --git a/ecl/hql/hqlutil.hpp b/ecl/hql/hqlutil.hpp
index df0208e75..b722ac2ef 100644
--- a/ecl/hql/hqlutil.hpp
+++ b/ecl/hql/hqlutil.hpp
@@ -874,5 +874,6 @@ protected:
 
 extern HQL_API bool joinHasRightOnlyHardMatch(IHqlExpression * expr, bool allowSlidingMatch);
 extern HQL_API void gatherParseWarnings(IErrorReceiver * errs, IHqlExpression * expr, IErrorArray & warnings);
+extern HQL_API IHqlExpression * queryAttributeModifier(ITypeInfo * type, IAtom * name);
 
 #endif
diff --git a/ecl/hqlcpp/hqlcpp.cpp b/ecl/hqlcpp/hqlcpp.cpp
index df02e6daf..215dcac63 100644
--- a/ecl/hqlcpp/hqlcpp.cpp
+++ b/ecl/hqlcpp/hqlcpp.cpp
@@ -1863,7 +1863,7 @@ void HqlCppTranslator::cacheOptions()
         DebugOption(options.checkDuplicateMinActivities, "checkDuplicateMinActivities", 100),
         DebugOption(options.diskReadsAreSimple, "diskReadsAreSimple", false), // Not yet enabled - needs filters to default to generating keyed info first
         DebugOption(options.allKeyedFiltersOptional, "allKeyedFiltersOptional", false),
-        DebugOption(options.genericDiskReads, "genericDiskReads", false),
+        DebugOption(options.genericDiskReads, "genericDiskReads", false), // Can be enabled for hthor, but locking not currently supported
         DebugOption(options.generateActivityFormats, "generateActivityFormats", false),
         DebugOption(options.generateDiskFormats, "generateDiskFormats", false),
         DebugOption(options.maxOptimizeSize, "maxOptimizeSize", 5),             // Remove the overhead from very small functions e.g. function prolog
diff --git a/ecl/hqlcpp/hqlsource.cpp b/ecl/hqlcpp/hqlsource.cpp
index db073e6f2..5306caca2 100644
--- a/ecl/hqlcpp/hqlsource.cpp
+++ b/ecl/hqlcpp/hqlsource.cpp
@@ -305,8 +305,6 @@ void VirtualFieldsInfo::gatherVirtualFields(IHqlExpression * _record, bool ignor
         if (virtualAttr)
         {
             selects.append(*LINK(cur));
-            if (isUnknownSize(cur->queryType()))
-                simpleVirtualsAtEnd = false;
             if (virtuals.find(*virtualAttr) == NotFound)
                 virtuals.append(*LINK(virtualAttr));
         }
@@ -634,7 +632,7 @@ static bool forceLegacyMapping(IHqlExpression * expr)
 class SourceBuilder
 {
 public:
-    SourceBuilder(HqlCppTranslator & _translator, IHqlExpression *_tableExpr, IHqlExpression *_nameExpr)
+    SourceBuilder(HqlCppTranslator & _translator, IHqlExpression *_tableExpr, IHqlExpression *_nameExpr, bool canReadGenerically)
         : tableExpr(_tableExpr), newInputMapping(false), translator(_translator)
     { 
         nameExpr.setown(foldHqlExpression(_nameExpr));
@@ -663,6 +661,7 @@ public:
         isUnfilteredCount = false;
         requiresOrderedMerge = false;
         genericDiskReads = translator.queryOptions().genericDiskReads;
+        genericDiskRead = genericDiskReads && canReadGenerically;
         rootSelfRow = NULL;
         activityKind = TAKnone;
 
@@ -673,7 +672,7 @@ public:
             else
                 newInputMapping = translator.queryOptions().newDiskReadMapping;
 
-            if (forceLegacyMapping(tableExpr))
+            if (!genericDiskRead && forceLegacyMapping(tableExpr))
                 newInputMapping = false;
 
             //If this index has been translated using the legacy method then ensure we continue to use that method
@@ -798,12 +797,13 @@ public:
     bool            useImplementationClass;
     bool            isUnfilteredCount;
     bool            isVirtualLogicalFilenameUsed = false;
+    bool            isVirtualLogicalFileposUsed = false;
     bool            transformUsesVirtualLogicalFilename = false;
     bool            transformUsesVirtualFilePosition = false;
     bool            requiresOrderedMerge;
     bool            newInputMapping;
     bool            extractCanMatch = false;
-    bool            genericDiskReads;
+    bool            genericDiskReads = false;
     bool            genericDiskRead = false;
     bool            hasDynamicOptions = false;
 
@@ -926,6 +926,8 @@ void SourceBuilder::analyse(IHqlExpression * expr)
             {
                 if (containsVirtualField(tableExpr->queryRecord(), logicalFilenameAtom))
                     isVirtualLogicalFilenameUsed = true;
+                if (containsVirtualField(tableExpr->queryRecord(), filepositionAtom) || containsVirtualField(tableExpr->queryRecord(), localFilePositionAtom))
+                    isVirtualLogicalFileposUsed = true;
             }
         }
         break;
@@ -2703,9 +2705,10 @@ void SourceBuilder::deduceDiskRecords()
     {
         projectedRecord.set(tableExpr->queryRecord());
         expectedRecord.setown(getSerializedForm(physicalRecord, diskAtom));
-        //MORE: HPCC-18469 Reduce projected to the fields that are actually required by the dataset, and will need to remap field references.
 
-        if (fieldInfo.hasVirtuals())
+        //If the record translator can proccess the record then virtual fields can be anywhere, otherwise they need
+        //to be at the end so they can be appended - and the projected format will match the serialized disk format
+        if (!canDefinitelyProcessWithTranslator(projectedRecord) && !fieldInfo.canAppendVirtuals())
         {
             StringBuffer typeName;
             unsigned recordTypeFlags = translator.buildRtlType(typeName, projectedRecord->queryType());
@@ -2845,14 +2848,13 @@ class DiskReadBuilderBase : public SourceBuilder
 {
 public:
     DiskReadBuilderBase(HqlCppTranslator & _translator, IHqlExpression *_tableExpr, IHqlExpression *_nameExpr, bool canReadGenerically)
-        : SourceBuilder(_translator, _tableExpr, _nameExpr), monitors(_tableExpr, _translator, 0, true, true)
+        : SourceBuilder(_translator, _tableExpr, _nameExpr, canReadGenerically), monitors(_tableExpr, _translator, 0, true, true)
     {
         fpos.setown(getFilepos(tableExpr, false));
         lfpos.setown(getFilepos(tableExpr, true));
         logicalFilenameMarker.setown(getFileLogicalName(tableExpr));
         mode = tableExpr->queryChild(2);
         modeOp = mode->getOperator();
-        genericDiskRead = genericDiskReads && canReadGenerically;
         includeFormatCrc = ((modeOp != no_csv) || genericDiskRead) && (modeOp != no_pipe);
     }
 
@@ -2963,6 +2965,8 @@ void DiskReadBuilderBase::buildFlagsMember(IHqlExpression * expr)
     if (tableExpr->hasAttribute(unsortedAtom)) flags.append("|TDRunsorted");
     if (tableExpr->hasAttribute(optAtom)) flags.append("|TDRoptional");
     if (tableExpr->hasAttribute(_workflowPersist_Atom)) flags.append("|TDXupdateaccessed");
+    if (genericDiskRead) flags.append("|TDXgeneric");
+
     if (isPreloaded) flags.append("|TDRpreload");
     if (monitors.isKeyed()) flags.append("|TDRkeyed");
     if (limitExpr)
@@ -2989,19 +2993,20 @@ void DiskReadBuilderBase::buildFlagsMember(IHqlExpression * expr)
     if (isUnfilteredCount) flags.append("|TDRunfilteredcount");
     if (isVirtualLogicalFilenameUsed || transformUsesVirtualLogicalFilename)
         flags.append("|TDRfilenamecallback");
+    if (isVirtualLogicalFileposUsed || transformUsesVirtualFilePosition)
+        flags.append("|TDRfileposcallback");
     if (transformUsesVirtualFilePosition || transformUsesVirtualLogicalFilename)
         flags.append("|TDRtransformvirtual");
     if (requiresOrderedMerge) flags.append("|TDRorderedmerge");
     if (hasDynamicOptions) flags.append("|TDRdynformatoptions");
+    if (fieldInfo.hasVirtuals() && fieldInfo.canAppendVirtuals())
+    {
+        if (!canDefinitelyProcessWithTranslator(projectedRecord))
+            flags.append("|TDRcloneappendvirtual");
+    }
 
     if (flags.length())
         translator.doBuildUnsignedFunction(instance->classctx, "getFlags", flags.str()+1);
-
-    //New activity doesn't currently support virtual callbacks from the transform.
-    //At a later date this error will be removed, and a new variant of the activity will be created
-    //that does not imposing the overhead of tracking filepositions on the general cases.
-    if (genericDiskRead && (transformUsesVirtualFilePosition || transformUsesVirtualLogicalFilename))
-        throwError(HQLERR_NoVirtualAndAlien);
 }
 
 
@@ -3113,6 +3118,11 @@ void DiskReadBuilder::analyseGraph(IHqlExpression * expr)
     DiskReadBuilderBase::analyseGraph(expr);
     if (newInputMapping && extractCanMatch && firstTransformer)
     {
+        //If the record cannot be read using the serialized meta information, do not reduce the fields because the translator
+        //cannot perform the mapping.
+        if (!canDefinitelyProcessWithTranslator(projectedRecord))
+            return;
+
         //Calculate the minimum set of fields required by any post-filters and projects.
         projectedRecord.setown(getMinimumInputRecord(translator, firstTransformer));
         if (projectedRecord != firstTransformer->queryChild(0)->queryRecord())
@@ -3329,11 +3339,12 @@ ABoundActivity * HqlCppTranslator::doBuildActivityDiskRead(BuildCtx & ctx, IHqlE
         const bool forceAllProjectedSerialized = options.forceAllProjectedDiskSerialized;
         //Reading from a spill file uses the in-memory format to optimize on-demand spilling.
         bool optimizeInMemorySpill = targetThor();
-        bool useInMemoryFormat = optimizeInMemorySpill && isSimpleProjectingDiskRead(expr);
+        IHqlExpression * record = tableExpr->queryRecord();
+        bool useInMemoryFormat = optimizeInMemorySpill && isSimpleProjectingDiskRead(expr) && !canDefinitelyProcessWithTranslator(record);
         if (forceAllProjectedSerialized || !useInMemoryFormat)
         {
             //else if the the table isn't serialized, then map to a serialized table, and then project to the real format
-            if (recordRequiresSerialization(tableExpr->queryRecord(), diskAtom))
+            if (recordRequiresSerialization(record, diskAtom))
             {
                 OwnedHqlExpr transformed = buildTableFromSerialized(expr);
                 //Need to wrap a possible no_usertable, otherwise the localisation can go wrong.
@@ -3697,7 +3708,7 @@ class ChildBuilderBase : public SourceBuilder
 {
 public:
     ChildBuilderBase(HqlCppTranslator & _translator, IHqlExpression *_tableExpr, IHqlExpression *_nameExpr)
-        : SourceBuilder(_translator, _tableExpr, _nameExpr)
+        : SourceBuilder(_translator, _tableExpr, _nameExpr, false)
     { 
     }
 
@@ -3972,7 +3983,7 @@ class IndexReadBuilderBase : public SourceBuilder
     friend class MonitorRemovalTransformer;
 public:
     IndexReadBuilderBase(HqlCppTranslator & _translator, IHqlExpression *_tableExpr, IHqlExpression *_nameExpr)
-        : SourceBuilder(_translator, _tableExpr, _nameExpr),
+        : SourceBuilder(_translator, _tableExpr, _nameExpr, false),
           monitors(_tableExpr, _translator, -(int)numPayloadFields(_tableExpr), false, getHintBool(_tableExpr, createValueSetsAtom, _translator.queryOptions().createValueSets))
     {
     }
@@ -4878,7 +4889,7 @@ class FetchBuilder : public SourceBuilder
 {
 public:
     FetchBuilder(HqlCppTranslator & _translator, IHqlExpression *_tableExpr, IHqlExpression *_nameExpr, IHqlExpression * _fetchExpr)
-        : SourceBuilder(_translator, _tableExpr, _nameExpr)
+        : SourceBuilder(_translator, _tableExpr, _nameExpr, false)
     {
         compoundExpr.set(_fetchExpr);
         fetchExpr.set(queryFetch(_fetchExpr));
diff --git a/ecl/hqlcpp/hqlsource.ipp b/ecl/hqlcpp/hqlsource.ipp
index 50d22e719..844611ebd 100644
--- a/ecl/hqlcpp/hqlsource.ipp
+++ b/ecl/hqlcpp/hqlsource.ipp
@@ -36,6 +36,7 @@ public:
     void gatherVirtualFields(IHqlExpression * record, bool ignoreVirtuals, bool ensureSerialized);
     bool hasVirtuals()      { return virtuals.ordinality() != 0; }
     bool hasVirtualsOrDeserialize() { return requiresDeserialize || virtuals.ordinality() != 0; }
+    bool canAppendVirtuals() { return simpleVirtualsAtEnd; }
 
 public:
     HqlExprArray    physicalFields;
diff --git a/ecl/hthor/hthor.cpp b/ecl/hthor/hthor.cpp
index 29e201d6f..876c8759c 100644
--- a/ecl/hthor/hthor.cpp
+++ b/ecl/hthor/hthor.cpp
@@ -54,6 +54,8 @@
 #include "ftbase.ipp"
 #include "rtldynfield.hpp"
 #include "rtlnewkey.hpp"
+
+#include "thormeta.hpp"
 #include "thorread.hpp"
 
 #define EMPTY_LOOP_LIMIT 1000
@@ -349,15 +351,20 @@ private:
 ClusterWriteHandler *createClusterWriteHandler(IAgentContext &agent, IHThorIndexWriteArg *iwHelper, IHThorDiskWriteArg *dwHelper, const char * lfn, StringAttr &fn, bool extend)
 {
     //In the containerized system, the default data plane for this component is in the configuration
-    const char * defaultCluster = queryDefaultStoragePlane();
+    StringBuffer defaultCluster;
+    getDefaultStoragePlane(defaultCluster);
     Owned<CHThorClusterWriteHandler> clusterHandler;
     unsigned clusterIdx = 0;
     while(true)
     {
-        OwnedRoxieString cluster(iwHelper ? iwHelper->getCluster(clusterIdx++) : dwHelper->getCluster(clusterIdx++));
-        if (!cluster && (clusterIdx == 1))
-            cluster.setown(defaultCluster); // safe even though it is not a roxie string.
-        if(!cluster)
+        OwnedRoxieString helperCluster(iwHelper ? iwHelper->getCluster(clusterIdx++) : dwHelper->getCluster(clusterIdx++));
+        const char *cluster = helperCluster;
+        if (!helperCluster && (clusterIdx == 1))
+        {
+            if (defaultCluster.length())
+                cluster = defaultCluster;
+        }
+        if (!cluster)
             break;
         if(!clusterHandler)
         {
@@ -532,7 +539,7 @@ void CHThorDiskWriteActivity::resolve()
     else
     {
         StringBuffer mangledName;
-        mangleLocalTempFilename(mangledName, mangledHelperFileName.str());
+        mangleLocalTempFilename(mangledName, mangledHelperFileName.str(), nullptr);
         filename.set(agent.noteTemporaryFile(mangledName.str()));
         PROGLOG("DISKWRITE: using temporary filename %s", filename.get());
     }
@@ -8267,7 +8274,7 @@ void CHThorDiskReadBaseActivity::resolve()
     if (helper.getFlags() & (TDXtemporary | TDXjobtemp))
     {
         StringBuffer mangledFilename;
-        mangleLocalTempFilename(mangledFilename, mangledHelperFileName.str());
+        mangleLocalTempFilename(mangledFilename, mangledHelperFileName.str(), nullptr);
         tempFileName.set(agent.queryTemporaryFile(mangledFilename.str()));
         logicalFileName.set(tempFileName);
         gatherInfo(NULL);
@@ -10650,7 +10657,7 @@ void CHThorNewDiskReadBaseActivity::resolveFile()
     if (helper.getFlags() & (TDXtemporary | TDXjobtemp))
     {
         StringBuffer mangledFilename;
-        mangleLocalTempFilename(mangledFilename, mangledHelperFileName.str());
+        mangleLocalTempFilename(mangledFilename, mangledHelperFileName.str(), nullptr);
         tempFileName.set(agent.queryTemporaryFile(mangledFilename.str()));
         logicalFileName = tempFileName.str();
         gatherInfo(NULL);
@@ -10760,7 +10767,7 @@ CHThorNewDiskReadBaseActivity::InputFileInfo * CHThorNewDiskReadBaseActivity::ex
     Owned<IPropertyTree> meta = createPTree();
     unsigned actualCrc = helper.getDiskFormatCrc();
     Linked<IOutputMetaData> actualDiskMeta = expectedDiskMeta;
-    Linked<const IPropertyTree> fileFormatOptions = curFormatOptions;
+    Linked<IPropertyTree> fileFormatOptions = createPTreeFromIPT(curFormatOptions);
     bool compressed = false;
     bool blockcompressed = false;
     const char * readFormat = helper.queryFormat();
@@ -10785,7 +10792,7 @@ CHThorNewDiskReadBaseActivity::InputFileInfo * CHThorNewDiskReadBaseActivity::ex
 
             size32_t dfsSize = props.getPropInt("@recordSize");
             if (dfsSize != 0)
-                meta->setPropInt("dfsRecordSize", dfsSize);
+                meta->setPropInt("@recordSize", dfsSize);
         }
         compressed = distributedFile->isCompressed(&blockcompressed); //try new decompression, fall back to old unless marked as block
 
@@ -10802,25 +10809,22 @@ CHThorNewDiskReadBaseActivity::InputFileInfo * CHThorNewDiskReadBaseActivity::ex
 
         //MORE: There should probably be a generic way of storing and extracting format options for a file
         IPropertyTree & options = distributedFile->queryAttributes();
-        Linked<IPropertyTree> tempOptions = createPTreeFromIPT(fileFormatOptions);
-        queryInheritProp(*tempOptions, "quote", options, "@csvQuote");
-        queryInheritSeparatorProp(*tempOptions, "separator", options, "@csvSeparate");
-        queryInheritProp(*tempOptions, "terminator", options, "@csvTerminate");
-        queryInheritProp(*tempOptions, "escape", options, "@csvEscape");
+        queryInheritProp(*fileFormatOptions, "quote", options, "@csvQuote");
+        queryInheritSeparatorProp(*fileFormatOptions, "separator", options, "@csvSeparate");
+        queryInheritProp(*fileFormatOptions, "terminator", options, "@csvTerminate");
+        queryInheritProp(*fileFormatOptions, "escape", options, "@csvEscape");
+        dbglogXML(fileFormatOptions);
         dbglogXML(fileFormatOptions);
-        dbglogXML(tempOptions);
-        if (!areMatchingPTrees(fileFormatOptions, tempOptions))
-            fileFormatOptions.setown(tempOptions.getClear());
     }
 
-    meta->setPropBool("grouped", grouped);
-    meta->setPropBool("compressed", compressed);
-    meta->setPropBool("blockCompressed", blockcompressed);
-    meta->setPropBool("forceCompressed", (helper.getFlags() & TDXcompress) != 0);
+    meta->setPropBool("@grouped", grouped);
+    meta->setPropBool("@compressed", compressed);
+    meta->setPropBool("@blockCompressed", blockcompressed);
+    meta->setPropBool("@forceCompressed", (helper.getFlags() & TDXcompress) != 0);
+    meta->setPropTree("formatOptions", fileFormatOptions.getClear());
 
     InputFileInfo & target = * new InputFileInfo;
     target.file = distributedFile;
-    target.formatOptions.swap(fileFormatOptions);
     target.meta.setown(meta.getClear());
     target.actualCrc = actualCrc;
     target.actualMeta.swap(actualDiskMeta);
@@ -10980,7 +10984,7 @@ bool CHThorNewDiskReadBaseActivity::openFilePart(const char * filename)
 
     unsigned expectedCrc = helper.getDiskFormatCrc();
     unsigned projectedCrc = helper.getProjectedFormatCrc();
-    IDiskRowReader * reader = ensureRowReader(format, false, expectedCrc, *expectedDiskMeta, projectedCrc, *projectedDiskMeta, expectedCrc, *expectedDiskMeta, fileInfo->formatOptions);
+    IDiskRowReader * reader = ensureRowReader(format, false, expectedCrc, *expectedDiskMeta, projectedCrc, *projectedDiskMeta, expectedCrc, *expectedDiskMeta, fileInfo->meta);
     if (reader->setInputFile(filename, logicalFileName, 0, offsetOfPart, fileInfo->meta, fieldFilters))
     {
         initStream(reader, filename);
@@ -11035,7 +11039,7 @@ bool CHThorNewDiskReadBaseActivity::openFilePart(ILocalOrDistributedFile * local
         {
             StringBuffer path;
             rfn.getPath(path);
-            IDiskRowReader * reader = ensureRowReader(format, false, expectedCrc, *expectedDiskMeta, projectedCrc, *projectedDiskMeta, actualCrc, *actualDiskMeta, fileInfo->formatOptions);
+            IDiskRowReader * reader = ensureRowReader(format, false, expectedCrc, *expectedDiskMeta, projectedCrc, *projectedDiskMeta, actualCrc, *actualDiskMeta, fileInfo->meta);
             if (reader->setInputFile(path.str(), logicalFileName, whichPart, offsetOfPart, fileInfo->meta, fieldFilters))
             {
                 initStream(reader, path.str());
@@ -11058,7 +11062,7 @@ bool CHThorNewDiskReadBaseActivity::openFilePart(ILocalOrDistributedFile * local
             filenamelist.append('\n').append(filename);
             try
             {
-                IDiskRowReader * reader = ensureRowReader(format, tryRemoteStream, expectedCrc, *expectedDiskMeta, projectedCrc, *projectedDiskMeta, actualCrc, *actualDiskMeta, fileInfo->formatOptions);
+                IDiskRowReader * reader = ensureRowReader(format, tryRemoteStream, expectedCrc, *expectedDiskMeta, projectedCrc, *projectedDiskMeta, actualCrc, *actualDiskMeta, fileInfo->meta);
                 if (reader->setInputFile(rfilename, logicalFileName, whichPart, offsetOfPart, fileInfo->meta, fieldFilters))
                 {
                     initStream(reader, filename);
@@ -11298,6 +11302,566 @@ const void *CHThorNewDiskReadActivity::nextRow()
 
 //=====================================================================================================
 
+bool RemoteReadChecker::onlyReadLocally(const CLogicalFileSlice & slice, unsigned copy)
+{
+    //Allow all operations to be forced to be executed locally.
+    if (forceRemoteDisabled.getValue(false))
+        return true;
+
+    //If not locally attached then there is no benefit in reading remotely
+    if (!slice.onAttachedStorage(copy))
+        return true;
+
+    //If the file is not local then execute it remotely
+    if (!slice.isLocal(copy))
+        return false;
+
+    StringBuffer localPath;
+    slice.getURL(localPath, copy);
+    if (forceRemoteRead.getValue(testForceRemote(localPath)))
+        return false;
+    return true;
+}
+
+
+CHThorGenericDiskReadBaseActivity::CHThorGenericDiskReadBaseActivity(IAgentContext &_agent, unsigned _activityId, unsigned _subgraphId, IHThorNewDiskReadBaseArg &_arg, IHThorCompoundBaseArg & _segHelper, ThorActivityKind _kind, EclGraph & _graph, IPropertyTree *_node)
+: CHThorActivityBase(_agent, _activityId, _subgraphId, _arg, _kind, _graph), helper(_arg), segHelper(_segHelper), remoteReadChecker(_agent.queryWorkUnit())
+{
+    helper.setCallback(this);
+    expectedDiskMeta = helper.queryDiskRecordSize();
+    projectedDiskMeta = helper.queryProjectedDiskRecordSize();
+    isCodeSigned = false;
+    if (_node)
+    {
+        const char *recordTranslationModeHintText = _node->queryProp("hint[@name='layouttranslation']/@value");
+        if (recordTranslationModeHintText)
+            recordTranslationModeHint = getTranslationMode(recordTranslationModeHintText, true);
+        isCodeSigned = isActivityCodeSigned(*_node);
+    }
+
+    grouped = ((helper.getFlags() & TDXgrouped) != 0);
+    inputOptions.setown(createPTree());
+    inputOptions->setPropBool("@grouped", grouped);
+    inputOptions->setPropBool("@forceCompressed", (helper.getFlags() & TDXcompress) != 0);
+    if (helper.getFlags() & TDRoptional)
+        inputOptions->setPropBool("@optional", true);
+    if ((helper.getFlags() & TDRcloneappendvirtual) != 0)
+        inputOptions->setPropBool("@cloneAppendVirtuals", true);
+
+    CPropertyTreeWriter writer(ensurePTree(inputOptions, "formatOptions"));
+    helper.getFormatOptions(writer);
+
+    outputGrouped = helper.queryOutputMeta()->isGrouped();  // It is possible for input to be incorrectly marked as grouped, and input not or vice-versa
+    bool isTemporary = (helper.getFlags() & (TDXtemporary | TDXjobtemp)) != 0;
+    files.init(this, agent.queryWuid(), isTemporary, agent.queryResolveFilesLocally(), isCodeSigned, agent.queryCodeContext()->queryUserDescriptor(), expectedDiskMeta);
+    if (isTemporary)
+    {
+        StringBuffer spillPath;
+        agent.getTempfileBase(spillPath);
+
+        //Should probably be in eclagent
+        spillPlane.setown(createPTree("planes"));
+        spillPlane->setProp("@name", "localspill");
+        spillPlane->setProp("@prefix", spillPath);
+    }
+}
+
+CHThorGenericDiskReadBaseActivity::~CHThorGenericDiskReadBaseActivity()
+{
+    close();
+}
+
+void CHThorGenericDiskReadBaseActivity::ready()
+{
+    CHThorActivityBase::ready();
+
+    opened = false;
+    curSlice = NotFound;
+
+    resolveFile();
+
+    fieldFilters.kill();
+    segHelper.createSegmentMonitors(this);
+}
+
+void CHThorGenericDiskReadBaseActivity::stop()
+{
+    close();
+    CHThorActivityBase::stop();
+}
+
+unsigned __int64 CHThorGenericDiskReadBaseActivity::getFilePosition(const void * row)
+{
+    //These functions do not need to be implemented - they will be implemented by the translation layer
+    throwUnexpected();
+}
+
+unsigned __int64 CHThorGenericDiskReadBaseActivity::getLocalFilePosition(const void * row)
+{
+    throwUnexpected();
+}
+
+void CHThorGenericDiskReadBaseActivity::noteException(unsigned severity, unsigned code, const char * text)
+{
+    //MORE: This should really supply the activity and the scope - a general issue for hthor errors...
+    agent.addWuExceptionEx(text, code, severity, MSGAUD_user, "hthor");
+}
+
+
+const char * CHThorGenericDiskReadBaseActivity::queryLogicalFilename(const void * row)
+{
+    throwUnexpected();
+}
+
+void CHThorGenericDiskReadBaseActivity::resolveFile()
+{
+    //If in a child query, and the filenames haven't changed, the information about the resolved filenames will also not have changed
+    //Assume that is also true for format properties - require dynamic if they are to be recalculated.
+    if (resolved && !(helper.getFlags() & (TDXvarfilename|TDRdynformatoptions)))
+        return;
+    resolved = true;
+
+    //Update the inputOptions and formatOptions if they depend on the current context
+    curInputOptions.set(inputOptions);
+    //Check for encryption key
+    void *k;
+    size32_t kl;
+    helper.getEncryptKey(kl,k);
+    if (kl || (helper.getFlags() & TDRdynformatoptions))
+    {
+        curInputOptions.setown(createPTreeFromIPT(inputOptions));
+        if (kl)
+        {
+            curInputOptions->setPropBin("encryptionKey", kl, k);
+            curInputOptions->setPropBool("blockcompressed", true);
+            curInputOptions->setPropBool("compressed", true);
+        }
+
+        if (helper.getFlags() & TDRdynformatoptions)
+        {
+            Owned<IPropertyTree> helperFormatOptions = createPTree("formatOptions");
+            CPropertyTreeWriter writer(helperFormatOptions);
+            helper.getFormatDynOptions(writer);
+
+            IPropertyTree * curFormatOptions = ensurePTree(curInputOptions, "formatOptions");
+            mergeConfiguration(*curFormatOptions, *helperFormatOptions, nullptr, true);
+        }
+    }
+
+    //Extract meta information from the helper.  Another (possibly more efficient) alternative to an IPropertyTree would be a class.
+    bool isTemporary = (helper.getFlags() & (TDXtemporary | TDXjobtemp)) != 0;
+    OwnedRoxieString fileName(helper.getFileName());
+    if (isTemporary)
+    {
+        StringBuffer mangledFilename;
+        mangleLocalTempFilename(mangledFilename, fileName, agent.queryWuid());    // should this occur inside setEclFilename?
+        curInputOptions->setPropBool("@singlePartNoSuffix", true);
+        files.setTempFilename(mangledFilename, curInputOptions, spillPlane);
+    }
+    else
+    {
+        StringBuffer lfn;
+        expandLogicalFilename(lfn, fileName, agent.queryWorkUnit(), false, false);
+        files.setEclFilename(lfn, curInputOptions);
+    }
+    slices.clear();
+    files.calcPartition(slices, 1, 0, false, true);
+    curSlice = 0;
+}
+
+void CHThorGenericDiskReadBaseActivity::close()
+{
+    closepart();
+    if (activeSlice)
+        activeSlice->setAccessed();
+}
+
+void CHThorGenericDiskReadBaseActivity::closepart()
+{
+    if (activeReader)
+    {
+        activeReader->clearInput();
+        activeReader = nullptr;
+        activeSlice = nullptr;
+    }
+}
+
+bool CHThorGenericDiskReadBaseActivity::openFirstPart()
+{
+    if (openFilePart(0U))
+        return true;
+    setEmptyStream();
+    return false;
+}
+
+bool CHThorGenericDiskReadBaseActivity::openNextPart()
+{
+    if (curSlice == NotFound)
+        return false;
+
+    if (activeSlice)
+        closepart();
+
+    if (openFilePart(curSlice+1))
+        return true;
+    setEmptyStream();
+    return false;
+}
+
+void CHThorGenericDiskReadBaseActivity::initStream(CLogicalFileSlice * slice, IDiskRowReader * reader)
+{
+    activeSlice = slice;
+    activeReader = reader;
+    inputRowStream = reader->queryAllocatedRowStream(rowAllocator);
+
+    StringBuffer report("Reading file ");
+    activeSlice->getTracingFilename(report);
+    agent.reportProgress(report.str());
+}
+
+void CHThorGenericDiskReadBaseActivity::setEmptyStream()
+{
+    inputRowStream = queryNullDiskRowStream();
+    finishedParts = true;
+}
+
+IDiskRowReader * CHThorGenericDiskReadBaseActivity::ensureRowReader(const char * format, bool streamRemote, unsigned expectedCrc, IOutputMetaData & expected, unsigned projectedCrc, IOutputMetaData & projected, unsigned actualCrc, IOutputMetaData & actual, CLogicalFileSlice * slice)
+{
+    bool translateFromActual = strsame(format, slice->queryFormat());
+    //Backwards compatibility - there should be an option to override this
+    if (strsame(format, "csv") || strsame(format, "xml"))
+        translateFromActual = false;
+
+    //If the actual and expected file formats do not translate from the actual file format - use the expected format instead
+    Owned<IDiskReadMapping> mapping;
+    if (translateFromActual)
+        mapping.setown(createDiskReadMapping(getLayoutTranslationMode(), format, actualCrc, actual, expectedCrc, expected, projectedCrc, projected, slice->queryFileMeta()));
+    else
+        mapping.setown(createDiskReadMapping(getLayoutTranslationMode(), format, expectedCrc, expected, expectedCrc, expected, projectedCrc, projected, slice->queryFileMeta()));
+
+    ForEachItemIn(i, readers)
+    {
+        IDiskRowReader & cur = readers.item(i);
+        if (cur.matches(format, streamRemote, mapping))
+            return &cur;
+    }
+    IDiskRowReader * reader = createDiskReader(format, streamRemote, mapping);
+    readers.append(*reader);
+    return reader;
+}
+
+bool CHThorGenericDiskReadBaseActivity::openFilePart(unsigned whichSlice)
+{
+    for (;;)
+    {
+        if (whichSlice >= slices.size())
+        {
+            curSlice = NotFound;
+            return false;
+        }
+
+        if (openFilePart(&slices[whichSlice]))
+        {
+            curSlice = whichSlice;
+            activeSlice = &slices[whichSlice];
+            return true;
+        }
+
+        whichSlice++;
+    }
+}
+
+bool CHThorGenericDiskReadBaseActivity::openFilePart(CLogicalFileSlice * nextSlice)
+{
+    unsigned expectedCrc = helper.getDiskFormatCrc();
+    unsigned projectedCrc = helper.getProjectedFormatCrc();
+    unsigned actualCrc = nextSlice->queryFile()->queryActualCrc();
+    IOutputMetaData * actualDiskMeta = nextSlice->queryFile()->queryActualMeta();
+
+    bool tryRemoteStream = actualDiskMeta->queryTypeInfo()->canInterpret() && actualDiskMeta->queryTypeInfo()->canSerialize() &&
+                           projectedDiskMeta->queryTypeInfo()->canInterpret() && projectedDiskMeta->queryTypeInfo()->canSerialize();
+
+
+    /*
+     * If a file part can be accessed local, then read it locally
+     * If a file part supports a remote stream, then use that
+     * Otherwise failover to the legacy remote access.
+     */
+    const char * format = helper.queryFormat();
+    // If format is not specified in the ECL then it is deduced from the file.  It must be the same for all copies of a file part
+    if (!format)
+        format = nextSlice->queryFormat();
+
+    Owned<IException> saveOpenExc;
+    StringBuffer filenamelist;
+    std::vector<unsigned> remoteCandidates;
+
+    // scan for local part 1st
+    //MORE: Order of copies should be optimized at this point....
+    unsigned numCopies = nextSlice->getNumCopies();
+    for (unsigned copy=0; copy<numCopies; copy++)
+    {
+        if (remoteReadChecker.onlyReadLocally(*nextSlice, copy))
+        {
+            IDiskRowReader * reader = ensureRowReader(format, false, expectedCrc, *expectedDiskMeta, projectedCrc, *projectedDiskMeta, actualCrc, *actualDiskMeta, nextSlice);
+            if (reader->setInputFile(*nextSlice, fieldFilters, copy))
+            {
+                initStream(nextSlice, reader);
+                return true;
+            }
+        }
+        else
+            remoteCandidates.push_back(copy);
+    }
+
+    //First try remote streaming, and if that does not succeed, fall back to remote reading.
+    bool allowFallbackToNonStreaming = true;
+    for (;;)
+    {
+        for (unsigned copy: remoteCandidates)
+        {
+            StringBuffer filename;
+            nextSlice->getURL(filename, copy);
+            filenamelist.append('\n').append(filename);
+            try
+            {
+                IDiskRowReader * reader = ensureRowReader(format, tryRemoteStream, expectedCrc, *expectedDiskMeta, projectedCrc, *projectedDiskMeta, actualCrc, *actualDiskMeta, nextSlice);
+                if (reader->setInputFile(*nextSlice, fieldFilters, copy))
+                {
+                    initStream(nextSlice, reader);
+                    return true;
+                }
+            }
+            catch (IException *E)
+            {
+                saveOrRelease(saveOpenExc, E);
+            }
+        }
+
+        if (!tryRemoteStream || !allowFallbackToNonStreaming)
+            break;
+        tryRemoteStream = false;
+    }
+
+    if (!(helper.getFlags() & TDRoptional))
+    {
+        //Should this be unconditional?  If the logical file exists, but the file can't be opened, it isn't really what OPT means.
+        StringBuffer s;
+        StringBuffer tracingName;
+        nextSlice->getTracingFilename(tracingName);
+
+        if (filenamelist)
+        {
+            if (saveOpenExc.get())
+            {
+                if (!nextSlice->isLogicalFile())
+                    saveOpenExc->errorMessage(s);
+                else
+                {
+                    s.append("Could not open logical file ").append(tracingName).append(" in any of these locations:").append(filenamelist).append(" (");
+                    saveOpenExc->errorMessage(s).append(")");
+                }
+            }
+            else
+                s.append("Could not open logical file ").append(tracingName).append(" in any of these locations:").append(filenamelist).append(" (").append((unsigned)GetLastError()).append(")");
+        }
+        else
+        {
+            const char * filename = nextSlice->queryFile()->queryLogicalFilename();
+            s.append("Could not open local physical file ").append(filename).append(" (").append((unsigned)GetLastError()).append(")");
+        }
+        agent.fail(1, s.str());
+    }
+    return false;
+}
+
+
+bool CHThorGenericDiskReadBaseActivity::openNext()
+{
+    return openNextPart();
+}
+
+void CHThorGenericDiskReadBaseActivity::open()
+{
+    assertex(!opened);
+    opened = true;
+    if (!segHelper.canMatchAny())
+    {
+        setEmptyStream();
+    }
+    else
+    {
+        if (!openFirstPart())
+            setEmptyStream();
+    }
+}
+
+void CHThorGenericDiskReadBaseActivity::append(FFoption option, const IFieldFilter * filter)
+{
+    if (filter->isWild())
+        filter->Release();
+    else
+        fieldFilters.append(*filter);
+}
+
+//=====================================================================================================
+
+CHThorGenericDiskReadActivity::CHThorGenericDiskReadActivity(IAgentContext &_agent, unsigned _activityId, unsigned _subgraphId, IHThorNewDiskReadArg &_arg, ThorActivityKind _kind, EclGraph & _graph, IPropertyTree *_node)
+: CHThorGenericDiskReadBaseActivity(_agent, _activityId, _subgraphId, _arg, _arg, _kind, _graph, _node), helper(_arg), outBuilder(NULL)
+{
+    hasMatchFilter = helper.hasMatchFilter();
+    useRawStream = hasMatchFilter || helper.needTransform();
+}
+
+void CHThorGenericDiskReadActivity::ready()
+{
+    PARENT::ready();
+    outBuilder.setAllocator(rowAllocator);
+    lastGroupProcessed = processed;
+    needTransform = helper.needTransform() || fieldFilters.length();
+    limit = helper.getRowLimit();
+    if (helper.getFlags() & TDRlimitskips)
+        limit = (unsigned __int64) -1;
+    stopAfter = helper.getChooseNLimit();
+    if (!helper.transformMayFilter() && !helper.hasMatchFilter())
+        remoteLimit = stopAfter;
+    finishedParts = false;
+}
+
+
+void CHThorGenericDiskReadActivity::stop()
+{
+    outBuilder.clear();
+    PARENT::stop();
+}
+
+
+void CHThorGenericDiskReadActivity::onLimitExceeded()
+{
+    if ( agent.queryCodeContext()->queryDebugContext())
+        agent.queryCodeContext()->queryDebugContext()->checkBreakpoint(DebugStateLimit, NULL, static_cast<IActivityBase *>(this));
+    helper.onLimitExceeded();
+}
+
+const void *CHThorGenericDiskReadActivity::nextRow()
+{
+    //Avoid this check on each row- e.g., initialising streams with a null stream, which returns eof, and falls through to eof processing
+    if (!opened) open();
+
+    // Only check once per row returned.  Potentially means that heavily filtered datasets may wait a long time to check for abort
+    queryUpdateProgress();
+
+    //Avoid this test...  Combine the limit checking with choosen, and have choosen/limit triggering set the
+    //stream to a special no more rows stream so that subsequent calls do not read records.
+    if ((processed - initialProcessed) >= stopAfter)
+        return nullptr;
+
+    try
+    {
+        if (useRawStream)
+        {
+            for (;;)
+            {
+                //Returns a row in the serialized form of the projected format
+                size32_t nextSize;
+                const byte * next = (const byte *)inputRowStream->nextRow(nextSize);
+                if (!isSpecialRow(next))
+                {
+                    if (likely(!hasMatchFilter || helper.canMatch(next)))
+                    {
+                        size32_t thisSize = helper.transform(outBuilder.ensureRow(), next);
+                        if (thisSize != 0)
+                        {
+                            if (unlikely((processed - initialProcessed) >= limit))
+                            {
+                                outBuilder.clear();
+                                onLimitExceeded();
+                                return nullptr;
+                            }
+                            processed++;
+                            return outBuilder.finalizeRowClear(thisSize);
+                        }
+                    }
+                }
+                else
+                {
+                    switch (getSpecialRowType(next))
+                    {
+                    case SpecialRow::eof:
+                        if (!openNext())
+                            return next; // i.e. eof
+                        //rawStream will have changed, but it cannot change into a rowStream
+                        break;
+                    case SpecialRow::eos:
+                        return next;
+                    case SpecialRow::eog:
+                        if (outputGrouped && (processed != lastGroupProcessed))
+                        {
+                            lastGroupProcessed = processed;
+                            //MORE: Change to return next - i.e. an eog marker
+                            return nullptr;
+                        }
+                        break;
+                    default:
+                        throwUnexpected();
+                    }
+                }
+            }
+        }
+        else
+        {
+            //This branch avoids a memcpy from actual to projected followed by a deserialize - since it can map directly
+            //May be more efficient to use this branch if serialized==deserialized and there is a filter, but no transform.
+            //It would be possibel to have two (or more) different implementations, which were created based on
+            //whether there was a limit, a transform etc., but unlikely to save more than a couple of boolean tests.
+            for (;;)
+            {
+                const byte * next = (const byte *)inputRowStream->nextRow();
+                if (!isSpecialRow(next))
+                {
+                    if (unlikely((processed - initialProcessed) >= limit))
+                    {
+                        ReleaseRoxieRow(next);
+                        onLimitExceeded();
+                        return nullptr;
+                    }
+                    processed++;
+                    return next;
+                }
+                else
+                {
+                    switch (getSpecialRowType(next))
+                    {
+                    case SpecialRow::eof:
+                        if (!openNext())
+                            return next;
+                        //rowStream will have changed
+                        break;
+                    case SpecialRow::eos:
+                        return next;
+                    case SpecialRow::eog:
+                        if (processed != lastGroupProcessed)
+                        {
+                            lastGroupProcessed = processed;
+                            return nullptr;
+                        }
+                        break;
+                    default:
+                        throwUnexpected();
+                    }
+                }
+            }
+        }
+    }
+    catch(IException * e)
+    {
+        throw makeWrappedException(e);
+    }
+    return NULL;
+}
+
+//=====================================================================================================
+
 MAKEFACTORY(DiskWrite);
 MAKEFACTORY(Iterate);
 MAKEFACTORY(Filter);
@@ -11358,6 +11922,11 @@ extern HTHOR_API IHThorActivity *createHashAggregateActivity(IAgentContext &_age
     return new CHThorHashAggregateActivity(_agent, _activityId, _subgraphId, arg, kind, _graph, _isGroupedAggregate);
 }
 
+extern HTHOR_API IHThorActivity *createGenericDiskReadActivity(IAgentContext &_agent, unsigned _activityId, unsigned _subgraphId, IHThorNewDiskReadArg &arg, ThorActivityKind kind, EclGraph & _graph, IPropertyTree * node)
+{
+    return new CHThorGenericDiskReadActivity(_agent, _activityId, _subgraphId, arg, kind, _graph, node);
+}
+
 MAKEFACTORY(Null);
 MAKEFACTORY(SideEffect);
 MAKEFACTORY(Action);
diff --git a/ecl/hthor/hthor.hpp b/ecl/hthor/hthor.hpp
index 31bb5e88b..78644a722 100644
--- a/ecl/hthor/hthor.hpp
+++ b/ecl/hthor/hthor.hpp
@@ -173,6 +173,7 @@ extern HTHOR_API IHThorActivity *createDiskCountActivity(IAgentContext &_agent,
 extern HTHOR_API IHThorActivity *createDiskGroupAggregateActivity(IAgentContext &_agent, unsigned _activityId, unsigned _subgraphId, IHThorDiskGroupAggregateArg &arg, ThorActivityKind kind, EclGraph & _graph, IPropertyTree *node);
 
 extern HTHOR_API IHThorActivity *createNewDiskReadActivity(IAgentContext &_agent, unsigned _activityId, unsigned _subgraphId, IHThorNewDiskReadArg &arg, ThorActivityKind kind, EclGraph & _graph, IPropertyTree *node);
+extern HTHOR_API IHThorActivity *createGenericDiskReadActivity(IAgentContext &_agent, unsigned _activityId, unsigned _subgraphId, IHThorNewDiskReadArg &arg, ThorActivityKind kind, EclGraph & _graph, IPropertyTree * node);
 
 extern HTHOR_API IHThorActivity *createIndexReadActivity(IAgentContext &_agent, unsigned _activityId, unsigned _subgraphId, IHThorIndexReadArg &arg, ThorActivityKind kind, EclGraph & _graph, IPropertyTree *_node);
 extern HTHOR_API IHThorActivity *createIndexNormalizeActivity(IAgentContext &_agent, unsigned _activityId, unsigned _subgraphId, IHThorIndexNormalizeArg &arg, ThorActivityKind kind, EclGraph & _graph, IPropertyTree *_node);
diff --git a/ecl/hthor/hthor.ipp b/ecl/hthor/hthor.ipp
index 9ff902fc5..28f456ee4 100644
--- a/ecl/hthor/hthor.ipp
+++ b/ecl/hthor/hthor.ipp
@@ -43,6 +43,8 @@
 #include "rtlrecord.hpp"
 #include "roxiemem.hpp"
 #include "roxierowbuff.hpp"
+
+#include "thormeta.hpp"
 #include "thorread.hpp"
 
 roxiemem::IRowManager * queryRowManager();
@@ -2927,7 +2929,6 @@ protected:
     {
         IDistributedFile * file;
         Owned<IOutputMetaData> actualMeta;
-        Owned<const IPropertyTree> formatOptions;
         Owned<const IPropertyTree> meta;
         unsigned actualCrc;
     };
@@ -3043,6 +3044,169 @@ protected:
 };
 
 
+//---------------------------------------------------------------------------------------------------------------------
+
+//Could be a useful general class for caching workunit debug and tree values
+template <class T>
+class CachedValue
+{
+public:
+    T getValue(const T dft = false) { return hasValue ? value : dft; }
+
+protected:
+    bool hasValue = false;
+    T value = false;
+};
+
+class CachedBoolValue : public CachedValue<bool>
+{
+public:
+    CachedBoolValue(IConstWorkUnit * wu, const char * name)
+    {
+        hasValue = wu->hasDebugValue(name);
+        if (hasValue)
+            value = wu->getDebugValueBool(name, false);
+    }
+
+    CachedBoolValue(IPropertyTree * tree, const char * name)
+    {
+        hasValue = tree->queryProp(name) != nullptr;
+        if (hasValue)
+            value = tree->getPropBool(name);
+    }
+};
+
+class RemoteReadChecker
+{
+public:
+    RemoteReadChecker(IConstWorkUnit * wu)
+    : forceRemoteDisabled(wu, "forceRemoteDisabled"), forceRemoteRead(wu, "forceRemoteRead")
+    {
+    }
+
+    bool onlyReadLocally(const CLogicalFileSlice & nextSlice, unsigned copy);
+
+protected:
+    CachedBoolValue forceRemoteDisabled;
+    CachedBoolValue forceRemoteRead;
+};
+
+//---------------------------------------------------------------------------------------------------------------------
+
+class CHThorGenericDiskReadBaseActivity : public CHThorActivityBase, implements IThorDiskCallback, implements IIndexReadContext, public IFileCollectionContext
+{
+protected:
+    IHThorNewDiskReadBaseArg &helper;
+    IHThorCompoundBaseArg & segHelper;
+    IDiskRowReader * activeReader = nullptr;
+    CLogicalFileCollection files;
+    Owned<IPropertyTree> spillPlane;
+    std::vector<CLogicalFileSlice> slices;
+    IArrayOf<IDiskRowReader> readers;
+    IDiskRowStream * inputRowStream = nullptr;
+    RemoteReadChecker remoteReadChecker;
+    IOutputMetaData *expectedDiskMeta = nullptr;
+    IOutputMetaData *projectedDiskMeta = nullptr;
+    IConstArrayOf<IFieldFilter> fieldFilters;  // These refer to the expected layout
+    Owned<IPropertyTree> inputOptions;
+    Owned<IPropertyTree> curInputOptions;
+    CLogicalFileSlice * activeSlice = nullptr;
+    unsigned curSlice = 0;
+    RecordTranslationMode recordTranslationModeHint = RecordTranslationMode::Unspecified;
+    bool useRawStream = false; // Constant for the lifetime of the activity
+    bool grouped = false;
+    bool outputGrouped = false;
+    bool opened = false;
+    bool finishedParts = false;
+    bool isCodeSigned = false;
+    bool resolved = false;
+    unsigned __int64 stopAfter = 0;
+
+protected:
+    void close();
+    void resolveFile();
+    StringBuffer &translateLFNtoLocal(const char *filename, StringBuffer &localName);
+
+    inline void queryUpdateProgress()
+    {
+        agent.reportProgress(NULL);
+    }
+
+    RecordTranslationMode getLayoutTranslationMode()
+    {
+        if (recordTranslationModeHint != RecordTranslationMode::Unspecified)
+            return recordTranslationModeHint;
+        return agent.getLayoutTranslationMode();
+    }
+
+public:
+    CHThorGenericDiskReadBaseActivity(IAgentContext &agent, unsigned _activityId, unsigned _subgraphId, IHThorNewDiskReadBaseArg &_arg, IHThorCompoundBaseArg & _segHelper, ThorActivityKind _kind, EclGraph & _graph, IPropertyTree *node);
+    ~CHThorGenericDiskReadBaseActivity();
+    IMPLEMENT_IINTERFACE_USING(CHThorActivityBase)
+
+    virtual void ready();
+    virtual void stop();
+
+    IHThorInput *queryOutput(unsigned index)                { return this; }
+
+//interface IHThorInput
+    virtual bool isGrouped()                                { return outputGrouped; }
+    virtual IOutputMetaData * queryOutputMeta() const       { return outputMeta; }
+
+//interface IFilePositionProvider
+    virtual unsigned __int64 getFilePosition(const void * row);
+    virtual unsigned __int64 getLocalFilePosition(const void * row);
+    virtual const char * queryLogicalFilename(const void * row);
+    virtual const byte * lookupBlob(unsigned __int64 id) { UNIMPLEMENTED; }
+
+//interface IIndexReadContext
+    virtual void append(IKeySegmentMonitor *segment) override { throwUnexpected(); }
+    virtual void append(FFoption option, const IFieldFilter * filter) override;
+
+//interface IFileCollectionContext
+    virtual void noteException(unsigned severity, unsigned code, const char * text) override;
+
+protected:
+    bool openFirstPart();
+    void initStream(CLogicalFileSlice * slice, IDiskRowReader * reader);
+    bool openFilePart(unsigned whichSlice);
+    bool openFilePart(CLogicalFileSlice * nextSlice);
+    void setEmptyStream();
+
+    virtual void open();
+    virtual bool openNext();
+    virtual void closepart();
+
+    bool openNextPart();
+    IDiskRowReader * ensureRowReader(const char * format, bool streamRemote, unsigned expectedCrc, IOutputMetaData & expected, unsigned projectedCrc, IOutputMetaData & projected, unsigned actualCrc, IOutputMetaData & actual, CLogicalFileSlice * slice);
+};
+
+
+class CHThorGenericDiskReadActivity : public CHThorGenericDiskReadBaseActivity
+{
+    typedef CHThorGenericDiskReadBaseActivity PARENT;
+protected:
+    IHThorNewDiskReadArg &helper;
+    bool needTransform = false;
+    bool hasMatchFilter = false;
+    unsigned __int64 lastGroupProcessed = 0;
+    RtlDynamicRowBuilder outBuilder;
+    unsigned __int64 limit = 0;
+    unsigned __int64 remoteLimit = 0;
+
+public:
+    CHThorGenericDiskReadActivity(IAgentContext &agent, unsigned _activityId, unsigned _subgraphId, IHThorNewDiskReadArg &_arg, ThorActivityKind _kind, EclGraph & _graph, IPropertyTree *node);
+
+    virtual void ready();
+    virtual void stop();
+    virtual bool needsAllocator() const { return true; }
+
+    //interface IHThorInput
+    virtual const void *nextRow();
+
+protected:
+    void onLimitExceeded();
+};
 
 
 #define MAKEFACTORY(NAME) \
diff --git a/ecl/hthor/hthorkey.cpp b/ecl/hthor/hthorkey.cpp
index cf2d484bd..306bbd8a9 100644
--- a/ecl/hthor/hthorkey.cpp
+++ b/ecl/hthor/hthorkey.cpp
@@ -2871,7 +2871,7 @@ public:
         left = NULL;
         prev = NULL;
         next = NULL;
-        atomic_set(&endMarkersPending,0);
+        endMarkersPending = 0;
         groupStart = NULL;
         matchcount = 0;
     }
@@ -2885,12 +2885,12 @@ public:
         if (_groupStart)
         {
             groupStart = _groupStart;
-            atomic_inc(&_groupStart->endMarkersPending);
+            ++_groupStart->endMarkersPending;
         }
         else
         {
             groupStart = this;
-            atomic_set(&endMarkersPending, 1);
+            endMarkersPending = 1;
         }
         matchcount = 0;
     }
@@ -2912,12 +2912,12 @@ public:
     inline void notePending()
     {
 //      assertex(!complete());
-        atomic_inc(&groupStart->endMarkersPending);
+        ++groupStart->endMarkersPending;
     }
 
     inline bool complete() const
     {
-        return atomic_read(&groupStart->endMarkersPending) == 0;
+        return groupStart->endMarkersPending == 0;
     }
 
     inline bool inGroup(CJoinGroup *leader) const
@@ -2931,7 +2931,7 @@ public:
         //Another completing group could cause this group to be processed once endMarkersPending is set to 0
         //So link this object to ensure it is not disposed of while this function is executing
         Linked<CJoinGroup> saveThis(this);
-        if (atomic_dec_and_test(&groupStart->endMarkersPending))
+        if (--groupStart->endMarkersPending == 0)
         {
             join->onComplete(groupStart);
         }
@@ -2966,7 +2966,7 @@ protected:
     const void *left;
     unsigned matchcount;
     CIArrayOf<MatchSet> matchsets;
-    atomic_t endMarkersPending;
+    std::atomic<unsigned> endMarkersPending;
     IJoinProcessor *join = nullptr;
     mutable CriticalSection crit;
     CJoinGroup *groupStart;
@@ -3439,9 +3439,9 @@ class CHThorKeyedJoinActivity  : public CHThorThreadedActivityBase, implements I
     Owned<JoinGroupPool> pool;
     QueueOf<const void, true> pending;
     CriticalSection statsCrit, imatchCrit, fmatchCrit;
-    atomic_t prefiltered;
-    atomic_t postfiltered;
-    atomic_t skips;
+    RelaxedAtomic<unsigned> prefiltered;
+    RelaxedAtomic<unsigned> postfiltered;
+    RelaxedAtomic<unsigned> skips;
     unsigned seeks;
     unsigned scans;
     unsigned wildseeks;
@@ -3460,9 +3460,9 @@ public:
     CHThorKeyedJoinActivity(IAgentContext &_agent, unsigned _activityId, unsigned _subgraphId, IHThorKeyedJoinArg &_arg, ThorActivityKind _kind, EclGraph & _graph, IPropertyTree *_node)
         : CHThorThreadedActivityBase(_agent, _activityId, _subgraphId, _arg, _arg, _kind, _graph, _arg.queryDiskRecordSize(), _node), helper(_arg)
     {
-        atomic_set(&prefiltered, 0);
-        atomic_set(&postfiltered, 0);
-        atomic_set(&skips, 0);
+        prefiltered = 0;
+        postfiltered = 0;
+        skips = 0;
         seeks = 0;
         scans = 0;
         eclKeySize.set(helper.queryIndexRecordSize());
@@ -3674,7 +3674,7 @@ public:
         CriticalBlock proc(fmatchCrit);
         bool ret = helper.fetchMatch(ms->queryJoinGroup()->queryLeft(), right);
         if (!ret)
-            atomic_inc(&postfiltered);
+            ++postfiltered;
         return ret;
     }
 
@@ -3682,7 +3682,7 @@ public:
     {
         bool ret = helper.leftCanMatch(_left);
         if (!ret)
-            atomic_inc(&prefiltered);
+            ++prefiltered;
         return ret;
     }
 
@@ -3802,7 +3802,7 @@ public:
                 }
                 else
                 {
-                    atomic_inc(&skips);
+                    ++skips;
                 }
             }
             else
@@ -3833,7 +3833,7 @@ public:
                             }
                             else
                             {
-                                atomic_inc(&skips);
+                                ++skips;
                             }
                         }
                         catch(IException * e)
@@ -3883,7 +3883,7 @@ public:
                                 }
                                 else
                                 {
-                                    atomic_inc(&skips);
+                                    ++skips;
                                 }
                             }
                             catch(IException * e)
@@ -3926,7 +3926,7 @@ public:
                                 }
                                 else
                                 {
-                                    atomic_inc(&skips);
+                                    ++skips;
                                 }
                             }
                             catch(IException * e)
@@ -3973,7 +3973,7 @@ public:
                         }
                         else
                         {
-                            atomic_inc(&skips);
+                            ++skips;
                         }
                     }
                     catch(IException * e)
@@ -4088,7 +4088,7 @@ public:
         }
         else
         {
-            atomic_inc(&postfiltered);
+            ++postfiltered;
         }
         return false;
     }
@@ -4115,9 +4115,9 @@ public:
     {
         CHThorThreadedActivityBase::updateProgress(progress);
         StatsActivityScope scope(progress, activityId);
-        progress.addStatistic(StNumPreFiltered, atomic_read(&prefiltered));
-        progress.addStatistic(StNumPostFiltered, atomic_read(&postfiltered));
-        progress.addStatistic(StNumIndexSkips, atomic_read(&skips));
+        progress.addStatistic(StNumPreFiltered, prefiltered);
+        progress.addStatistic(StNumPostFiltered, postfiltered);
+        progress.addStatistic(StNumIndexSkips, skips);
         progress.addStatistic(StNumIndexSeeks, seeks);
         progress.addStatistic(StNumIndexScans, scans);
         progress.addStatistic(StNumIndexWildSeeks, wildseeks);
diff --git a/ecl/regress/alienread_bad.ecl b/ecl/regress/alienread_bad.ecl
new file mode 100644
index 000000000..c8d7a1ad8
--- /dev/null
+++ b/ecl/regress/alienread_bad.ecl
@@ -0,0 +1,58 @@
+/*##############################################################################
+
+    HPCC SYSTEMS software Copyright (C) 2021 HPCC SystemsÂ®.
+
+    Licensed under the Apache License, Version 2.0 (the "License");
+    you may not use this file except in compliance with the License.
+    You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
+############################################################################## */
+
+//check that virtual fields in the middle of a record with alein datatypes reports an error.
+#option ('targetClusterType', 'hthor');
+#option ('genericDiskReads', true);
+
+import lib_stringlib;
+prefix := 'regress::'+ __TARGET_PLATFORM__ + '::';
+
+extractXStringLength(data x, unsigned len) := transfer(((data4)(x[1..len])), unsigned4);
+
+//A pretty weird type example - a length prefixed string, where the number of bytes used for the length is configurable...
+xstring(unsigned len) := type
+    export integer physicallength(data x) := extractXStringLength(x, len)+len;
+    export string load(data x) := (string)x[(len+1)..extractXStringLength(x, len)+len];
+    export data store(string x) := transfer(length(x), data4)[1..len]+(data)x;
+end;
+
+dstring(string del) := TYPE
+    export integer physicallength(string s) := StringLib.StringUnboundedUnsafeFind(s,del)+length(del)-1;
+    export string load(string s) := s[1..StringLib.StringUnboundedUnsafeFind(s,del)-1];
+    export string store(string s) := s+del; // Untested (vlength output generally broken)
+END;
+
+
+alienString := xstring(4);
+alienVarString := dstring('\000');
+
+alienRecordEx := RECORD
+    alienString         surname;
+    alienString         forename;
+    alienVarString      addr;
+    string4             extra;
+    unsigned        fpos{virtual(fileposition)};
+    alienVarString      extra2;
+    string          filename{virtual(logicalfilename)};
+    unsigned        lfpos{virtual(localfileposition)};
+END;
+
+filenameRaw := prefix+'alientest_raw';
+filenameAlien := prefix+'alientest_alien';
+
+output(DATASET(filenameRaw, alienRecordEx, THOR, HINT(layoutTranslation('alwaysEcl'))),,NAMED('RawAlien'));
diff --git a/ecl/regress/standaloneread.ecl b/ecl/regress/standaloneread.ecl
new file mode 100644
index 000000000..260afabc0
--- /dev/null
+++ b/ecl/regress/standaloneread.ecl
@@ -0,0 +1,5 @@
+ds := DATASET('localout1', { unsigned c }, XML('Dataset/Row') );
+ds2 := DATASET('subdir::localout1', { unsigned c }, XML('Dataset/Row') );
+
+output(ds, { c+1 },'localout2',csv,overwrite);
+output(ds, { c*2 },'subdir::localout2',csv,overwrite);
diff --git a/ecl/regress/standalonewrite.ecl b/ecl/regress/standalonewrite.ecl
new file mode 100644
index 000000000..0486f647a
--- /dev/null
+++ b/ecl/regress/standalonewrite.ecl
@@ -0,0 +1,5 @@
+ds := DATASET(10, transform({ unsigned c }, SELF.c := COUNTER));
+
+output(ds,,'localout1',xml,overwrite);
+
+output(ds,,'subdir::localout1',xml,overwrite);
diff --git a/esp/applications/eclservices/application.yaml b/esp/applications/eclservices/application.yaml
index 1682d7ede..0f6a3be46 100644
--- a/esp/applications/eclservices/application.yaml
+++ b/esp/applications/eclservices/application.yaml
@@ -9,7 +9,6 @@ application:
    - WsFileIO
    - WsPackageProcess
    - FileSpray
-   - ws_machine
    - ws_elk
    - ws_access
    - ws_account
diff --git a/esp/applications/eclservices/eclservices.yaml b/esp/applications/eclservices/eclservices.yaml
index 5228313c2..0a79d66de 100644
--- a/esp/applications/eclservices/eclservices.yaml
+++ b/esp/applications/eclservices/eclservices.yaml
@@ -65,118 +65,4 @@ eclservices:
             description: JWT token cache
             default: false
             maxValSize: 32768
-   ws_machine:
-      excludePartitions: "/dev*,/sys*,/proc*,/run*,/boot"
-      monitorDaliFileServer: false
-      UseDefaultSSHUserID: false
-      UseDefaultPIDFileName: true
-      ProcessFilters:
-        Platform:
-        - name: Windows
-          ProcessFilter:
-          - name: any
-            Process:
-              name: dafilesrv
-          - name: AttrServerProcess
-            Process:
-              name: attrserver
-          - name: DaliProcess
-            Process:
-              name: daserver
-          - name: DfuServerProcess
-            multipleInstances: true
-            Process:
-              name: dfuserver
-          - name: EclCCServerProcess
-            multipleInstances: true
-            Process:
-              name: eclccserver
-          - name: EclServerProcess
-            multipleInstances: true
-            Process:
-              name: eclserver
-          - name: EspProcess
-            multipleInstances: true
-            Process:
-              - name: esp
-              - name: dafilesrv
-                remove: true
-          - name: FTSlaveProcess
-            Process:
-              name: ftslave
-          - name: RoxieServerProcess
-            Process:
-              name: roxie
-          - name: RoxieSlaveProcess
-            Process:
-              name: roxie
-          - name: SchedulerProcess
-            Process:
-              name: scheduler
-          - name: ThorMasterProcess
-            Process:
-              name: thormaster
-          - name: ThorSlaveProcess
-            Process:
-              name: thorslave
-          - name: SashaServerProcess
-            Process:
-              name: saserver
-          - name: Linux
-            ProcessFilter:
-            - name: any
-              Process:
-                name: dafilesrv
-            - name: AttrServerProcess
-              Process:
-                name: attrserver
-            - name: DaliProcess
-              Process:
-                name: daserver
-            - name: DfuServerProcess
-              multipleInstances: true
-              Process:
-                name: dfuserver
-            - name: EclCCServerProcess
-              multipleInstances: true
-              Process:
-                name: eclccserver
-            - name: EclServerProcess
-              multipleInstances: true
-              Process:
-                name: eclserver
-            - name: EspProcess
-              multipleInstances: true
-              Process:
-              - name: esp
-              - name: dafilesrv
-                remove: true
-            - name: FTSlaveProcess
-              Process:
-                name: ftslave
-            - name: RoxieServerProcess
-              Process:
-                name: roxie
-            - name: RoxieSlaveProcess
-              Process:
-                name: roxie
-            - name: SchedulerProcess
-              Process:
-                name: scheduler
-            - name: ThorMasterProcess
-              Process:
-                name: thormaster
-            - name: ThorSlaveProcess
-              Process:
-                name: thorslave
-            - name: SashaServerProcess
-              Process:
-                name: saserver
-            - name: GenesisServerProcess
-              multipleInstances: true
-              Process:
-              - name: mysql
-              - name: httpd
-              - name: atftpd
-              - name: dhcpd
-            
\ No newline at end of file
+            
diff --git a/esp/applications/eclservices/ldap_authorization_map.yaml b/esp/applications/eclservices/ldap_authorization_map.yaml
index 629510f38..58b55ca0c 100644
--- a/esp/applications/eclservices/ldap_authorization_map.yaml
+++ b/esp/applications/eclservices/ldap_authorization_map.yaml
@@ -135,17 +135,6 @@ ldap:
          -  path: FileIOAccess
             resource: FileIOAccess
             description: Access to files in dropzone
-      ws_machine:
-         Feature:
-         -  path: MachineInfoAccess
-            resource: MachineInfoAccess
-            description: Access to machine information
-         -  path: MetricsAccess
-            resource: MetricsAccess
-            description: Access to SNMP metrics information
-         -  path: ExecuteAccess
-            resource: ExecuteAccess
-            description: Access to remote execution
       ws_config:
          Feature:
          -  path: ConfigAccess
diff --git a/esp/applications/eclservices/plugins.yaml b/esp/applications/eclservices/plugins.yaml
index c107bf527..057d6e0ca 100644
--- a/esp/applications/eclservices/plugins.yaml
+++ b/esp/applications/eclservices/plugins.yaml
@@ -11,7 +11,6 @@ service_plugins:
   ws_elk: ws_elk
   ws_esdlconfig: ws_esdlconfig
   WsFileIO: ws_fileio
-  ws_machine: ws_machine
   WsPackageProcess: ws_packageprocess
   ws_store: ws_store
   WSESPControl: wsespcontrol
@@ -29,7 +28,6 @@ binding_plugins:
   ws_elk: ws_elk
   ws_esdlconfig: ws_esdlconfig
   WsFileIO: ws_fileio
-  ws_machine: ws_machine
   WsPackageProcess: ws_packageprocess
   ws_store: ws_store
   WsTopology: ws_topology
diff --git a/esp/applications/eclwatch/application.yaml b/esp/applications/eclwatch/application.yaml
index e81be06bb..6f880101b 100644
--- a/esp/applications/eclwatch/application.yaml
+++ b/esp/applications/eclwatch/application.yaml
@@ -9,7 +9,6 @@ application:
    - WsFileIO
    - WsPackageProcess
    - FileSpray
-   - ws_machine
    - ws_elk
    - ws_access
    - ws_account
diff --git a/esp/applications/eclwatch/eclwatch.yaml b/esp/applications/eclwatch/eclwatch.yaml
index ff66bdb2e..40e85c9fe 100644
--- a/esp/applications/eclwatch/eclwatch.yaml
+++ b/esp/applications/eclwatch/eclwatch.yaml
@@ -63,117 +63,3 @@ eclwatch:
             description: JWT token cache
             default: false
             maxValSize: 32768
-   ws_machine:
-      excludePartitions: "/dev*,/sys*,/proc*,/run*,/boot"
-      monitorDaliFileServer: false
-      UseDefaultSSHUserID: false
-      UseDefaultPIDFileName: true
-      ProcessFilters:
-        Platform:
-        - name: Windows
-          ProcessFilter:
-          - name: any
-            Process:
-              name: dafilesrv
-          - name: AttrServerProcess
-            Process:
-              name: attrserver
-          - name: DaliProcess
-            Process:
-              name: daserver
-          - name: DfuServerProcess
-            multipleInstances: true
-            Process:
-              name: dfuserver
-          - name: EclCCServerProcess
-            multipleInstances: true
-            Process:
-              name: eclccserver
-          - name: EclServerProcess
-            multipleInstances: true
-            Process:
-              name: eclserver
-          - name: EspProcess
-            multipleInstances: true
-            Process:
-              - name: esp
-              - name: dafilesrv
-                remove: true
-          - name: FTSlaveProcess
-            Process:
-              name: ftslave
-          - name: RoxieServerProcess
-            Process:
-              name: roxie
-          - name: RoxieSlaveProcess
-            Process:
-              name: roxie
-          - name: SchedulerProcess
-            Process:
-              name: scheduler
-          - name: ThorMasterProcess
-            Process:
-              name: thormaster
-          - name: ThorSlaveProcess
-            Process:
-              name: thorslave
-          - name: SashaServerProcess
-            Process:
-              name: saserver
-        - name: Linux
-          ProcessFilter:
-          - name: any
-            Process:
-              name: dafilesrv
-          - name: AttrServerProcess
-            Process:
-              name: attrserver
-          - name: DaliProcess
-            Process:
-              name: daserver
-          - name: DfuServerProcess
-            multipleInstances: true
-            Process:
-              name: dfuserver
-          - name: EclCCServerProcess
-            multipleInstances: true
-            Process:
-              name: eclccserver
-          - name: EclServerProcess
-            multipleInstances: true
-            Process:
-              name: eclserver
-          - name: EspProcess
-            multipleInstances: true
-            Process:
-            - name: esp
-            - name: dafilesrv
-              remove: true
-          - name: FTSlaveProcess
-            Process:
-              name: ftslave
-          - name: RoxieServerProcess
-            Process:
-              name: roxie
-          - name: RoxieSlaveProcess
-            Process:
-              name: roxie
-          - name: SchedulerProcess
-            Process:
-              name: scheduler
-          - name: ThorMasterProcess
-            Process:
-              name: thormaster
-          - name: ThorSlaveProcess
-            Process:
-              name: thorslave
-          - name: SashaServerProcess
-            Process:
-              name: saserver
-          - name: GenesisServerProcess
-            multipleInstances: true
-            Process:
-            - name: mysql
-            - name: httpd
-            - name: atftpd
-            - name: dhcpd
diff --git a/esp/applications/eclwatch/ldap_authorization_map.yaml b/esp/applications/eclwatch/ldap_authorization_map.yaml
index 2a26e07a9..eaff8f2eb 100644
--- a/esp/applications/eclwatch/ldap_authorization_map.yaml
+++ b/esp/applications/eclwatch/ldap_authorization_map.yaml
@@ -136,17 +136,6 @@ ldap:
          -  path: FileIOAccess
             resource: FileIOAccess
             description: Access to files in dropzone
-      ws_machine:
-         Feature:
-         -  path: MachineInfoAccess
-            resource: MachineInfoAccess
-            description: Access to machine information
-         -  path: MetricsAccess
-            resource: MetricsAccess
-            description: Access to SNMP metrics information
-         -  path: ExecuteAccess
-            resource: ExecuteAccess
-            description: Access to remote execution
       ws_config:
          Feature:
          -  path: ConfigAccess
diff --git a/esp/applications/eclwatch/plugins.yaml b/esp/applications/eclwatch/plugins.yaml
index 33f81b77e..9eb4a136c 100644
--- a/esp/applications/eclwatch/plugins.yaml
+++ b/esp/applications/eclwatch/plugins.yaml
@@ -12,7 +12,6 @@ service_plugins:
   ws_elk: ws_elk
   ws_esdlconfig: ws_esdlconfig
   WsFileIO: ws_fileio
-  ws_machine: ws_machine
   WsPackageProcess: ws_packageprocess
   ws_store: ws_store
   WSESPControl: wsespcontrol
@@ -33,7 +32,6 @@ binding_plugins:
   ws_elk: ws_elk
   ws_esdlconfig: ws_esdlconfig
   WsFileIO: ws_fileio
-  ws_machine: ws_machine
   WsPackageProcess: ws_packageprocess
   ws_store: ws_store
   WsTopology: ws_topology
diff --git a/esp/bindings/http/platform/httptransport.ipp b/esp/bindings/http/platform/httptransport.ipp
index 0d3b1e5bf..7d13f6b39 100644
--- a/esp/bindings/http/platform/httptransport.ipp
+++ b/esp/bindings/http/platform/httptransport.ipp
@@ -454,7 +454,7 @@ inline bool checkRedirect(IEspContext &ctx)
 
 inline bool skipXslt(IEspContext &context)
 {
-    if (queryComponentConfig().getPropBool("@api_only"))
+    if (getComponentConfigSP()->getPropBool("@api_only"))
         return true;
     return (context.getResponseFormat()!=ESPSerializationANY);  //for now
 }
diff --git a/esp/platform/espp.cpp b/esp/platform/espp.cpp
index eac273a8d..3887349c8 100644
--- a/esp/platform/espp.cpp
+++ b/esp/platform/espp.cpp
@@ -362,7 +362,7 @@ void initializeMetrics(CEspConfig* config)
     Owned<IPropertyTree> pMetricsTree = config->queryConfigPTree()->getPropTree("metrics");
     if (pMetricsTree == nullptr)
     {
-        pMetricsTree.setown(queryComponentConfig().getPropTree("metrics"));
+        pMetricsTree.setown(getComponentConfigSP()->getPropTree("metrics"));
     }
 
     if (pMetricsTree != nullptr)
@@ -376,15 +376,9 @@ void initializeMetrics(CEspConfig* config)
 
 int init_main(int argc, const char* argv[])
 {
-    for (unsigned i=0;i<(unsigned)argc;i++) {
-        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-            if (daemon(1,0) || write_pidfile(argv[++i])) {
-                perror("Failed to daemonize");
-                return EXIT_FAILURE;
-            }
-            break;
-        }
-    }
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
+
     InitModuleObjects();
 
     Owned<IProperties> inputs = createProperties(true);
@@ -481,7 +475,7 @@ int init_main(int argc, const char* argv[])
 
 #ifdef _CONTAINERIZED
         // TBD: Some esp services read daliServers from it's legacy config file
-        procpt->setProp("@daliServers", queryComponentConfig().queryProp("@daliServers"));
+        procpt->setProp("@daliServers", getComponentConfigSP()->queryProp("@daliServers"));
 #endif
 
         const char* build_ver = hpccBuildInfo.buildTag;
diff --git a/esp/platform/espprotocol.cpp b/esp/platform/espprotocol.cpp
index 830337690..a0fd54b67 100644
--- a/esp/platform/espprotocol.cpp
+++ b/esp/platform/espprotocol.cpp
@@ -28,21 +28,21 @@
 
 typedef IXslProcessor * (*getXslProcessor_func)();
 
-static atomic_t gActiveRequests;
+static RelaxedAtomic<unsigned> gActiveRequests;
 
-long ActiveRequests::getCount()
+unsigned ActiveRequests::getCount()
 {
-    return atomic_read(&gActiveRequests);
+    return gActiveRequests;
 }
 
-void ActiveRequests::inc()
+ActiveRequests::ActiveRequests()
 {
-    atomic_inc(&gActiveRequests);
+    gActiveRequests++;
 }
 
-void ActiveRequests::dec()
+ActiveRequests::~ActiveRequests()
 {
-    atomic_dec(&gActiveRequests);
+    gActiveRequests--;
 }
 
 CEspApplicationPort::CEspApplicationPort(bool viewcfg, CEspProtocol* prot) : viewConfig(viewcfg), rootAuth(false), navWidth(165), navResize(false), navScroll(false), protocol(prot)
diff --git a/esp/platform/espprotocol.hpp b/esp/platform/espprotocol.hpp
index a8e71c20d..ce7d76620 100644
--- a/esp/platform/espprotocol.hpp
+++ b/esp/platform/espprotocol.hpp
@@ -34,17 +34,14 @@
 #include <map>
 using namespace std;
 
+//A helper class for tracking the number of active requests
 class ActiveRequests
 {
 public:
+    ActiveRequests();
+    ~ActiveRequests();
 
-    ActiveRequests() { inc(); }
-    ~ActiveRequests()  { dec(); }
-
-    void inc();
-    void dec();
-
-    static long getCount();
+    static unsigned getCount();
 };
 
 class CEspBindingEntry : public CInterface, implements IInterface
diff --git a/esp/scm/espscm.cmake b/esp/scm/espscm.cmake
index c0d16d2d3..0a6080911 100644
--- a/esp/scm/espscm.cmake
+++ b/esp/scm/espscm.cmake
@@ -32,7 +32,6 @@ set ( ESPSCM_SRCS
       soapesp.ecm
       ws_ecl_client.ecm
       ws_fs.ecm
-      ws_machine.ecm
       ws_smc.ecm
       ws_topology.ecm
       ws_workunits_struct.ecm
@@ -52,6 +51,10 @@ set ( ESPSCM_SRCS
       ws_resources.ecm
     )
 
+if (NOT CONTAINERIZED)
+    list ( APPEND ESPSCM_SRCS ws_machine.ecm )
+endif()
+
 foreach ( loop_var ${ESPSCM_SRCS} )
     string(  REGEX REPLACE "[.]ecm" "" result ${loop_var} )
     if (SCM_BUILD)
diff --git a/esp/scm/ws_dali.ecm b/esp/scm/ws_dali.ecm
index 7a9a50cd5..081c0e7e9 100644
--- a/esp/scm/ws_dali.ecm
+++ b/esp/scm/ws_dali.ecm
@@ -17,6 +17,11 @@
 
 EspInclude(common);
 
+ESPresponse [exceptions_inline, nil_remove] BooleanResponse
+{
+    bool Result;
+};
+
 ESPrequest [nil_remove] SetValueRequest
 {
     string Path;
@@ -61,8 +66,59 @@ ESPresponse [exceptions_inline, nil_remove] CountResponse
     unsigned Result;
 };
 
+ESPrequest [nil_remove] GetLogicalFileRequest
+{
+    string FileName;
+};
+
+ESPrequest [nil_remove] GetLogicalFilePartRequest
+{
+    string FileName;
+    unsigned PartNumber;
+};
+
+ESPrequest [nil_remove] SetLogicalFilePartAttrRequest
+{
+    string FileName;
+    unsigned PartNumber;
+    string Attr;
+    string Value;
+};
+
+ESPrequest [nil_remove]  GetDFSCSVRequest
+{
+    string LogicalNameMask;
+};
+
+ESPrequest [nil_remove]  GetDFSMapRequest
+{
+    string FileName;
+};
+
+ESPrequest [nil_remove]  GetDFSParentsRequest
+{
+    string FileName;
+};
+
+ESPrequest [nil_remove]  DFSCheckRequest
+{
+};
+
+ESPrequest [nil_remove]  DFSLSRequest
+{
+    string Name;
+    bool PathAndNameOnly(true);
+    bool IncludeSubFileInfo(false);
+    bool Recursively(false);
+};
+
+ESPrequest [nil_remove]  DFSExistsRequest
+{
+    string FileName;
+};
+
 ESPservice [auth_feature("NONE"), //This declares that the method logic handles feature level authorization
-    version("1.03"), default_client_version("1.03"), exceptions_inline("./smc_xslt/exceptions.xslt")] WSDali
+    version("1.04"), default_client_version("1.04"), exceptions_inline("./smc_xslt/exceptions.xslt")] WSDali
 {
     ESPmethod [min_ver("1.01")] SetValue(SetValueRequest, ResultResponse);
     ESPmethod [min_ver("1.01")] GetValue(GetValueRequest, ResultResponse);
@@ -70,6 +126,15 @@ ESPservice [auth_feature("NONE"), //This declares that the method logic handles
     ESPmethod [min_ver("1.02")] Delete(DeleteRequest, ResultResponse);
     ESPmethod [min_ver("1.03")] Add(AddRequest, ResultResponse);
     ESPmethod [min_ver("1.03")] Count(CountRequest, CountResponse);
+    ESPmethod [min_ver("1.04")] GetLogicalFile(GetLogicalFileRequest, ResultResponse);
+    ESPmethod [min_ver("1.04")] GetLogicalFilePart(GetLogicalFilePartRequest, ResultResponse);
+    ESPmethod [min_ver("1.04")] SetLogicalFilePartAttr(SetLogicalFilePartAttrRequest, ResultResponse);
+    ESPmethod [min_ver("1.04")] GetDFSCSV(GetDFSCSVRequest, ResultResponse);
+    ESPmethod [min_ver("1.04")] GetDFSMap(GetDFSMapRequest, ResultResponse);
+    ESPmethod [min_ver("1.04")] GetDFSParents(GetDFSParentsRequest, ResultResponse);
+    ESPmethod [min_ver("1.04")] DFSCheck(DFSCheckRequest, ResultResponse);
+    ESPmethod [min_ver("1.04")] DFSLS(DFSLSRequest, ResultResponse);
+    ESPmethod [min_ver("1.04")] DFSExists(DFSExistsRequest, BooleanResponse);
 };
 
 SCMexportdef(WSDali);
diff --git a/esp/services/CMakeLists.txt b/esp/services/CMakeLists.txt
index c5c18123d..34f16bb42 100644
--- a/esp/services/CMakeLists.txt
+++ b/esp/services/CMakeLists.txt
@@ -22,7 +22,6 @@ HPCC_ADD_SUBDIRECTORY (ws_dfu "PLATFORM")
 HPCC_ADD_SUBDIRECTORY (ws_ecl "PLATFORM")
 HPCC_ADD_SUBDIRECTORY (ws_fileio "PLATFORM")
 HPCC_ADD_SUBDIRECTORY (ws_fs "PLATFORM")
-HPCC_ADD_SUBDIRECTORY (ws_machine "PLATFORM")
 HPCC_ADD_SUBDIRECTORY (ws_smc "PLATFORM")
 HPCC_ADD_SUBDIRECTORY (ws_topology "PLATFORM")
 HPCC_ADD_SUBDIRECTORY (ws_workunits "PLATFORM")
@@ -41,6 +40,7 @@ HPCC_ADD_SUBDIRECTORY (ws_codesign "PLATFORM")
 HPCC_ADD_SUBDIRECTORY (ws_resources "PLATFORM")
 HPCC_ADD_SUBDIRECTORY (ws_dali "PLATFORM")
 if (NOT CONTAINERIZED)
+  HPCC_ADD_SUBDIRECTORY (ws_machine "PLATFORM")
   HPCC_ADD_SUBDIRECTORY (ws_config "PLATFORM")
   HPCC_ADD_SUBDIRECTORY (WsDeploy "PLATFORM")
 endif()
diff --git a/esp/services/WsDeploy/WsDeployBinding.cpp b/esp/services/WsDeploy/WsDeployBinding.cpp
index 0a4c00f3e..07628aa59 100644
--- a/esp/services/WsDeploy/WsDeployBinding.cpp
+++ b/esp/services/WsDeploy/WsDeployBinding.cpp
@@ -41,7 +41,7 @@ public:
 
     void getNavigationData(IEspContext &context, IPropertyTree& data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/esdl_svc_engine/esdl_monitor.cpp b/esp/services/esdl_svc_engine/esdl_monitor.cpp
index 620dc55ba..8c4555d2b 100644
--- a/esp/services/esdl_svc_engine/esdl_monitor.cpp
+++ b/esp/services/esdl_svc_engine/esdl_monitor.cpp
@@ -176,7 +176,7 @@ public:
 
     void setupSubscription()
     {
-        if (false == queryComponentConfig().getPropBool("@loadDaliBindings", true))
+        if (false == getComponentConfigSP()->getPropBool("@loadDaliBindings", true))
             return;
         m_isSubscribed = true;
         m_pSubscription.setown(createEsdlSubscription(this));
@@ -255,14 +255,15 @@ public:
 
     void loadLocalBindings()
     {
-        const char *paths = queryComponentConfig().queryProp("@bindings");
+        Owned<IPropertyTree> compConfig = getComponentConfig();
+        const char *paths = compConfig->queryProp("@bindings");
         if (isEmptyString(paths))
             return;
         StringArray entries;
         entries.appendList(paths, ";");
 
-        const char *process = queryComponentConfig().queryProp("@instance");
-        unsigned int port  = queryComponentConfig().getPropInt("@port");
+        const char *process = compConfig->queryProp("@instance");
+        unsigned int port  = compConfig->getPropInt("@port");
         ForEachItemIn(i, entries)
         {
             const char *path = entries.item(i);
@@ -274,7 +275,7 @@ public:
 
     void loadDynamicBindings()
     {
-        if (false == queryComponentConfig().getPropBool("@loadDaliBindings", true))
+        if (false == getComponentConfigSP()->getPropBool("@loadDaliBindings", true))
             return;
         Owned<IPropertyTree> esdlBindings = m_pCentralStore->getBindings();
         if (!esdlBindings)
diff --git a/esp/services/esdl_svc_engine/esdl_store.cpp b/esp/services/esdl_svc_engine/esdl_store.cpp
index 43398a612..82ac32372 100644
--- a/esp/services/esdl_svc_engine/esdl_store.cpp
+++ b/esp/services/esdl_svc_engine/esdl_store.cpp
@@ -1247,7 +1247,7 @@ private:
     {
 #ifdef _CONTAINERIZED
         VStringBuffer xpath("services[@name='%s']", espprocname);
-        IPropertyTree *service = queryComponentConfig().queryPropTree(xpath);
+        Owned<IPropertyTree> service = getComponentConfigSP()->getPropTree(xpath);
         if (service)
         {
             const char *serviceType = service->queryProp("@type");
diff --git a/esp/services/ws_access/ws_accessService.hpp b/esp/services/ws_access/ws_accessService.hpp
index a5d8a3893..65d9cbea7 100644
--- a/esp/services/ws_access/ws_accessService.hpp
+++ b/esp/services/ws_access/ws_accessService.hpp
@@ -40,7 +40,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_account/ws_accountService.hpp b/esp/services/ws_account/ws_accountService.hpp
index 4d6948ec8..3a2422850 100644
--- a/esp/services/ws_account/ws_accountService.hpp
+++ b/esp/services/ws_account/ws_accountService.hpp
@@ -37,7 +37,7 @@ public:
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
 #ifdef _USE_OPENLDAP
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_config/ws_configBinding.cpp b/esp/services/ws_config/ws_configBinding.cpp
index 7e4f66230..fddb2239e 100644
--- a/esp/services/ws_config/ws_configBinding.cpp
+++ b/esp/services/ws_config/ws_configBinding.cpp
@@ -40,7 +40,7 @@ public:
 
     void getNavigationData(IEspContext &context, IPropertyTree& data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_config/ws_configService.hpp b/esp/services/ws_config/ws_configService.hpp
index 2eb8797e2..a1a1ac37f 100644
--- a/esp/services/ws_config/ws_configService.hpp
+++ b/esp/services/ws_config/ws_configService.hpp
@@ -48,7 +48,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_dali/ws_daliservice.cpp b/esp/services/ws_dali/ws_daliservice.cpp
index 31ef7d18e..7b33c819f 100644
--- a/esp/services/ws_dali/ws_daliservice.cpp
+++ b/esp/services/ws_dali/ws_daliservice.cpp
@@ -22,7 +22,6 @@
 #include "ws_daliservice.hpp"
 #include "jlib.hpp"
 #include "dautils.hpp"
-#include "dasds.hpp"
 #include "daadmin.hpp"
 
 using namespace daadmin;
@@ -244,3 +243,220 @@ bool CWSDaliEx::onCount(IEspContext& context, IEspCountRequest& req, IEspCountRe
     }
     return true;
 }
+
+IUserDescriptor* CWSDaliEx::createUserDesc(IEspContext& context)
+{
+    StringBuffer username;
+    context.getUserID(username);
+    if (username.isEmpty())
+        return nullptr;
+
+    Owned<IUserDescriptor> userdesc = createUserDescriptor();
+    userdesc->set(username.str(), context.queryPassword(), context.querySignature());
+    return userdesc.getClear();
+}
+
+bool CWSDaliEx::onDFSLS(IEspContext& context, IEspDFSLSRequest& req, IEspResultResponse& resp)
+{
+    try
+    {
+        checkAccess(context);
+
+        StringBuffer options;
+        if (req.getRecursively())
+            options.append("r");
+        if (!req.getPathAndNameOnly())
+            options.append("l");
+        if (req.getIncludeSubFileInfo())
+            options.append("s");
+
+        StringBuffer result;
+        dfsLs(req.getName(), options, result);
+        resp.setResult(result);
+    }
+    catch(IException* e)
+    {
+        FORWARDEXCEPTION(context, e,  ECLWATCH_INTERNAL_ERROR);
+    }
+    return true;
+}
+
+bool CWSDaliEx::onGetDFSCSV(IEspContext& context, IEspGetDFSCSVRequest& req, IEspResultResponse& resp)
+{
+    try
+    {
+        checkAccess(context);
+
+        Owned<IUserDescriptor> userDesc = createUserDesc(context);
+
+        StringBuffer result;
+        dfscsv(req.getLogicalNameMask(), userDesc, result);
+        resp.setResult(result);
+    }
+    catch(IException* e)
+    {
+        FORWARDEXCEPTION(context, e,  ECLWATCH_INTERNAL_ERROR);
+    }
+    return true;
+}
+
+bool CWSDaliEx::onDFSExists(IEspContext& context, IEspDFSExistsRequest& req, IEspBooleanResponse& resp)
+{
+    try
+    {
+        checkAccess(context);
+
+        const char* fileName = req.getFileName();
+        if (isEmptyString(fileName))
+            throw makeStringException(ECLWATCH_INVALID_INPUT, "File name not specified.");
+
+        Owned<IUserDescriptor> userDesc = createUserDesc(context);
+        resp.setResult(dfsexists(fileName, userDesc) == 0 ? true : false);
+    }
+    catch(IException* e)
+    {
+        FORWARDEXCEPTION(context, e,  ECLWATCH_INTERNAL_ERROR);
+    }
+    return true;
+}
+
+bool CWSDaliEx::onGetLogicalFile(IEspContext& context, IEspGetLogicalFileRequest& req, IEspResultResponse& resp)
+{
+    try
+    {
+        checkAccess(context);
+
+        const char* fileName = req.getFileName();
+        if (isEmptyString(fileName))
+            throw makeStringException(ECLWATCH_INVALID_INPUT, "File name not specified.");
+
+        Owned<IUserDescriptor> userDesc = createUserDesc(context);
+
+        StringBuffer result;
+        dfsfile(fileName, userDesc, result);
+        resp.setResult(result);
+    }
+    catch(IException* e)
+    {
+        FORWARDEXCEPTION(context, e,  ECLWATCH_INTERNAL_ERROR);
+    }
+    return true;
+}
+
+bool CWSDaliEx::onGetLogicalFilePart(IEspContext& context, IEspGetLogicalFilePartRequest& req, IEspResultResponse& resp)
+{
+    try
+    {
+        checkAccess(context);
+
+        const char* fileName = req.getFileName();
+        if (isEmptyString(fileName))
+            throw makeStringException(ECLWATCH_INVALID_INPUT, "File name not specified.");
+        if (req.getPartNumber_isNull())
+            throw makeStringException(ECLWATCH_INVALID_INPUT, "Part number not specified.");
+
+        Owned<IUserDescriptor> userDesc = createUserDesc(context);
+
+        StringBuffer result;
+        dfspart(fileName, userDesc, req.getPartNumber(), result);
+        resp.setResult(result);
+    }
+    catch(IException* e)
+    {
+        FORWARDEXCEPTION(context, e,  ECLWATCH_INTERNAL_ERROR);
+    }
+    return true;
+}
+
+bool CWSDaliEx::onSetLogicalFilePartAttr(IEspContext& context, IEspSetLogicalFilePartAttrRequest& req, IEspResultResponse& resp)
+{
+    try
+    {
+        checkAccess(context);
+
+        const char* fileName = req.getFileName();
+        if (isEmptyString(fileName))
+            throw makeStringException(ECLWATCH_INVALID_INPUT, "File name not specified.");
+        const char* attr = req.getAttr();
+        if (isEmptyString(attr))
+            throw makeStringException(ECLWATCH_INVALID_INPUT, "Part attribute name not specified.");
+        if (req.getPartNumber_isNull())
+            throw makeStringException(ECLWATCH_INVALID_INPUT, "Part number not specified.");
+
+        Owned<IUserDescriptor> userDesc = createUserDesc(context);
+
+        StringBuffer result;
+        setdfspartattr(fileName, req.getPartNumber(), attr, req.getValue(), userDesc, result);
+        resp.setResult(result);
+    }
+    catch(IException* e)
+    {
+        FORWARDEXCEPTION(context, e,  ECLWATCH_INTERNAL_ERROR);
+    }
+    return true;
+}
+
+bool CWSDaliEx::onGetDFSMap(IEspContext& context, IEspGetDFSMapRequest& req, IEspResultResponse& resp)
+{
+    try
+    {
+        checkAccess(context);
+
+        const char* fileName = req.getFileName();
+        if (isEmptyString(fileName))
+            throw makeStringException(ECLWATCH_INVALID_INPUT, "File name not specified.");
+
+        Owned<IUserDescriptor> userDesc = createUserDesc(context);
+
+        StringBuffer result;
+        dfsmap(fileName, userDesc, result);
+        resp.setResult(result);
+    }
+    catch(IException* e)
+    {
+        FORWARDEXCEPTION(context, e,  ECLWATCH_INTERNAL_ERROR);
+    }
+    return true;
+}
+
+bool CWSDaliEx::onGetDFSParents(IEspContext& context, IEspGetDFSParentsRequest& req, IEspResultResponse& resp)
+{
+    try
+    {
+        checkAccess(context);
+
+        const char* fileName = req.getFileName();
+        if (isEmptyString(fileName))
+            throw makeStringException(ECLWATCH_INVALID_INPUT, "File name not specified.");
+
+        Owned<IUserDescriptor> userDesc = createUserDesc(context);
+
+        StringBuffer result;
+        dfsparents(fileName, userDesc, result);
+        resp.setResult(result);
+    }
+    catch(IException* e)
+    {
+        FORWARDEXCEPTION(context, e,  ECLWATCH_INTERNAL_ERROR);
+    }
+    return true;
+}
+
+bool CWSDaliEx::onDFSCheck(IEspContext& context, IEspDFSCheckRequest& req, IEspResultResponse& resp)
+{
+    try
+    {
+        checkAccess(context);
+
+        Owned<IUserDescriptor> userDesc = createUserDesc(context);
+
+        StringBuffer result;
+        dfsCheck(result);
+        resp.setResult(result);
+    }
+    catch(IException* e)
+    {
+        FORWARDEXCEPTION(context, e,  ECLWATCH_INTERNAL_ERROR);
+    }
+    return true;
+}
diff --git a/esp/services/ws_dali/ws_daliservice.hpp b/esp/services/ws_dali/ws_daliservice.hpp
index 315a0e1d9..d85dc2f19 100644
--- a/esp/services/ws_dali/ws_daliservice.hpp
+++ b/esp/services/ws_dali/ws_daliservice.hpp
@@ -20,6 +20,7 @@
 
 #include "ws_dali_esp.ipp"
 #include "exception_util.hpp"
+#include "dasds.hpp"
 
 class CWSDaliEx : public CWSDali
 {
@@ -27,6 +28,7 @@ class CWSDaliEx : public CWSDali
     std::atomic<bool> daliDetached{false};
 
     void checkAccess(IEspContext& context);
+    IUserDescriptor* createUserDesc(IEspContext& context);
 public:
     IMPLEMENT_IINTERFACE;
 
@@ -54,6 +56,15 @@ public:
     virtual bool onDelete(IEspContext& context, IEspDeleteRequest& req, IEspResultResponse& resp) override;
     virtual bool onAdd(IEspContext& context, IEspAddRequest& req, IEspResultResponse& resp) override;
     virtual bool onCount(IEspContext& context, IEspCountRequest& req, IEspCountResponse& resp) override;
+    virtual bool onDFSLS(IEspContext& context, IEspDFSLSRequest& req, IEspResultResponse& resp) override;
+    virtual bool onGetDFSCSV(IEspContext& context, IEspGetDFSCSVRequest& req, IEspResultResponse& resp) override;
+    virtual bool onDFSExists(IEspContext& context, IEspDFSExistsRequest& req, IEspBooleanResponse& resp) override;
+    virtual bool onGetLogicalFile(IEspContext& context, IEspGetLogicalFileRequest& req, IEspResultResponse& resp) override;
+    virtual bool onGetLogicalFilePart(IEspContext& context, IEspGetLogicalFilePartRequest& req, IEspResultResponse& resp) override;
+    virtual bool onSetLogicalFilePartAttr(IEspContext& context, IEspSetLogicalFilePartAttrRequest& req, IEspResultResponse& resp) override;
+    virtual bool onGetDFSMap(IEspContext& context, IEspGetDFSMapRequest& req, IEspResultResponse& resp) override;
+    virtual bool onGetDFSParents(IEspContext& context, IEspGetDFSParentsRequest& req, IEspResultResponse& resp) override;
+    virtual bool onDFSCheck(IEspContext& context, IEspDFSCheckRequest& req, IEspResultResponse& resp) override;
 };
 
 class CWSDaliSoapBindingEx : public CWSDaliSoapBinding
diff --git a/esp/services/ws_dfu/ws_dfuService.hpp b/esp/services/ws_dfu/ws_dfuService.hpp
index 8dd82a127..15a53f23b 100644
--- a/esp/services/ws_dfu/ws_dfuService.hpp
+++ b/esp/services/ws_dfu/ws_dfuService.hpp
@@ -109,7 +109,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_dfu/ws_dfuXRefService.hpp b/esp/services/ws_dfu/ws_dfuXRefService.hpp
index a0c4f4583..1cf78870d 100644
--- a/esp/services/ws_dfu/ws_dfuXRefService.hpp
+++ b/esp/services/ws_dfu/ws_dfuXRefService.hpp
@@ -176,7 +176,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_ecl/ws_ecl_service.cpp b/esp/services/ws_ecl/ws_ecl_service.cpp
index 3c50597e8..b1f862186 100644
--- a/esp/services/ws_ecl/ws_ecl_service.cpp
+++ b/esp/services/ws_ecl/ws_ecl_service.cpp
@@ -198,7 +198,7 @@ static void appendServerAddress(StringBuffer &s, IPropertyTree &env, IPropertyTr
 
 void initContainerRoxieTargets(MapStringToMyClass<ISmartSocketFactory> &connMap)
 {
-    Owned<IPropertyTreeIterator> services = queryComponentConfig().getElements("services[@type='roxie']");
+    Owned<IPropertyTreeIterator> services = getComponentConfigSP()->getElements("services[@type='roxie']");
     ForEach(*services)
     {
         IPropertyTree &service = services->query();
@@ -363,7 +363,7 @@ void CWsEclBinding::getNavigationData(IEspContext &context, IPropertyTree & data
 static IStringIterator *getContainerTargetClusters()
 {
     Owned<CStringArrayIterator> ret = new CStringArrayIterator;
-    Owned<IPropertyTreeIterator> queues = queryComponentConfig().getElements("queues");
+    Owned<IPropertyTreeIterator> queues = getComponentConfigSP()->getElements("queues");
     ForEach(*queues)
     {
         IPropertyTree &queue = queues->query();
@@ -371,7 +371,7 @@ static IStringIterator *getContainerTargetClusters()
         if (!isEmptyString(qName))
             ret->append_unique(qName);
     }
-    Owned<IPropertyTreeIterator> services = queryComponentConfig().getElements("services[@type='roxie']");
+    Owned<IPropertyTreeIterator> services = getComponentConfigSP()->getElements("services[@type='roxie']");
     ForEach(*services)
     {
         IPropertyTree &service = services->query();
diff --git a/esp/services/ws_fileio/ws_fileioservice.hpp b/esp/services/ws_fileio/ws_fileioservice.hpp
index 3ada55bb7..0abaa5c01 100644
--- a/esp/services/ws_fileio/ws_fileioservice.hpp
+++ b/esp/services/ws_fileio/ws_fileioservice.hpp
@@ -27,7 +27,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_fs/ws_fsBinding.hpp b/esp/services/ws_fs/ws_fsBinding.hpp
index 82611b887..ece655e21 100644
--- a/esp/services/ws_fs/ws_fsBinding.hpp
+++ b/esp/services/ws_fs/ws_fsBinding.hpp
@@ -47,7 +47,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_fs/ws_fsService.cpp b/esp/services/ws_fs/ws_fsService.cpp
index 82919ca75..3b7243fc2 100644
--- a/esp/services/ws_fs/ws_fsService.cpp
+++ b/esp/services/ws_fs/ws_fsService.cpp
@@ -160,7 +160,7 @@ void CFileSprayEx::init(IPropertyTree *cfg, const char *process, const char *ser
 #else
     // Using the first queue for now.
     // TODO: Re-design support for multiple queues
-    Owned<IPropertyTreeIterator> dfuQueues = queryComponentConfig().getElements("dfuQueues");
+    Owned<IPropertyTreeIterator> dfuQueues = getComponentConfigSP()->getElements("dfuQueues");
     ForEach(*dfuQueues)
     {
         IPropertyTree & dfuQueue = dfuQueues->query();
@@ -536,7 +536,7 @@ bool CFileSprayEx::ParseLogicalPath(const char * pLogicalPath, const char* group
     if(groupName != NULL && *groupName != '\0')
     {
 #ifdef _CONTAINERIZED
-        IPropertyTree * plane = queryStoragePlane(groupName);
+        Owned<IPropertyTree> plane = getStoragePlane(groupName);
         if (plane)
             defaultFolder.append(plane->queryProp("@prefix"));
 #else
@@ -1842,7 +1842,7 @@ static void checkValidDfuQueue(const char * dfuQueue)
             throw MakeStringException(ECLWATCH_INVALID_INPUT, "Invalid DFU server queue name:'%s'", dfuQueue);
 #else
         bool isValidDfuQueueName = false;
-        Owned<IPropertyTreeIterator> dfuServers = queryComponentConfig().getElements("dfuQueues");
+        Owned<IPropertyTreeIterator> dfuServers = getComponentConfigSP()->getElements("dfuQueues");
         ForEach(*dfuServers)
         {
             IPropertyTree & dfuServer = dfuServers->query();
@@ -3462,7 +3462,7 @@ bool CFileSprayEx::onGetSprayTargets(IEspContext &context, IEspGetSprayTargetsRe
         context.ensureFeatureAccess(FILE_SPRAY_URL, SecAccess_Read, ECLWATCH_FILE_SPRAY_ACCESS_DENIED, "Permission denied.");
 #ifdef _CONTAINERIZED
         IArrayOf<IEspGroupNode> sprayTargets;
-        Owned<IPropertyTreeIterator> dataPlanes = queryGlobalConfig().getElements("storage/planes[labels='data']");
+        Owned<IPropertyTreeIterator> dataPlanes = getGlobalConfigSP()->getElements("storage/planes[labels='data']");
         ForEach(*dataPlanes)
         {
             IPropertyTree & plane = dataPlanes->query();
diff --git a/esp/services/ws_machine/ws_machineBinding.hpp b/esp/services/ws_machine/ws_machineBinding.hpp
index a55b9c5b1..0692de84b 100644
--- a/esp/services/ws_machine/ws_machineBinding.hpp
+++ b/esp/services/ws_machine/ws_machineBinding.hpp
@@ -60,7 +60,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_packageprocess/ws_packageprocessService.cpp b/esp/services/ws_packageprocess/ws_packageprocessService.cpp
index 49dc5e2ad..e124cd470 100644
--- a/esp/services/ws_packageprocess/ws_packageprocessService.cpp
+++ b/esp/services/ws_packageprocess/ws_packageprocessService.cpp
@@ -31,6 +31,7 @@
 #include "exception_util.hpp"
 #include "TpWrapper.hpp"
 
+
 void CWsPackageProcessEx::init(IPropertyTree *cfg, const char *process, const char *service)
 {
     packageMapAndSet.subscribe();
@@ -136,6 +137,16 @@ void cloneFileInfoToDali(unsigned updateFlags, StringArray &notFound, IPropertyT
 
     Owned<IReferencedFileList> wufiles = createReferencedFileList(user, password, allowForeignFiles, false);
     wufiles->addFilesFromPackageMap(packageMap);
+
+    Owned<IDFUhelper> helper = createIDFUhelper();
+#ifdef _CONTAINERIZED
+    SCMStringBuffer clusterName;
+    dstInfo->getName(clusterName);
+    StringBuffer targetPlane;
+    getRoxieDefaultPlane(targetPlane, clusterName.str());
+    wufiles->resolveFiles(targetPlane, lookupDaliIp, remotePrefix, srcCluster, !(updateFlags & (DALI_UPDATEF_REPLACE_FILE | DALI_UPDATEF_CLONE_FROM)), false, false);
+    wufiles->cloneAllInfo(updateFlags, helper, true, false, 0, 1, 0, nullptr);
+#else
     SCMStringBuffer processName;
     dstInfo->getRoxieProcess(processName);
     wufiles->resolveFiles(processName.str(), lookupDaliIp, remotePrefix, srcCluster, !(updateFlags & (DALI_UPDATEF_REPLACE_FILE | DALI_UPDATEF_CLONE_FROM)), false, false);
@@ -143,8 +154,8 @@ void cloneFileInfoToDali(unsigned updateFlags, StringArray &notFound, IPropertyT
     StringBuffer defReplicateFolder;
     getConfigurationDirectory(NULL, "data2", "roxie", processName.str(), defReplicateFolder);
 
-    Owned<IDFUhelper> helper = createIDFUhelper();
     wufiles->cloneAllInfo(updateFlags, helper, true, false, dstInfo->getRoxieRedundancy(), dstInfo->getChannelsPerNode(), dstInfo->getRoxieReplicateOffset(), defReplicateFolder);
+#endif
 
     Owned<IReferencedFileIterator> iter = wufiles->getFiles();
     ForEach(*iter)
diff --git a/esp/services/ws_packageprocess/ws_packageprocessService.hpp b/esp/services/ws_packageprocess/ws_packageprocessService.hpp
index 5286597f6..ff12a88e6 100644
--- a/esp/services/ws_packageprocess/ws_packageprocessService.hpp
+++ b/esp/services/ws_packageprocess/ws_packageprocessService.hpp
@@ -140,7 +140,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_smc/CMakeLists.txt b/esp/services/ws_smc/CMakeLists.txt
index df333f280..44ebd7e70 100644
--- a/esp/services/ws_smc/CMakeLists.txt
+++ b/esp/services/ws_smc/CMakeLists.txt
@@ -83,7 +83,6 @@ target_link_libraries ( ws_smc
          remote 
          dalibase 
          environment 
-         ws_machine 
          dalift 
          dllserver 
          nbcd 
@@ -103,6 +102,13 @@ target_link_libraries ( ws_smc
          schedulectrl 
          ws_workunits 
     )
+
+if (NOT CONTAINERIZED)
+    target_link_libraries ( ws_smc
+        ws_machine
+    )
+endif()
+
 IF (USE_OPENSSL)
     target_link_libraries ( ws_smc
     	securesocket
diff --git a/esp/services/ws_smc/ws_smcService.hpp b/esp/services/ws_smc/ws_smcService.hpp
index 3cb2bc281..94e8a1d07 100644
--- a/esp/services/ws_smc/ws_smcService.hpp
+++ b/esp/services/ws_smc/ws_smcService.hpp
@@ -286,7 +286,7 @@ public:
     virtual ~CWsSMCSoapBindingEx(){}
     virtual const char* getRootPage(IEspContext* ctx)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
             return nullptr;
         if (ctx->queryRequestParameters()->hasProp("legacy"))
             return NULL;
@@ -299,21 +299,21 @@ public:
 
     virtual int onGetRoot(IEspContext &context, CHttpRequest* request,  CHttpResponse* response)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
             return CWsSMCSoapBinding::onGetRoot(context, request,  response);
         return  onGetInstantQuery(context, request, response, "WsSMC", "Activity");
     }
 
     virtual int onGetIndex(IEspContext &context, CHttpRequest* request,  CHttpResponse* response, const char *service)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
             return CWsSMCSoapBinding::onGetIndex(context, request, response, service);
         return  onGetInstantQuery(context, request, response, "WsSMC", "Activity");
     }
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_topology/ws_topologyService.cpp b/esp/services/ws_topology/ws_topologyService.cpp
index cf29c4115..f89a44418 100644
--- a/esp/services/ws_topology/ws_topologyService.cpp
+++ b/esp/services/ws_topology/ws_topologyService.cpp
@@ -1327,7 +1327,7 @@ bool CWsTopologyEx::onTpLogicalClusterQuery(IEspContext &context, IEspTpLogicalC
         if (roxieQueueFilter == RoxieQueueFilter_Undefined)
             roxieQueueFilter = CRoxieQueueFilter_All;
 
-        Owned<IPropertyTreeIterator> iter = queryComponentConfig().getElements("queues");
+        Owned<IPropertyTreeIterator> iter = getComponentConfigSP()->getElements("queues");
         ForEach(*iter)
         {
             IPropertyTree &queue = iter->query();
diff --git a/esp/services/ws_topology/ws_topologyService.hpp b/esp/services/ws_topology/ws_topologyService.hpp
index e7db71f3b..b28ff504c 100644
--- a/esp/services/ws_topology/ws_topologyService.hpp
+++ b/esp/services/ws_topology/ws_topologyService.hpp
@@ -69,7 +69,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/services/ws_workunits/ws_workunitsQuerySets.cpp b/esp/services/ws_workunits/ws_workunitsQuerySets.cpp
index 96bc5fb48..a0dbc7410 100644
--- a/esp/services/ws_workunits/ws_workunitsQuerySets.cpp
+++ b/esp/services/ws_workunits/ws_workunitsQuerySets.cpp
@@ -753,7 +753,7 @@ public:
         if (!process.length())
             return;
 #else
-        StringBuffer process(target);
+        process.set(target);
 #endif
 
         ps.setown(createPackageSet(process.str()));
@@ -766,11 +766,21 @@ public:
         if (queryname && *queryname)
             queryname = queryid.append(queryname).append(".0").str(); //prepublish dummy version number to support fuzzy match like queries="myquery.*" in package
         files->addFilesFromQuery(cw, pm, queryname);
-        files->resolveFiles(process.str(), remoteIP, remotePrefix, srcCluster, !(updateFlags & (DALI_UPDATEF_REPLACE_FILE | DALI_UPDATEF_CLONE_FROM | DALI_UPDATEF_SUPERFILES)), true, false, true);
+
+#ifdef _CONTAINERIZED
+        StringBuffer targetPlane;
+        getRoxieDefaultPlane(targetPlane, target);
+        const char * targetPlaneOrGroup = targetPlane;
+#else
+        const char * targetPlaneOrGroup = process;
+#endif
+        files->resolveFiles(targetPlaneOrGroup, remoteIP, remotePrefix, srcCluster, !(updateFlags & (DALI_UPDATEF_REPLACE_FILE | DALI_UPDATEF_CLONE_FROM | DALI_UPDATEF_SUPERFILES)), true, false, true);
+        Owned<IDFUhelper> helper = createIDFUhelper();
+#ifdef _CONTAINERIZED
+        files->cloneAllInfo(updateFlags, helper, true, true, 0, 1, 0, nullptr);
+#else
         StringBuffer defReplicateFolder;
         getConfigurationDirectory(NULL, "data2", "roxie", process.str(), defReplicateFolder);
-        Owned<IDFUhelper> helper = createIDFUhelper();
-#ifndef _CONTAINERIZED
         files->cloneAllInfo(updateFlags, helper, true, true, clusterInfo->getRoxieRedundancy(), clusterInfo->getChannelsPerNode(), clusterInfo->getRoxieReplicateOffset(), defReplicateFolder);
 #endif
     }
@@ -881,7 +891,7 @@ bool CWsWorkunitsEx::onWUPublishWorkunit(IEspContext &context, IEspWUPublishWork
         target.set(cw->queryClusterName());
     validateTargetName(target);
 
-    DBGLOG("%s publishing wuid %s to target %s as query %s", context.queryUserId(), wuid.str(), target.str(), queryName.str());
+    DBGLOG("%s publishing wuid %s to target %s as query %s", nullText(context.queryUserId()), wuid.str(), target.str(), queryName.str());
 
     StringBuffer daliIP;
     StringBuffer srcCluster;
@@ -2937,7 +2947,13 @@ public:
         wufiles.setown(createReferencedFileList(context->queryUserId(), context->queryPassword(), allowForeign, false));
         Owned<IHpccPackageSet> ps = createPackageSet(destProcess);
         pm.set(ps->queryActiveMap(target));
-        process.set(destProcess);
+        if (isContainerized())
+        {
+            StringAttrBuilder builder(process);
+            getRoxieDefaultPlane(builder, target);
+        }
+        else
+            process.set(destProcess);
     }
 
     void cloneFiles()
@@ -2949,10 +2965,14 @@ public:
             Owned <IConstWUClusterInfo> cl = getWUClusterInfoByName(target);
             if (cl)
             {
+#ifdef _CONTAINERIZED
+                wufiles->cloneAllInfo(updateFlags, helper, true, true, 0, 1, 0, nullptr);
+#else
                 SCMStringBuffer process;
                 StringBuffer defReplicateFolder;
                 getConfigurationDirectory(NULL, "data2", "roxie", cl->getRoxieProcess(process).str(), defReplicateFolder);
                 wufiles->cloneAllInfo(updateFlags, helper, true, true, cl->getRoxieRedundancy(), cl->getChannelsPerNode(), cl->getRoxieReplicateOffset(), defReplicateFolder);
+#endif
             }
         }
     }
diff --git a/esp/services/ws_workunits/ws_workunitsService.hpp b/esp/services/ws_workunits/ws_workunitsService.hpp
index 3b5ffd5e0..2f63bcef9 100644
--- a/esp/services/ws_workunits/ws_workunitsService.hpp
+++ b/esp/services/ws_workunits/ws_workunitsService.hpp
@@ -452,7 +452,7 @@ public:
 
     virtual void getNavigationData(IEspContext &context, IPropertyTree & data)
     {
-        if (queryComponentConfig().getPropBool("@api_only"))
+        if (getComponentConfigSP()->getPropBool("@api_only"))
         {
             CHttpSoapBinding::getNavigationData(context, data);
             return;
diff --git a/esp/smc/SMCLib/TpWrapper.cpp b/esp/smc/SMCLib/TpWrapper.cpp
index a136ce198..d3269a467 100644
--- a/esp/smc/SMCLib/TpWrapper.cpp
+++ b/esp/smc/SMCLib/TpWrapper.cpp
@@ -29,6 +29,17 @@
 #include "dautils.hpp"
 #include "dameta.hpp"
 
+static unsigned reloadConfigCBId = (unsigned)-1;
+MODULE_INIT(INIT_PRIORITY_STANDARD)
+{
+    return true;
+}
+MODULE_EXIT()
+{
+    if ((unsigned)-1 != reloadConfigCBId)
+        removeConfigUpdateHook(reloadConfigCBId);
+}
+
 const char* MSG_FAILED_GET_ENVIRONMENT_INFO = "Failed to get environment information.";
 
 //////////////////////////////////////////////////////////////////////
@@ -500,7 +511,7 @@ static void gatherDropZoneMachines(IArrayOf<IEspTpMachine> & tpMachines, IProper
     }
     else if (plane.hasProp("@hostGroup"))
     {
-        IPropertyTree * hostGroup = queryHostGroup(plane.queryProp("@hostGroup"), true);
+        Owned<IPropertyTree> hostGroup = getHostGroup(plane.queryProp("@hostGroup"), true);
         gatherDropZoneMachinesFromHosts(tpMachines, *hostGroup, prefix);
     }
     else
@@ -512,7 +523,7 @@ static void gatherDropZoneMachines(IArrayOf<IEspTpMachine> & tpMachines, IProper
 void CTpWrapper::getTpDfuServers(IArrayOf<IConstTpDfuServer>& list)
 {
 #ifdef _CONTAINERIZED
-    Owned<IPropertyTreeIterator> dfuQueues = queryComponentConfig().getElements("dfuQueues");
+    Owned<IPropertyTreeIterator> dfuQueues = getComponentConfigSP()->getElements("dfuQueues");
     ForEach(*dfuQueues)
     {
         IPropertyTree & dfuQueue = dfuQueues->query();
@@ -1316,7 +1327,7 @@ void CTpWrapper::getGroupList(double espVersion, const char* kindReq, IArrayOf<I
     try
     {
 #ifdef _CONTAINERIZED
-        Owned<IPropertyTreeIterator> dataPlanes = queryGlobalConfig().getElements("storage/planes[labels='data']");
+        Owned<IPropertyTreeIterator> dataPlanes = getGlobalConfigSP()->getElements("storage/planes[labels='data']");
         ForEach(*dataPlanes)
         {
             IPropertyTree & plane = dataPlanes->query();
@@ -2080,7 +2091,7 @@ void CTpWrapper::getAttPath(const char* Path,StringBuffer& returnStr)
 
 void CTpWrapper::getServices(double version, const char* serviceType, const char* serviceName, IArrayOf<IConstHPCCService>& services)
 {
-    Owned<IPropertyTreeIterator> itr = queryComponentConfig().getElements("services");
+    Owned<IPropertyTreeIterator> itr = getComponentConfigSP()->getElements("services");
     ForEach(*itr)
     {
         IPropertyTree& service = itr->query();
@@ -2139,7 +2150,7 @@ extern TPWRAPPER_API ISashaCommand* archiveOrRestoreWorkunits(StringArray& wuids
 extern TPWRAPPER_API IStringIterator* getContainerTargetClusters(const char* processType, const char* processName)
 {
     Owned<CStringArrayIterator> ret = new CStringArrayIterator;
-    Owned<IPropertyTreeIterator> queues = queryComponentConfig().getElements("queues");
+    Owned<IPropertyTreeIterator> queues = getComponentConfigSP()->getElements("queues");
     ForEach(*queues)
     {
         IPropertyTree& queue = queues->query();
@@ -2161,7 +2172,7 @@ extern TPWRAPPER_API IStringIterator* getContainerTargetClusters(const char* pro
     if (!isEmptyString(processType) && !strieq("roxie", processType))
         return ret.getClear();
 
-    Owned<IPropertyTreeIterator> services = queryComponentConfig().getElements("services[@type='roxie']");
+    Owned<IPropertyTreeIterator> services = getComponentConfigSP()->getElements("services[@type='roxie']");
     ForEach(*services)
     {
         IPropertyTree& service = services->query();
@@ -2309,7 +2320,7 @@ public:
 
 extern TPWRAPPER_API unsigned getContainerWUClusterInfo(CConstWUClusterInfoArray& clusters)
 {
-    Owned<IPropertyTreeIterator> queues = queryComponentConfig().getElements("queues");
+    Owned<IPropertyTreeIterator> queues = getComponentConfigSP()->getElements("queues");
     ForEach(*queues)
     {
         IPropertyTree& queue = queues->query();
@@ -2330,13 +2341,18 @@ extern TPWRAPPER_API unsigned getWUClusterInfo(CConstWUClusterInfoArray& cluster
 #endif
 }
 
+static IPropertyTree * getContainerClusterConfig(const char * clusterName)
+{
+    VStringBuffer xpath("queues[@name='%s']", clusterName);
+    return getComponentConfigSP()->getPropTree(xpath);
+}
+
 extern TPWRAPPER_API IConstWUClusterInfo* getWUClusterInfoByName(const char* clusterName)
 {
 #ifndef _CONTAINERIZED
     return getTargetClusterInfo(clusterName);
 #else
-    VStringBuffer xpath("queues[@name='%s']", clusterName);
-    IPropertyTree* queue = queryComponentConfig().queryPropTree(xpath);
+    Owned<IPropertyTree> queue = getContainerClusterConfig(clusterName);
     if (!queue)
         return nullptr;
 
@@ -2347,7 +2363,7 @@ extern TPWRAPPER_API IConstWUClusterInfo* getWUClusterInfoByName(const char* clu
 
 extern TPWRAPPER_API void initContainerRoxieTargets(MapStringToMyClass<ISmartSocketFactory>& connMap)
 {
-    Owned<IPropertyTreeIterator> services = queryComponentConfig().getElements("services[@type='roxie']");
+    Owned<IPropertyTreeIterator> services = getComponentConfigSP()->getElements("services[@type='roxie']");
     ForEach(*services)
     {
         IPropertyTree& service = services->query();
@@ -2387,8 +2403,8 @@ extern TPWRAPPER_API unsigned getThorClusterNames(StringArray& targetNames, Stri
 
 static std::set<std::string> validTargets;
 static CriticalSection validTargetSect;
-static bool targetsDirty = true;
 
+// called within validTargetSect lock
 static void refreshValidTargets()
 {
     validTargets.clear();
@@ -2410,29 +2426,36 @@ static void refreshValidTargets()
     }
 }
 
+static void configUpdate(const IPropertyTree *oldComponentConfiguration, const IPropertyTree *oldGlobalConfiguration)
+{
+    CriticalBlock block(validTargetSect);
+    // as much as effort [small] to check if different as to refresh
+    refreshValidTargets();
+    PROGLOG("Valid targets updated");
+}
+
 extern TPWRAPPER_API void validateTargetName(const char* target)
 {
     if (isEmptyString(target))
         throw makeStringException(ECLWATCH_INVALID_CLUSTER_NAME, "Empty target name.");
 
     CriticalBlock block(validTargetSect);
-    if (targetsDirty)
+#ifdef _CONTAINERIZED
+    if ((unsigned) -1 == reloadConfigCBId) // once only
     {
         refreshValidTargets();
-        targetsDirty = false;
+        reloadConfigCBId = installConfigUpdateHook(configUpdate);
     }
-
-    if (validTargets.find(target) != validTargets.end())
-        return;
-
-#ifdef _CONTAINERIZED
-    //Currently, if there's any change to the target queues, esp will be auto restarted by K8s.
-    throw makeStringExceptionV(ECLWATCH_INVALID_CLUSTER_NAME, "Invalid target name: %s", target);
-#else
-    if (!validateTargetClusterName(target))
+    if (validTargets.find(target) == validTargets.end())
         throw makeStringExceptionV(ECLWATCH_INVALID_CLUSTER_NAME, "Invalid target name: %s", target);
-
-    targetsDirty = true;
+#else
+    if (validTargets.find(target) == validTargets.end())
+    {
+        // bare metal rechecks in case env. changed since target list built
+        if (!validateTargetClusterName(target))
+            throw makeStringExceptionV(ECLWATCH_INVALID_CLUSTER_NAME, "Invalid target name: %s", target);
+        refreshValidTargets();
+    }
 #endif
 }
 
@@ -2442,7 +2465,7 @@ bool getSashaService(StringBuffer &serviceAddress, const char *serviceName, bool
     {
 #ifdef _CONTAINERIZED
         VStringBuffer serviceQualifier("services[@type='sasha'][@name='%s']", serviceName);
-        IPropertyTree *serviceTree = queryComponentConfig().queryPropTree(serviceQualifier);
+        Owned<IPropertyTree> serviceTree = getComponentConfigSP()->getPropTree(serviceQualifier);
         if (serviceTree)
         {
             serviceAddress.append(serviceName).append(':').append(serviceTree->queryProp("@port"));
@@ -2482,3 +2505,27 @@ bool getSashaServiceEP(SocketEndpoint &serviceEndpoint, const char *service, boo
     serviceEndpoint.set(serviceAddress);
     return true;
 }
+
+StringBuffer & getRoxieDefaultPlane(StringBuffer & plane, const char * roxieName)
+{
+#ifdef _CONTAINERIZED
+    Owned<IPropertyTree> queue = getContainerClusterConfig(roxieName);
+    if (!queue)
+        throw makeStringExceptionV(ECLWATCH_INVALID_CLUSTER_NAME, "Unknown queue name %s", roxieName);
+
+    if (queue->getProp("@storagePlane", plane))
+        return plane;
+
+    //Find the first data plane - better if it was retrieved from roxie config
+    Owned<IPropertyTreeIterator> dataPlanes = getGlobalConfigSP()->getElements("storage/planes[labels='data']");
+    if (!dataPlanes->first())
+        throwUnexpectedX("No default data plane defined");
+    return plane.append(dataPlanes->query().queryProp("@name"));
+#else
+    Owned <IConstWUClusterInfo> clusterInfo(getTargetClusterInfo(roxieName));
+    StringBufferAdaptor process(plane);
+    if (clusterInfo && clusterInfo->getPlatform()==RoxieCluster)
+        clusterInfo->getRoxieProcess(process);
+    return plane;
+#endif
+}
diff --git a/esp/smc/SMCLib/TpWrapper.hpp b/esp/smc/SMCLib/TpWrapper.hpp
index 060281fa7..dc089cc04 100644
--- a/esp/smc/SMCLib/TpWrapper.hpp
+++ b/esp/smc/SMCLib/TpWrapper.hpp
@@ -225,5 +225,7 @@ extern TPWRAPPER_API void validateTargetName(const char* target);
 extern TPWRAPPER_API bool getSashaService(StringBuffer &serviceAddress, const char *service, bool failIfNotFound);
 extern TPWRAPPER_API bool getSashaServiceEP(SocketEndpoint &serviceEndpoint, const char *service, bool failIfNotFound);
 
+extern TPWRAPPER_API StringBuffer & getRoxieDefaultPlane(StringBuffer & plane, const char * roxieName);
+
 #endif //_ESPWIZ_TpWrapper_HPP__
 
diff --git a/esp/src/eclwatch/InfoGridWidget.js b/esp/src/eclwatch/InfoGridWidget.js
index 24dd9e6ff..4e5a61273 100755
--- a/esp/src/eclwatch/InfoGridWidget.js
+++ b/esp/src/eclwatch/InfoGridWidget.js
@@ -214,75 +214,15 @@ define([
                 this.infoData = [];
                 this.refreshTopics();
             },
-
-            toCSVCell: function (str) {
-                str = "" + str;
-                var mustQuote = (str.indexOf(",") >= 0 || str.indexOf("\"") >= 0 || str.indexOf("\r") >= 0 || str.indexOf("\n") >= 0);
-                if (mustQuote) {
-                    var retVal = "\"";
-                    for (var i = 0; i < str.length; ++i) {
-                        var c = str.charAt(i);
-                        retVal += c === "\"" ? "\"\"" : c;
-
-                    }
-                    retVal += "\"";
-                    return retVal;
-                }
-                return str;
-            },
-            csvFormatHeader: function (data, delim) {
-                var retVal = "";
-                if (data.length) {
-                    for (var key in data[0]) {
-                        if (retVal.length)
-                            retVal += delim;
-                        retVal += key;
-                    }
-                }
-                return retVal;
-            },
-            csvFormatRow: function (row, idx, delim) {
-                var retVal = "";
-                for (var key in row) {
-                    if (retVal.length)
-                        retVal += delim;
-                    retVal += this.toCSVCell(row[key]);
-                }
-                return retVal;
-            },
-            csvFormatFooter: function (data) {
-                return "";
-            },
-            toCSV: function (data, delim) {
-                var retVal = this.csvFormatHeader(data, delim) + "\n";
-                var context = this;
-                arrayUtil.forEach(data, function (item, idx) {
-                    retVal += context.csvFormatRow(item, idx, delim) + "\n";
-                });
-                retVal += this.csvFormatFooter(data);
-                return retVal;
-            },
             _onCopy: function (evt) {
-                var csvContent = this.toCSV(this.infoData, "\t");
+                var csvContent = Utility.toCSV(this.infoData, "\t");
                 this.widget.ErrWarnDialogTextArea.set("value", csvContent);
                 this.widget.ErrWarnDialog.show();
                 this.widget.ErrWarnDialogTextArea.focus();
                 this.widget.ErrWarnDialogTextArea.domNode.select();
             },
             _onDownload: function (evt) {
-                var csvContent = this.toCSV(this.infoData, ",");
-                var encodedUri = "data:text/csv;charset=utf-8,\uFEFF" + encodeURI(csvContent);
-                if (navigator.msSaveBlob) {
-                    var blob = new Blob([csvContent], {
-                        type: "text/csv;charset=utf-8;"
-                    });
-                    navigator.msSaveBlob(blob, "ErrWarn.csv");
-                } else {
-                    var link = document.createElement("a");
-                    link.setAttribute("href", encodedUri);
-                    link.appendChild(document.createTextNode("ErrWarn.csv"));
-                    link.click();
-                }
+                Utility.downloadText(Utility.toCSV(this.infoData, ","), "ErrWarn.csv");
             },
 
             _onErrors: function (args) {
diff --git a/esp/src/eclwatch/WUQueryWidget.js b/esp/src/eclwatch/WUQueryWidget.js
index dad7b62f6..01ca009a5 100644
--- a/esp/src/eclwatch/WUQueryWidget.js
+++ b/esp/src/eclwatch/WUQueryWidget.js
@@ -105,7 +105,7 @@ define([
             var fileName = this.fileName.get("value") + ".csv";
 
             arrayUtil.forEach(selections, function (cell, idx) {
-                var rowData = [cell.Protected, cell.Wuid, cell.Owner, cell.Jobname, cell.Cluster, cell.RoxieCluster, cell.State, cell.TotalClusterTime];
+                var rowData = [cell.Protected, cell.Wuid, cell.Owner, cell.Jobname, cell.Cluster, cell.State, cell.TotalClusterTime];
                 row.push(rowData);
             });
 
@@ -478,13 +478,12 @@ define([
                             return wu.getStateImageHTML() + "&nbsp;<a href='#/workunits/" + Wuid + "' class='dgrid-row-url' onClick='return false;'>" + Wuid + "</a>";
                         }
                     },
-                    Owner: { label: this.i18n.Owner, width: 90 },
-                    Jobname: { label: this.i18n.JobName, width: 500 },
+                    Owner: { label: this.i18n.Owner, width: 120 },
+                    Jobname: { label: this.i18n.JobName },
                     Cluster: { label: this.i18n.Cluster, width: 90 },
-                    RoxieCluster: { label: this.i18n.RoxieCluster, width: 99 },
                     State: { label: this.i18n.State, width: 90 },
                     TotalClusterTime: {
-                        label: this.i18n.TotalClusterTime, width: 117,
+                        label: this.i18n.TotalClusterTime, width: 150,
                         renderCell: function (object, value, node, options) {
                             domClass.add(node, "justify-right");
                             node.innerText = value;
diff --git a/esp/src/package-lock.json b/esp/src/package-lock.json
index 5c0b76301..52931b93d 100644
--- a/esp/src/package-lock.json
+++ b/esp/src/package-lock.json
@@ -14,18 +14,18 @@
       }
     },
     "@babel/helper-validator-identifier": {
-      "version": "7.12.11",
-      "resolved": "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.12.11.tgz",
-      "integrity": "sha512-np/lG3uARFybkoHokJUmf1QfEvRVCPbmQeUQpKow5cQ3xWrV9i3rUHodKDJPQfTVX61qKi+UdYk8kik84n7XOw==",
+      "version": "7.14.0",
+      "resolved": "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.14.0.tgz",
+      "integrity": "sha512-V3ts7zMSu5lfiwWDVWzRDGIN+lnCEUdaXgtVHJgLb1rGaA6jMrtB9EmE7L18foXJIE8Un/A/h6NJfGQp/e1J4A==",
       "dev": true
     },
     "@babel/highlight": {
-      "version": "7.13.8",
-      "resolved": "https://registry.npmjs.org/@babel/highlight/-/highlight-7.13.8.tgz",
-      "integrity": "sha512-4vrIhfJyfNf+lCtXC2ck1rKSzDwciqF7IWFhXXrSOUC2O5DrVp+w4c6ed4AllTxhTkUP5x2tYj41VaxdVMMRDw==",
+      "version": "7.14.0",
+      "resolved": "https://registry.npmjs.org/@babel/highlight/-/highlight-7.14.0.tgz",
+      "integrity": "sha512-YSCOwxvTYEIMSGaBQb5kDDsCopDdiUGsqpatp3fOlI4+2HQSkTmEVWnVuySdAC5EWCqSWWTv0ib63RjR7dTBdg==",
       "dev": true,
       "requires": {
-        "@babel/helper-validator-identifier": "^7.12.11",
+        "@babel/helper-validator-identifier": "^7.14.0",
         "chalk": "^2.0.0",
         "js-tokens": "^4.0.0"
       }
@@ -50,9 +50,9 @@
       "integrity": "sha512-kBJtf7PH6aWwZ6fka3zQ0p6SBYzx4fl1LoZXE2RrnYST9Xljm7WfKJrU4g/Xr3Beg72MLrp1AWNUmuYJTL7Cow=="
     },
     "@eslint/eslintrc": {
-      "version": "0.4.0",
-      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-0.4.0.tgz",
-      "integrity": "sha512-2ZPCc+uNbjV5ERJr+aKSPRwZgKd2z11x0EgLvb1PURmUrn9QNRXFqje0Ldq454PfAVyaJYyrDvvIKSFP4NnBog==",
+      "version": "0.4.1",
+      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-0.4.1.tgz",
+      "integrity": "sha512-5v7TDE9plVhvxQeWLXDTvFvJBdH6pEsdnl2g/dAptmuFEPedQ4Erq5rsDsX+mvAM610IhNaO2W5V1dOOnDKxkQ==",
       "dev": true,
       "requires": {
         "ajv": "^6.12.4",
@@ -83,22 +83,34 @@
           "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
           "integrity": "sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==",
           "dev": true
+        },
+        "globals": {
+          "version": "12.4.0",
+          "resolved": "https://registry.npmjs.org/globals/-/globals-12.4.0.tgz",
+          "integrity": "sha512-BWICuzzDvDoH54NHKCseDanAhE3CeDorgDL5MT6LMXXj2WCnd9UC2szdk4AWLfjdgNBCXLUanXYcpBBKOSWGwg==",
+          "dev": true,
+          "requires": {
+            "type-fest": "^0.8.1"
+          }
         }
       }
     },
     "@fluentui/date-time-utilities": {
-      "version": "8.0.1",
-      "resolved": "https://registry.npmjs.org/@fluentui/date-time-utilities/-/date-time-utilities-8.0.1.tgz",
-      "integrity": "sha512-s6yafxXMQlkXAVgANf7mjWqgd4YaqYXT1Vqv9Kf9vinNtQurBY7wiN/b0CjcDbzDqEzT5dM0NLMG3pg5L/8hpA==",
+      "version": "8.1.0",
+      "resolved": "https://registry.npmjs.org/@fluentui/date-time-utilities/-/date-time-utilities-8.1.0.tgz",
+      "integrity": "sha512-1PSp/ufi5urnvxkbT9Lijsh7Y2PNEsZfpNXDVwOpPDqpRkRrd8Wr8IdRPQk7w6XLZIeDCiWIBXBRYCVp6KGbYg==",
       "requires": {
-        "@fluentui/set-version": "^8.0.1",
-        "tslib": "^1.10.0"
+        "@fluentui/set-version": "^8.1.0",
+        "tslib": "^2.1.0"
       },
       "dependencies": {
-        "tslib": {
-          "version": "1.14.1",
-          "resolved": "https://registry.npmjs.org/tslib/-/tslib-1.14.1.tgz",
-          "integrity": "sha512-Xni35NKzjgMrwevysHTCArtLDpPvye8zV/0E4EyYn43P7/7qvQwPh9BGkHewbMulVntbigmcT7rdX3BNo9wRJg=="
+        "@fluentui/set-version": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/set-version/-/set-version-8.1.0.tgz",
+          "integrity": "sha512-FhruPyh+VoAVmqAadRxawMNB13syBLoT6PePdZ+sKW7rZVc2CWT3qw7w9O9x6MJeRNl6/6ZnjCo6sWyOyVEdNg==",
+          "requires": {
+            "tslib": "^2.1.0"
+          }
         }
       }
     },
@@ -119,19 +131,75 @@
       }
     },
     "@fluentui/font-icons-mdl2": {
-      "version": "8.0.2",
-      "resolved": "https://registry.npmjs.org/@fluentui/font-icons-mdl2/-/font-icons-mdl2-8.0.2.tgz",
-      "integrity": "sha512-KiEKYJgMbRiWI2az04QY2o7icCkHwEWsGSFlpLvwCJNvMAw22o/Dnx6vnJM/F1aH90TvC16OILpGzwH1IH3o+Q==",
+      "version": "8.1.0",
+      "resolved": "https://registry.npmjs.org/@fluentui/font-icons-mdl2/-/font-icons-mdl2-8.1.0.tgz",
+      "integrity": "sha512-U0nAsv/vULZ4ezHDw0umk4mijSot9BNDXl0dZ4ZatxLBr8JZkNgTDowBZ9aEyWuFukZ6Lf0V/eEPIeJULrUDfw==",
       "requires": {
-        "@fluentui/set-version": "^8.0.1",
-        "@fluentui/style-utilities": "^8.0.2",
-        "tslib": "^1.10.0"
+        "@fluentui/set-version": "^8.1.0",
+        "@fluentui/style-utilities": "^8.1.0",
+        "tslib": "^2.1.0"
       },
       "dependencies": {
-        "tslib": {
-          "version": "1.14.1",
-          "resolved": "https://registry.npmjs.org/tslib/-/tslib-1.14.1.tgz",
-          "integrity": "sha512-Xni35NKzjgMrwevysHTCArtLDpPvye8zV/0E4EyYn43P7/7qvQwPh9BGkHewbMulVntbigmcT7rdX3BNo9wRJg=="
+        "@fluentui/dom-utilities": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/dom-utilities/-/dom-utilities-2.1.0.tgz",
+          "integrity": "sha512-DMr0uH4EtyXgdpVLyvWq60YtWN38jx22rtdsEIbbBNYcFgcl3rRa7M8p/rnaw/k/KWX35H40AYga1SM6Zgpyww==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/merge-styles": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/merge-styles/-/merge-styles-8.1.0.tgz",
+          "integrity": "sha512-afJ8rw1V3sfgzfufP7ockcP5AxiQN7VlqKo6JoCSZbWC2ypQ0DZre7d3k+Zj2LvjCrM8HM57YEfwXWT/WxGfqw==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/set-version": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/set-version/-/set-version-8.1.0.tgz",
+          "integrity": "sha512-FhruPyh+VoAVmqAadRxawMNB13syBLoT6PePdZ+sKW7rZVc2CWT3qw7w9O9x6MJeRNl6/6ZnjCo6sWyOyVEdNg==",
+          "requires": {
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/style-utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/style-utilities/-/style-utilities-8.1.0.tgz",
+          "integrity": "sha512-XUH+8T7/2HAMYzTLr20odD5lfKy56fJooFlkSmW0SSC6sOilHmrdPZCBSTV+WJzH/YY2ed/GnySIjCQOx5UsYg==",
+          "requires": {
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "@fluentui/theme": "^2.1.0",
+            "@fluentui/utilities": "^8.1.0",
+            "@microsoft/load-themed-styles": "^1.10.26",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/theme": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/theme/-/theme-2.1.0.tgz",
+          "integrity": "sha512-2jFun5LqUZJb+AiWeLOnNQTxrKWMCNHFTs4+QIUyL7ZPMAiNZyWMsQJfeGOujzdlReivZ7kONNQEi0LTJ0Tmzw==",
+          "requires": {
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "@fluentui/utilities": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/utilities/-/utilities-8.1.0.tgz",
+          "integrity": "sha512-/yHnDkrIlyn/Jy3XWccNRyuujQDgUxz44OQDEiMSko50S/L7cVeWdIzG/CiIsCnKAgU4/QyzRo40Wdy3rdM8ag==",
+          "requires": {
+            "@fluentui/dom-utilities": "^2.1.0",
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
         }
       }
     },
@@ -186,30 +254,106 @@
       }
     },
     "@fluentui/react": {
-      "version": "8.1.4",
-      "resolved": "https://registry.npmjs.org/@fluentui/react/-/react-8.1.4.tgz",
-      "integrity": "sha512-v0487DpIsL4pexkorEkEpzXWZNUh3mrUTw/eO9eDKyOwDteTZr+pLDO1NlBRDtujH49S0BsLpiyDUqTdga4WCQ==",
-      "requires": {
-        "@fluentui/date-time-utilities": "^8.0.1",
-        "@fluentui/font-icons-mdl2": "^8.0.2",
-        "@fluentui/foundation-legacy": "^8.0.2",
-        "@fluentui/merge-styles": "^8.0.2",
-        "@fluentui/react-focus": "^8.0.2",
-        "@fluentui/react-hooks": "^8.0.2",
-        "@fluentui/react-shared-contexts": "^1.0.0-beta.10",
-        "@fluentui/react-window-provider": "^2.0.1",
-        "@fluentui/set-version": "^8.0.1",
-        "@fluentui/style-utilities": "^8.0.2",
-        "@fluentui/theme": "^2.0.2",
-        "@fluentui/utilities": "^8.0.2",
+      "version": "8.14.5",
+      "resolved": "https://registry.npmjs.org/@fluentui/react/-/react-8.14.5.tgz",
+      "integrity": "sha512-2UDjVTYvWWm7kZ5nOlUWBg0hlZkh3GHLzxkPanlFURGnI1AT5P25/TY/EoawJUsOaRv3klWjUfPTQfyzPuNFQw==",
+      "requires": {
+        "@fluentui/date-time-utilities": "^8.1.0",
+        "@fluentui/font-icons-mdl2": "^8.1.0",
+        "@fluentui/foundation-legacy": "^8.1.0",
+        "@fluentui/merge-styles": "^8.1.0",
+        "@fluentui/react-focus": "^8.1.0",
+        "@fluentui/react-hooks": "^8.2.0",
+        "@fluentui/react-window-provider": "^2.1.0",
+        "@fluentui/set-version": "^8.1.0",
+        "@fluentui/style-utilities": "^8.1.0",
+        "@fluentui/theme": "^2.1.0",
+        "@fluentui/utilities": "^8.1.0",
         "@microsoft/load-themed-styles": "^1.10.26",
-        "tslib": "^1.10.0"
+        "tslib": "^2.1.0"
       },
       "dependencies": {
-        "tslib": {
-          "version": "1.14.1",
-          "resolved": "https://registry.npmjs.org/tslib/-/tslib-1.14.1.tgz",
-          "integrity": "sha512-Xni35NKzjgMrwevysHTCArtLDpPvye8zV/0E4EyYn43P7/7qvQwPh9BGkHewbMulVntbigmcT7rdX3BNo9wRJg=="
+        "@fluentui/dom-utilities": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/dom-utilities/-/dom-utilities-2.1.0.tgz",
+          "integrity": "sha512-DMr0uH4EtyXgdpVLyvWq60YtWN38jx22rtdsEIbbBNYcFgcl3rRa7M8p/rnaw/k/KWX35H40AYga1SM6Zgpyww==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/foundation-legacy": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/foundation-legacy/-/foundation-legacy-8.1.0.tgz",
+          "integrity": "sha512-GC6MkfcBbfqltgKe0hi4Wq0DTj8UxSFUdoOG9QQDLjIjI1r+L935ba0x91phqB9nptJCp+5TjkTtz7Q1lJ97Tw==",
+          "requires": {
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "@fluentui/style-utilities": "^8.1.0",
+            "@fluentui/utilities": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/merge-styles": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/merge-styles/-/merge-styles-8.1.0.tgz",
+          "integrity": "sha512-afJ8rw1V3sfgzfufP7ockcP5AxiQN7VlqKo6JoCSZbWC2ypQ0DZre7d3k+Zj2LvjCrM8HM57YEfwXWT/WxGfqw==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/react-window-provider": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/react-window-provider/-/react-window-provider-2.1.0.tgz",
+          "integrity": "sha512-LcNni1utHiXiCu8EbXL42o118yNRAWKX15qKd0iyMqcUg5RplOdWuaniohXv2gsmdNB0l3F5Tnujgayy0xPlvQ==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/set-version": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/set-version/-/set-version-8.1.0.tgz",
+          "integrity": "sha512-FhruPyh+VoAVmqAadRxawMNB13syBLoT6PePdZ+sKW7rZVc2CWT3qw7w9O9x6MJeRNl6/6ZnjCo6sWyOyVEdNg==",
+          "requires": {
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/style-utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/style-utilities/-/style-utilities-8.1.0.tgz",
+          "integrity": "sha512-XUH+8T7/2HAMYzTLr20odD5lfKy56fJooFlkSmW0SSC6sOilHmrdPZCBSTV+WJzH/YY2ed/GnySIjCQOx5UsYg==",
+          "requires": {
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "@fluentui/theme": "^2.1.0",
+            "@fluentui/utilities": "^8.1.0",
+            "@microsoft/load-themed-styles": "^1.10.26",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/theme": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/theme/-/theme-2.1.0.tgz",
+          "integrity": "sha512-2jFun5LqUZJb+AiWeLOnNQTxrKWMCNHFTs4+QIUyL7ZPMAiNZyWMsQJfeGOujzdlReivZ7kONNQEi0LTJ0Tmzw==",
+          "requires": {
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "@fluentui/utilities": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/utilities/-/utilities-8.1.0.tgz",
+          "integrity": "sha512-/yHnDkrIlyn/Jy3XWccNRyuujQDgUxz44OQDEiMSko50S/L7cVeWdIzG/CiIsCnKAgU4/QyzRo40Wdy3rdM8ag==",
+          "requires": {
+            "@fluentui/dom-utilities": "^2.1.0",
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
         }
       }
     },
@@ -258,56 +402,269 @@
       }
     },
     "@fluentui/react-focus": {
-      "version": "8.0.2",
-      "resolved": "https://registry.npmjs.org/@fluentui/react-focus/-/react-focus-8.0.2.tgz",
-      "integrity": "sha512-ySv9TR6rE6awMroxs3PZ1N+j4BSmo6Ajw+ZtN7UNM3IpHdzNetiqN3f+4UF8NMDuKwVKSNDNxfNddRQ0CsLmYQ==",
+      "version": "8.1.0",
+      "resolved": "https://registry.npmjs.org/@fluentui/react-focus/-/react-focus-8.1.0.tgz",
+      "integrity": "sha512-yzfDnDrnHq5z4Nt1xY7LS+DtjbJmCdpDiTiQm8tnCj98qESzqqqAwjpSc+HFXVexBzlmPNf1hzc8BMCQOUF/7g==",
       "requires": {
-        "@fluentui/keyboard-key": "^0.2.14",
-        "@fluentui/merge-styles": "^8.0.2",
-        "@fluentui/set-version": "^8.0.1",
-        "@fluentui/style-utilities": "^8.0.2",
-        "@fluentui/utilities": "^8.0.2",
-        "tslib": "^1.10.0"
+        "@fluentui/keyboard-key": "^0.3.0",
+        "@fluentui/merge-styles": "^8.1.0",
+        "@fluentui/set-version": "^8.1.0",
+        "@fluentui/style-utilities": "^8.1.0",
+        "@fluentui/utilities": "^8.1.0",
+        "tslib": "^2.1.0"
       },
       "dependencies": {
-        "tslib": {
-          "version": "1.14.1",
-          "resolved": "https://registry.npmjs.org/tslib/-/tslib-1.14.1.tgz",
-          "integrity": "sha512-Xni35NKzjgMrwevysHTCArtLDpPvye8zV/0E4EyYn43P7/7qvQwPh9BGkHewbMulVntbigmcT7rdX3BNo9wRJg=="
+        "@fluentui/dom-utilities": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/dom-utilities/-/dom-utilities-2.1.0.tgz",
+          "integrity": "sha512-DMr0uH4EtyXgdpVLyvWq60YtWN38jx22rtdsEIbbBNYcFgcl3rRa7M8p/rnaw/k/KWX35H40AYga1SM6Zgpyww==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/keyboard-key": {
+          "version": "0.3.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/keyboard-key/-/keyboard-key-0.3.0.tgz",
+          "integrity": "sha512-5GZ9038lwNK5BcgFkbXJs6zpZUlmyrszWbKPMqcHysMFBbL569VwV7zQt/yF3ivL0L4k46C+uXHbnFbMgZEJ4w==",
+          "requires": {
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/merge-styles": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/merge-styles/-/merge-styles-8.1.0.tgz",
+          "integrity": "sha512-afJ8rw1V3sfgzfufP7ockcP5AxiQN7VlqKo6JoCSZbWC2ypQ0DZre7d3k+Zj2LvjCrM8HM57YEfwXWT/WxGfqw==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/set-version": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/set-version/-/set-version-8.1.0.tgz",
+          "integrity": "sha512-FhruPyh+VoAVmqAadRxawMNB13syBLoT6PePdZ+sKW7rZVc2CWT3qw7w9O9x6MJeRNl6/6ZnjCo6sWyOyVEdNg==",
+          "requires": {
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/style-utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/style-utilities/-/style-utilities-8.1.0.tgz",
+          "integrity": "sha512-XUH+8T7/2HAMYzTLr20odD5lfKy56fJooFlkSmW0SSC6sOilHmrdPZCBSTV+WJzH/YY2ed/GnySIjCQOx5UsYg==",
+          "requires": {
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "@fluentui/theme": "^2.1.0",
+            "@fluentui/utilities": "^8.1.0",
+            "@microsoft/load-themed-styles": "^1.10.26",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/theme": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/theme/-/theme-2.1.0.tgz",
+          "integrity": "sha512-2jFun5LqUZJb+AiWeLOnNQTxrKWMCNHFTs4+QIUyL7ZPMAiNZyWMsQJfeGOujzdlReivZ7kONNQEi0LTJ0Tmzw==",
+          "requires": {
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "@fluentui/utilities": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/utilities/-/utilities-8.1.0.tgz",
+          "integrity": "sha512-/yHnDkrIlyn/Jy3XWccNRyuujQDgUxz44OQDEiMSko50S/L7cVeWdIzG/CiIsCnKAgU4/QyzRo40Wdy3rdM8ag==",
+          "requires": {
+            "@fluentui/dom-utilities": "^2.1.0",
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
         }
       }
     },
     "@fluentui/react-hooks": {
-      "version": "8.0.2",
-      "resolved": "https://registry.npmjs.org/@fluentui/react-hooks/-/react-hooks-8.0.2.tgz",
-      "integrity": "sha512-6/ES+AakKfISMMV7GCI+UEDxuL84Se89SKwcIqCrnq79r0dyu4husvwM2QRXeNvnHerTyARg+yN+6MOmzqyQEA==",
+      "version": "8.2.0",
+      "resolved": "https://registry.npmjs.org/@fluentui/react-hooks/-/react-hooks-8.2.0.tgz",
+      "integrity": "sha512-FnmtkDurjnLXN/VssBnQQ19RGY3mUh+rLiYa4VRBWRIh1JTs7o6DGCu+IijvvFNzTHvsMgL/O3v/2UjXShO6uQ==",
       "requires": {
-        "@fluentui/react-window-provider": "^2.0.1",
-        "@fluentui/set-version": "^8.0.1",
-        "@fluentui/utilities": "^8.0.2",
-        "tslib": "^1.10.0"
+        "@fluentui/react-window-provider": "^2.1.0",
+        "@fluentui/set-version": "^8.1.0",
+        "@fluentui/utilities": "^8.1.0",
+        "tslib": "^2.1.0"
       },
       "dependencies": {
-        "tslib": {
-          "version": "1.14.1",
-          "resolved": "https://registry.npmjs.org/tslib/-/tslib-1.14.1.tgz",
-          "integrity": "sha512-Xni35NKzjgMrwevysHTCArtLDpPvye8zV/0E4EyYn43P7/7qvQwPh9BGkHewbMulVntbigmcT7rdX3BNo9wRJg=="
+        "@fluentui/dom-utilities": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/dom-utilities/-/dom-utilities-2.1.0.tgz",
+          "integrity": "sha512-DMr0uH4EtyXgdpVLyvWq60YtWN38jx22rtdsEIbbBNYcFgcl3rRa7M8p/rnaw/k/KWX35H40AYga1SM6Zgpyww==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/merge-styles": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/merge-styles/-/merge-styles-8.1.0.tgz",
+          "integrity": "sha512-afJ8rw1V3sfgzfufP7ockcP5AxiQN7VlqKo6JoCSZbWC2ypQ0DZre7d3k+Zj2LvjCrM8HM57YEfwXWT/WxGfqw==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/react-window-provider": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/react-window-provider/-/react-window-provider-2.1.0.tgz",
+          "integrity": "sha512-LcNni1utHiXiCu8EbXL42o118yNRAWKX15qKd0iyMqcUg5RplOdWuaniohXv2gsmdNB0l3F5Tnujgayy0xPlvQ==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/set-version": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/set-version/-/set-version-8.1.0.tgz",
+          "integrity": "sha512-FhruPyh+VoAVmqAadRxawMNB13syBLoT6PePdZ+sKW7rZVc2CWT3qw7w9O9x6MJeRNl6/6ZnjCo6sWyOyVEdNg==",
+          "requires": {
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/utilities/-/utilities-8.1.0.tgz",
+          "integrity": "sha512-/yHnDkrIlyn/Jy3XWccNRyuujQDgUxz44OQDEiMSko50S/L7cVeWdIzG/CiIsCnKAgU4/QyzRo40Wdy3rdM8ag==",
+          "requires": {
+            "@fluentui/dom-utilities": "^2.1.0",
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
         }
       }
     },
-    "@fluentui/react-shared-contexts": {
-      "version": "1.0.0-beta.10",
-      "resolved": "https://registry.npmjs.org/@fluentui/react-shared-contexts/-/react-shared-contexts-1.0.0-beta.10.tgz",
-      "integrity": "sha512-z9HScE3I4jQBbHG4Sel2JCjx0hxDKY6l8x6Qr6q4vuI3p5Hdz36z1z/9vWhHLxslvRNO7qL/GhlKh7noOiZuVQ==",
+    "@fluentui/react-icon-provider": {
+      "version": "1.1.0",
+      "resolved": "https://registry.npmjs.org/@fluentui/react-icon-provider/-/react-icon-provider-1.1.0.tgz",
+      "integrity": "sha512-kn5SXSoDaK63I0/7guQNCqr0BUNLiiQ3TmzjCuXieafEkOH4SInZOuA9n83JWWSuvjcOZWjy8xU5Km35obfFWg==",
       "requires": {
-        "@fluentui/set-version": "^8.0.1",
-        "tslib": "^1.10.0"
+        "@fluentui/set-version": "^8.1.0",
+        "@fluentui/style-utilities": "^8.1.0",
+        "tslib": "^2.1.0"
       },
       "dependencies": {
-        "tslib": {
-          "version": "1.14.1",
-          "resolved": "https://registry.npmjs.org/tslib/-/tslib-1.14.1.tgz",
-          "integrity": "sha512-Xni35NKzjgMrwevysHTCArtLDpPvye8zV/0E4EyYn43P7/7qvQwPh9BGkHewbMulVntbigmcT7rdX3BNo9wRJg=="
+        "@fluentui/dom-utilities": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/dom-utilities/-/dom-utilities-2.1.0.tgz",
+          "integrity": "sha512-DMr0uH4EtyXgdpVLyvWq60YtWN38jx22rtdsEIbbBNYcFgcl3rRa7M8p/rnaw/k/KWX35H40AYga1SM6Zgpyww==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/merge-styles": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/merge-styles/-/merge-styles-8.1.0.tgz",
+          "integrity": "sha512-afJ8rw1V3sfgzfufP7ockcP5AxiQN7VlqKo6JoCSZbWC2ypQ0DZre7d3k+Zj2LvjCrM8HM57YEfwXWT/WxGfqw==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/set-version": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/set-version/-/set-version-8.1.0.tgz",
+          "integrity": "sha512-FhruPyh+VoAVmqAadRxawMNB13syBLoT6PePdZ+sKW7rZVc2CWT3qw7w9O9x6MJeRNl6/6ZnjCo6sWyOyVEdNg==",
+          "requires": {
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/style-utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/style-utilities/-/style-utilities-8.1.0.tgz",
+          "integrity": "sha512-XUH+8T7/2HAMYzTLr20odD5lfKy56fJooFlkSmW0SSC6sOilHmrdPZCBSTV+WJzH/YY2ed/GnySIjCQOx5UsYg==",
+          "requires": {
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "@fluentui/theme": "^2.1.0",
+            "@fluentui/utilities": "^8.1.0",
+            "@microsoft/load-themed-styles": "^1.10.26",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/theme": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/theme/-/theme-2.1.0.tgz",
+          "integrity": "sha512-2jFun5LqUZJb+AiWeLOnNQTxrKWMCNHFTs4+QIUyL7ZPMAiNZyWMsQJfeGOujzdlReivZ7kONNQEi0LTJ0Tmzw==",
+          "requires": {
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "@fluentui/utilities": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/utilities/-/utilities-8.1.0.tgz",
+          "integrity": "sha512-/yHnDkrIlyn/Jy3XWccNRyuujQDgUxz44OQDEiMSko50S/L7cVeWdIzG/CiIsCnKAgU4/QyzRo40Wdy3rdM8ag==",
+          "requires": {
+            "@fluentui/dom-utilities": "^2.1.0",
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        }
+      }
+    },
+    "@fluentui/react-icons-mdl2": {
+      "version": "1.1.0",
+      "resolved": "https://registry.npmjs.org/@fluentui/react-icons-mdl2/-/react-icons-mdl2-1.1.0.tgz",
+      "integrity": "sha512-UXpgtTpzmcLlTRkLWI3U+YfdN99I0qTBLU1xGnyPDyUIKJttTq1gLudLsr5Jm60hW9mf/AX6qXt9j5P25m1/5g==",
+      "requires": {
+        "@fluentui/react-icon-provider": "^1.1.0",
+        "@fluentui/set-version": "^8.1.0",
+        "@fluentui/utilities": "^8.1.0",
+        "@microsoft/load-themed-styles": "^1.10.26",
+        "tslib": "^2.1.0"
+      },
+      "dependencies": {
+        "@fluentui/dom-utilities": {
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/dom-utilities/-/dom-utilities-2.1.0.tgz",
+          "integrity": "sha512-DMr0uH4EtyXgdpVLyvWq60YtWN38jx22rtdsEIbbBNYcFgcl3rRa7M8p/rnaw/k/KWX35H40AYga1SM6Zgpyww==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/merge-styles": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/merge-styles/-/merge-styles-8.1.0.tgz",
+          "integrity": "sha512-afJ8rw1V3sfgzfufP7ockcP5AxiQN7VlqKo6JoCSZbWC2ypQ0DZre7d3k+Zj2LvjCrM8HM57YEfwXWT/WxGfqw==",
+          "requires": {
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/set-version": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/set-version/-/set-version-8.1.0.tgz",
+          "integrity": "sha512-FhruPyh+VoAVmqAadRxawMNB13syBLoT6PePdZ+sKW7rZVc2CWT3qw7w9O9x6MJeRNl6/6ZnjCo6sWyOyVEdNg==",
+          "requires": {
+            "tslib": "^2.1.0"
+          }
+        },
+        "@fluentui/utilities": {
+          "version": "8.1.0",
+          "resolved": "https://registry.npmjs.org/@fluentui/utilities/-/utilities-8.1.0.tgz",
+          "integrity": "sha512-/yHnDkrIlyn/Jy3XWccNRyuujQDgUxz44OQDEiMSko50S/L7cVeWdIzG/CiIsCnKAgU4/QyzRo40Wdy3rdM8ag==",
+          "requires": {
+            "@fluentui/dom-utilities": "^2.1.0",
+            "@fluentui/merge-styles": "^8.1.0",
+            "@fluentui/set-version": "^8.1.0",
+            "tslib": "^2.1.0"
+          }
         }
       }
     },
@@ -456,35 +813,60 @@
       }
     },
     "@hpcc-js/api": {
-      "version": "2.8.42",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/api/-/api-2.8.42.tgz",
-      "integrity": "sha512-DrLxZ0dmoux0WJhUSv+EIf+fgFJXU2ZBQFlgDTOcKqQtFYFIx18SepRM/89hhsduHY5uFHvB9z+utDYGqwj3cA==",
+      "version": "2.8.43",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/api/-/api-2.8.43.tgz",
+      "integrity": "sha512-UDiN19j0d2zEQRsQH8T7swoEuy2byY+b8TpoNMA5BFzxcqe9fzZ72iZA98T2Fi/mMVhdLxoqJwAYkwx+nPdVkA==",
       "requires": {
-        "@hpcc-js/common": "^2.47.0"
+        "@hpcc-js/common": "^2.48.0"
       }
     },
     "@hpcc-js/chart": {
-      "version": "2.57.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/chart/-/chart-2.57.0.tgz",
-      "integrity": "sha512-naXNiEKK1fqSDOXbLbdblFgenIKgcv+Og3QKYux4nF7KJ0R+SMkho7iROz4oqbCO2rLHn1lVl+5gKAA9rJrJIA==",
+      "version": "2.58.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/chart/-/chart-2.58.0.tgz",
+      "integrity": "sha512-VYKRbqX49lHrW0e/RXcGDJV50YvwgPWJHj40vT4tiF1lgJr+exXLRj/RbFrBj0PLINIcUCRa1ClDI6iOnS10aQ==",
       "requires": {
-        "@hpcc-js/api": "^2.8.42",
-        "@hpcc-js/common": "^2.47.0",
+        "@hpcc-js/api": "^2.8.43",
+        "@hpcc-js/common": "^2.48.0",
         "@hpcc-js/util": "^2.29.0"
       }
     },
     "@hpcc-js/codemirror": {
-      "version": "2.38.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/codemirror/-/codemirror-2.38.0.tgz",
-      "integrity": "sha512-zyzB74F0Uc4qt/lPAbABX+jCvo3eb1K3gZ9Dm1yNxSGV29Z+tKZ1hywuwrtYJC8Evn9FDQCrXZPSu0BCFeDN3w==",
+      "version": "2.40.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/codemirror/-/codemirror-2.40.0.tgz",
+      "integrity": "sha512-oSWVv2St9gfP49C6c0BrqcQ2qpPACplWVdW3R/SaqeNWXihtJeCJOGz+bzzdGqsSqXd7nvXDnoBjjcGxiiNWSw==",
       "requires": {
-        "@hpcc-js/common": "^2.47.0"
+        "@hpcc-js/common": "^2.48.0"
+      },
+      "dependencies": {
+        "@hpcc-js/common": {
+          "version": "2.48.0",
+          "resolved": "https://registry.npmjs.org/@hpcc-js/common/-/common-2.48.0.tgz",
+          "integrity": "sha512-RtM7genqXIkEm8Z2kLIa+UCGTYqYiWoldALqX9Hk3Z2b7lNTtuZKx/DRcwaPhkI7SOuVA50ou1agbsBuFeOCvg==",
+          "requires": {
+            "@hpcc-js/util": "^2.29.0",
+            "@types/d3-array": "1.2.6",
+            "@types/d3-brush": "1.0.10",
+            "@types/d3-collection": "1.0.8",
+            "@types/d3-color": "1.2.2",
+            "@types/d3-dispatch": "1.0.7",
+            "@types/d3-drag": "1.2.3",
+            "@types/d3-dsv": "1.0.36",
+            "@types/d3-ease": "1.0.8",
+            "@types/d3-format": "1.3.1",
+            "@types/d3-interpolate": "1.3.1",
+            "@types/d3-scale": "1.0.14",
+            "@types/d3-selection": "1.4.1",
+            "@types/d3-time-format": "2.1.1",
+            "@types/d3-transition": "1.1.4",
+            "@types/d3-zoom": "1.7.4"
+          }
+        }
       }
     },
     "@hpcc-js/common": {
-      "version": "2.47.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/common/-/common-2.47.0.tgz",
-      "integrity": "sha512-hFCIEbxJd4xk9C5NmPlb+VtvuHO/+1QlpYihldJ/4yfAjga59XMDRMs8qQazvgQZNHatTtrBHpZyY0oetkzRJQ==",
+      "version": "2.48.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/common/-/common-2.48.0.tgz",
+      "integrity": "sha512-RtM7genqXIkEm8Z2kLIa+UCGTYqYiWoldALqX9Hk3Z2b7lNTtuZKx/DRcwaPhkI7SOuVA50ou1agbsBuFeOCvg==",
       "requires": {
         "@hpcc-js/util": "^2.29.0",
         "@types/d3-array": "1.2.6",
@@ -505,9 +887,9 @@
       }
     },
     "@hpcc-js/comms": {
-      "version": "2.40.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/comms/-/comms-2.40.0.tgz",
-      "integrity": "sha512-g3bnsmQPNw1O7O2M6gI4fYIkTtpXKaVmFC2qEGCEbOJEGYdqLCGS3NQk2Fk5vAo8QiMOD2wZz3HJhg+kQDTejQ==",
+      "version": "2.41.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/comms/-/comms-2.41.0.tgz",
+      "integrity": "sha512-Z/jiewMYqV7RMJcmfeEOwv8d4A01OxSjFuBiQIHiylEfeFpH4pw8ZYJOxjZJfQPZqIpm1TVFLkMSYEAtTku+nA==",
       "requires": {
         "@hpcc-js/ddl-shim": "^2.17.15",
         "@hpcc-js/util": "^2.29.0",
@@ -531,11 +913,11 @@
       }
     },
     "@hpcc-js/dgrid": {
-      "version": "2.8.42",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/dgrid/-/dgrid-2.8.42.tgz",
-      "integrity": "sha512-JwargwjDxCtnj6QkfLtwxx4Jjsm/MvmF87Gj/XHzPcaiK2PRbOqlH940v6Cu2npczg5hBc/Nso/PI+Jh2gAjxw==",
+      "version": "2.9.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/dgrid/-/dgrid-2.9.0.tgz",
+      "integrity": "sha512-G+3jTTzERoqWtbKDiBzqvxCpNxWxZiYJQFqGa+wFiIz6G/1Y2dLVB0C6H568iC1tnoNJFvUrinHo6O2PoOk07w==",
       "requires": {
-        "@hpcc-js/common": "^2.47.0",
+        "@hpcc-js/common": "^2.48.0",
         "@hpcc-js/ddl-shim": "^2.17.15",
         "@hpcc-js/dgrid-shim": "^2.11.22",
         "@hpcc-js/util": "^2.29.0"
@@ -547,196 +929,52 @@
       "integrity": "sha512-D2S7JBWJyTV819G00xis9yj4NA/tV+o79kiwBeqma5tAMF9UPBgOdtj24BsXVPbjM3uLiCD7irsfY0g+DuFD5Q=="
     },
     "@hpcc-js/eclwatch": {
-      "version": "2.34.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/eclwatch/-/eclwatch-2.34.0.tgz",
-      "integrity": "sha512-cwFa3Tmk5lBEpo1hEwJfJz1ZxmRLKwXW3Q20GSOO2MbJOM5T86dQO9v4Jy+oo1usndkvn+4WLuWF87sfvS0UMA==",
+      "version": "2.36.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/eclwatch/-/eclwatch-2.36.0.tgz",
+      "integrity": "sha512-oMbBVfyBb3HKd615lMu7Gx0fI2KoTfZeolFZkxiC/S5M7wCEbd2Epo5+yRpHgu9HUbdrmjmQDoayz8v18K+6xg==",
       "requires": {
-        "@hpcc-js/codemirror": "^2.39.0",
+        "@hpcc-js/codemirror": "^2.40.0",
         "@hpcc-js/common": "^2.48.0",
-        "@hpcc-js/comms": "^2.40.0",
-        "@hpcc-js/dgrid": "^2.8.43",
-        "@hpcc-js/graph": "^2.53.0",
-        "@hpcc-js/layout": "^2.25.0",
-        "@hpcc-js/phosphor": "^2.14.38",
-        "@hpcc-js/timeline": "^2.27.0",
+        "@hpcc-js/comms": "^2.41.0",
+        "@hpcc-js/dgrid": "^2.9.0",
+        "@hpcc-js/graph": "^2.54.0",
+        "@hpcc-js/layout": "^2.26.0",
+        "@hpcc-js/phosphor": "^2.14.39",
+        "@hpcc-js/timeline": "^2.28.0",
         "@hpcc-js/tree": "^2.21.0",
         "@hpcc-js/util": "^2.29.0"
-      },
-      "dependencies": {
-        "@hpcc-js/api": {
-          "version": "2.8.43",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/api/-/api-2.8.43.tgz",
-          "integrity": "sha512-UDiN19j0d2zEQRsQH8T7swoEuy2byY+b8TpoNMA5BFzxcqe9fzZ72iZA98T2Fi/mMVhdLxoqJwAYkwx+nPdVkA==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0"
-          }
-        },
-        "@hpcc-js/codemirror": {
-          "version": "2.39.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/codemirror/-/codemirror-2.39.0.tgz",
-          "integrity": "sha512-LVo1Z9PVnceU2lJ0zSjAOB3SCD36ulhmRn6Uw+irHKk23WkUHMYb4/oZoE+hHs94yAK5sP69GA2h5Kp75bo92Q==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0"
-          }
-        },
-        "@hpcc-js/common": {
-          "version": "2.48.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/common/-/common-2.48.0.tgz",
-          "integrity": "sha512-RtM7genqXIkEm8Z2kLIa+UCGTYqYiWoldALqX9Hk3Z2b7lNTtuZKx/DRcwaPhkI7SOuVA50ou1agbsBuFeOCvg==",
-          "requires": {
-            "@hpcc-js/util": "^2.29.0",
-            "@types/d3-array": "1.2.6",
-            "@types/d3-brush": "1.0.10",
-            "@types/d3-collection": "1.0.8",
-            "@types/d3-color": "1.2.2",
-            "@types/d3-dispatch": "1.0.7",
-            "@types/d3-drag": "1.2.3",
-            "@types/d3-dsv": "1.0.36",
-            "@types/d3-ease": "1.0.8",
-            "@types/d3-format": "1.3.1",
-            "@types/d3-interpolate": "1.3.1",
-            "@types/d3-scale": "1.0.14",
-            "@types/d3-selection": "1.4.1",
-            "@types/d3-time-format": "2.1.1",
-            "@types/d3-transition": "1.1.4",
-            "@types/d3-zoom": "1.7.4"
-          }
-        },
-        "@hpcc-js/dgrid": {
-          "version": "2.8.43",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/dgrid/-/dgrid-2.8.43.tgz",
-          "integrity": "sha512-HmdEQ0wDtS4eYzNZ+W4YwK4DajGMZKDpvqxdVORiYK9cW//PLe8NpzyzWSFFZcdBkVnHF6rto9shdWL9VCHWDg==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/ddl-shim": "^2.17.15",
-            "@hpcc-js/dgrid-shim": "^2.11.22",
-            "@hpcc-js/util": "^2.29.0"
-          }
-        },
-        "@hpcc-js/layout": {
-          "version": "2.25.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/layout/-/layout-2.25.0.tgz",
-          "integrity": "sha512-Ww159jvN/92n7jt793JEtgDumE7MzEArJmfkJFXxeGuaLfOXbwS549AZk/Q1y4LS8QUpSMF5k2m0WidriTVpXg==",
-          "requires": {
-            "@hpcc-js/api": "^2.8.43",
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/dgrid": "^2.8.43"
-          }
-        },
-        "@hpcc-js/other": {
-          "version": "2.13.58",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/other/-/other-2.13.58.tgz",
-          "integrity": "sha512-iwRxmd+htGfMzH60QZWsJxVsaUHlu6mWrxBKrBwbe86TJn9afG/Jy+CILpguYtz5ZnUb/D0yJLsnjbEpUEMGmw==",
-          "requires": {
-            "@hpcc-js/api": "^2.8.43",
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/layout": "^2.25.0"
-          }
-        },
-        "@hpcc-js/phosphor": {
-          "version": "2.14.38",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/phosphor/-/phosphor-2.14.38.tgz",
-          "integrity": "sha512-/NTlVTNgSOe2AMu1MvrDkuTTZB57WQAGvW7OEcTBlpfyuFrsonQYn1eBcObr3jbRzvi4tTCLXh3bcQNvA3cZmg==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/other": "^2.13.58",
-            "@hpcc-js/phosphor-shim": "^2.11.17",
-            "@hpcc-js/util": "^2.29.0"
-          }
-        },
-        "@hpcc-js/tree": {
-          "version": "2.21.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/tree/-/tree-2.21.0.tgz",
-          "integrity": "sha512-ihPUvAUIzroK8iOM2yuKCsTzKwBdpz5NK2XrFp/0vSom6lOG+oqOYBTdgvLeMdZYRd5AnEMUVi6R/Tlgfs9qcA==",
-          "requires": {
-            "@hpcc-js/api": "^2.8.43",
-            "@hpcc-js/common": "^2.48.0"
-          }
-        }
       }
     },
     "@hpcc-js/graph": {
-      "version": "2.53.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/graph/-/graph-2.53.0.tgz",
-      "integrity": "sha512-oEIn2pOJIib0J0Hxnx2so1bsYDL6XgKt35nfBXebQLGze8QqrBoqhL5TSwyMEC3FCXvne95+pMHICT/RseiWMw==",
+      "version": "2.54.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/graph/-/graph-2.54.0.tgz",
+      "integrity": "sha512-zbMlU8t1aqg9A5SW+mRh1HVs486LXXkBgBqPR2RwYl3n1HdQ7XtaSlxy0atY2Wv42I5pZNCg/7vFsHURPICmvA==",
       "requires": {
         "@hpcc-js/api": "^2.8.43",
         "@hpcc-js/common": "^2.48.0",
         "@hpcc-js/html": "^2.23.0",
         "@hpcc-js/react": "^2.30.0",
         "@hpcc-js/util": "^2.29.0"
-      },
-      "dependencies": {
-        "@hpcc-js/api": {
-          "version": "2.8.43",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/api/-/api-2.8.43.tgz",
-          "integrity": "sha512-UDiN19j0d2zEQRsQH8T7swoEuy2byY+b8TpoNMA5BFzxcqe9fzZ72iZA98T2Fi/mMVhdLxoqJwAYkwx+nPdVkA==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0"
-          }
-        },
-        "@hpcc-js/common": {
-          "version": "2.48.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/common/-/common-2.48.0.tgz",
-          "integrity": "sha512-RtM7genqXIkEm8Z2kLIa+UCGTYqYiWoldALqX9Hk3Z2b7lNTtuZKx/DRcwaPhkI7SOuVA50ou1agbsBuFeOCvg==",
-          "requires": {
-            "@hpcc-js/util": "^2.29.0",
-            "@types/d3-array": "1.2.6",
-            "@types/d3-brush": "1.0.10",
-            "@types/d3-collection": "1.0.8",
-            "@types/d3-color": "1.2.2",
-            "@types/d3-dispatch": "1.0.7",
-            "@types/d3-drag": "1.2.3",
-            "@types/d3-dsv": "1.0.36",
-            "@types/d3-ease": "1.0.8",
-            "@types/d3-format": "1.3.1",
-            "@types/d3-interpolate": "1.3.1",
-            "@types/d3-scale": "1.0.14",
-            "@types/d3-selection": "1.4.1",
-            "@types/d3-time-format": "2.1.1",
-            "@types/d3-transition": "1.1.4",
-            "@types/d3-zoom": "1.7.4"
-          }
-        },
-        "@hpcc-js/html": {
-          "version": "2.23.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/html/-/html-2.23.0.tgz",
-          "integrity": "sha512-p6yoaCCD5zAYTMcf2kOr51r4YfkWGYqkyrQm+6Ig/eWToL+ItowpCYsx2ZYcpdTbnuYnJkno6QzfNRr++lRHng==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/preact-shim": "^2.13.13",
-            "@hpcc-js/util": "^2.29.0"
-          }
-        },
-        "@hpcc-js/react": {
-          "version": "2.30.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/react/-/react-2.30.0.tgz",
-          "integrity": "sha512-tF6MSgCMmvehDOV7XDFJVHzQsEDBtdeqVQSE90JICNean6N0X58Sc8G6NJ73LJmyk5Zfb8UKmIuR7O/PjuqUDg==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/preact-shim": "^2.13.13"
-          }
-        }
       }
     },
     "@hpcc-js/html": {
-      "version": "2.22.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/html/-/html-2.22.0.tgz",
-      "integrity": "sha512-6/rR4kCQnhDM1fH/voovaQsXJbIW/rZ3HBxgtxx4jZUkPFGIjN6VKJKOQnZYbwaTk1zYHdC0fp7gyEOiKkpMgQ==",
+      "version": "2.23.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/html/-/html-2.23.0.tgz",
+      "integrity": "sha512-p6yoaCCD5zAYTMcf2kOr51r4YfkWGYqkyrQm+6Ig/eWToL+ItowpCYsx2ZYcpdTbnuYnJkno6QzfNRr++lRHng==",
       "requires": {
-        "@hpcc-js/common": "^2.47.0",
+        "@hpcc-js/common": "^2.48.0",
         "@hpcc-js/preact-shim": "^2.13.13",
         "@hpcc-js/util": "^2.29.0"
       }
     },
     "@hpcc-js/layout": {
-      "version": "2.24.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/layout/-/layout-2.24.0.tgz",
-      "integrity": "sha512-EZlffC9LF8zu7v0HGQjGzBQXHxnolhp9blcaKR35CAgvp2lf2RnZHCA2CgWnLTo4AXmLtplHMcvjr28OAnyXfQ==",
+      "version": "2.26.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/layout/-/layout-2.26.0.tgz",
+      "integrity": "sha512-jZEE6IbwU3BLhJwz0feaZ71aIbcCXwkP1yHGP71wf4MmYVno84FKI6ecNtzEStr/QJRevbiMkZw0WvvQ7I5Z+A==",
       "requires": {
-        "@hpcc-js/api": "^2.8.42",
-        "@hpcc-js/common": "^2.47.0",
-        "@hpcc-js/dgrid": "^2.8.42"
+        "@hpcc-js/api": "^2.8.43",
+        "@hpcc-js/common": "^2.48.0",
+        "@hpcc-js/dgrid": "^2.9.0"
       }
     },
     "@hpcc-js/leaflet-shim": {
@@ -750,100 +988,36 @@
       }
     },
     "@hpcc-js/map": {
-      "version": "2.45.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/map/-/map-2.45.0.tgz",
-      "integrity": "sha512-Eq8quS/OhmmbEk1K3u7me0hTGTyEIN7StJFDILuB7PpACTPzyvNAERCIs9mfKPahyfSmbzQlLupBOvR/ipXHtQ==",
+      "version": "2.47.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/map/-/map-2.47.0.tgz",
+      "integrity": "sha512-uQbsyrgdquAi+cjrukECsjOqu0XqUbm2tQ0SXX1NwoJ9JXH661ZIh7p72WxfxA0anJkIOZOC4aJj54Ozhbmvyw==",
       "requires": {
         "@hpcc-js/api": "^2.8.43",
         "@hpcc-js/common": "^2.48.0",
-        "@hpcc-js/graph": "^2.53.0",
-        "@hpcc-js/layout": "^2.25.0",
+        "@hpcc-js/graph": "^2.54.0",
+        "@hpcc-js/layout": "^2.26.0",
         "@hpcc-js/leaflet-shim": "^2.1.14",
-        "@hpcc-js/other": "^2.13.58",
+        "@hpcc-js/other": "^2.13.59",
         "@hpcc-js/util": "^2.29.0"
-      },
-      "dependencies": {
-        "@hpcc-js/api": {
-          "version": "2.8.43",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/api/-/api-2.8.43.tgz",
-          "integrity": "sha512-UDiN19j0d2zEQRsQH8T7swoEuy2byY+b8TpoNMA5BFzxcqe9fzZ72iZA98T2Fi/mMVhdLxoqJwAYkwx+nPdVkA==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0"
-          }
-        },
-        "@hpcc-js/common": {
-          "version": "2.48.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/common/-/common-2.48.0.tgz",
-          "integrity": "sha512-RtM7genqXIkEm8Z2kLIa+UCGTYqYiWoldALqX9Hk3Z2b7lNTtuZKx/DRcwaPhkI7SOuVA50ou1agbsBuFeOCvg==",
-          "requires": {
-            "@hpcc-js/util": "^2.29.0",
-            "@types/d3-array": "1.2.6",
-            "@types/d3-brush": "1.0.10",
-            "@types/d3-collection": "1.0.8",
-            "@types/d3-color": "1.2.2",
-            "@types/d3-dispatch": "1.0.7",
-            "@types/d3-drag": "1.2.3",
-            "@types/d3-dsv": "1.0.36",
-            "@types/d3-ease": "1.0.8",
-            "@types/d3-format": "1.3.1",
-            "@types/d3-interpolate": "1.3.1",
-            "@types/d3-scale": "1.0.14",
-            "@types/d3-selection": "1.4.1",
-            "@types/d3-time-format": "2.1.1",
-            "@types/d3-transition": "1.1.4",
-            "@types/d3-zoom": "1.7.4"
-          }
-        },
-        "@hpcc-js/dgrid": {
-          "version": "2.8.43",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/dgrid/-/dgrid-2.8.43.tgz",
-          "integrity": "sha512-HmdEQ0wDtS4eYzNZ+W4YwK4DajGMZKDpvqxdVORiYK9cW//PLe8NpzyzWSFFZcdBkVnHF6rto9shdWL9VCHWDg==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/ddl-shim": "^2.17.15",
-            "@hpcc-js/dgrid-shim": "^2.11.22",
-            "@hpcc-js/util": "^2.29.0"
-          }
-        },
-        "@hpcc-js/layout": {
-          "version": "2.25.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/layout/-/layout-2.25.0.tgz",
-          "integrity": "sha512-Ww159jvN/92n7jt793JEtgDumE7MzEArJmfkJFXxeGuaLfOXbwS549AZk/Q1y4LS8QUpSMF5k2m0WidriTVpXg==",
-          "requires": {
-            "@hpcc-js/api": "^2.8.43",
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/dgrid": "^2.8.43"
-          }
-        },
-        "@hpcc-js/other": {
-          "version": "2.13.58",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/other/-/other-2.13.58.tgz",
-          "integrity": "sha512-iwRxmd+htGfMzH60QZWsJxVsaUHlu6mWrxBKrBwbe86TJn9afG/Jy+CILpguYtz5ZnUb/D0yJLsnjbEpUEMGmw==",
-          "requires": {
-            "@hpcc-js/api": "^2.8.43",
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/layout": "^2.25.0"
-          }
-        }
       }
     },
     "@hpcc-js/other": {
-      "version": "2.13.57",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/other/-/other-2.13.57.tgz",
-      "integrity": "sha512-dG02Hxo9aJn6WNvMGvSeunzqeZBj97Sa93RASrimn3/MNrB6sihHM/O3nupsv3I+W1BrBXaEq1z+6L2zWTq9qA==",
+      "version": "2.13.59",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/other/-/other-2.13.59.tgz",
+      "integrity": "sha512-wvadhIT86ip3AP4vBBQF+9aBMyrJ6nghZyLt+wrBf6GO8RKHzRCCh/g1r5WHPCgFZjmo79cox+PxR13zQ3yr6g==",
       "requires": {
-        "@hpcc-js/api": "^2.8.42",
-        "@hpcc-js/common": "^2.47.0",
-        "@hpcc-js/layout": "^2.24.0"
+        "@hpcc-js/api": "^2.8.43",
+        "@hpcc-js/common": "^2.48.0",
+        "@hpcc-js/layout": "^2.26.0"
       }
     },
     "@hpcc-js/phosphor": {
-      "version": "2.14.37",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/phosphor/-/phosphor-2.14.37.tgz",
-      "integrity": "sha512-ERjbRPZF5GfUBPoQrKXmar4sA6gdt11BjyOVBnEPHiCNoHCdzg+lgAWtrwR9JcPXtsDvvnrHhLjtElIxA3CDag==",
+      "version": "2.14.39",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/phosphor/-/phosphor-2.14.39.tgz",
+      "integrity": "sha512-evSYxPHi9j+WYp12oRrjKaQvhCWmFOhPmhiARKGIsueq+PYgXtQH1uPN3oaFOW0Poh2vE2tWNVVE/oFFv36+9Q==",
       "requires": {
-        "@hpcc-js/common": "^2.47.0",
-        "@hpcc-js/other": "^2.13.57",
+        "@hpcc-js/common": "^2.48.0",
+        "@hpcc-js/other": "^2.13.59",
         "@hpcc-js/phosphor-shim": "^2.11.17",
         "@hpcc-js/util": "^2.29.0"
       }
@@ -868,117 +1042,34 @@
       }
     },
     "@hpcc-js/react": {
-      "version": "2.29.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/react/-/react-2.29.0.tgz",
-      "integrity": "sha512-FJGsckr5YBV1ru6t1WOd9snBSjrAKULdg60OiXaFMo/HqrbAUVj66m/u/RTIHDwDjBuwnwEmEJBh0XLQgfdZdw==",
+      "version": "2.30.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/react/-/react-2.30.0.tgz",
+      "integrity": "sha512-tF6MSgCMmvehDOV7XDFJVHzQsEDBtdeqVQSE90JICNean6N0X58Sc8G6NJ73LJmyk5Zfb8UKmIuR7O/PjuqUDg==",
       "requires": {
-        "@hpcc-js/common": "^2.47.0",
+        "@hpcc-js/common": "^2.48.0",
         "@hpcc-js/preact-shim": "^2.13.13"
       }
     },
     "@hpcc-js/timeline": {
-      "version": "2.27.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/timeline/-/timeline-2.27.0.tgz",
-      "integrity": "sha512-C/j4XCyJdgqXfsM268shdtObLK9li06MIF6xZu1ozD/VlAx0ImAz6zfOVZe73oqVRbxlfL2qpi+rehcMfU/ssw==",
+      "version": "2.28.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/timeline/-/timeline-2.28.0.tgz",
+      "integrity": "sha512-OIAIYXrA4r1vGtmPzs/Vr2y7Ks5+SAZqja5UgQ3zDrH0BlMLWzIBvf8qyDGIvFWM0IB/SDZVdAE/mzIv01YaNQ==",
       "requires": {
         "@hpcc-js/api": "^2.8.43",
         "@hpcc-js/chart": "^2.58.0",
         "@hpcc-js/common": "^2.48.0",
         "@hpcc-js/html": "^2.23.0",
-        "@hpcc-js/layout": "^2.25.0",
+        "@hpcc-js/layout": "^2.26.0",
         "@hpcc-js/react": "^2.30.0"
-      },
-      "dependencies": {
-        "@hpcc-js/api": {
-          "version": "2.8.43",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/api/-/api-2.8.43.tgz",
-          "integrity": "sha512-UDiN19j0d2zEQRsQH8T7swoEuy2byY+b8TpoNMA5BFzxcqe9fzZ72iZA98T2Fi/mMVhdLxoqJwAYkwx+nPdVkA==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0"
-          }
-        },
-        "@hpcc-js/chart": {
-          "version": "2.58.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/chart/-/chart-2.58.0.tgz",
-          "integrity": "sha512-VYKRbqX49lHrW0e/RXcGDJV50YvwgPWJHj40vT4tiF1lgJr+exXLRj/RbFrBj0PLINIcUCRa1ClDI6iOnS10aQ==",
-          "requires": {
-            "@hpcc-js/api": "^2.8.43",
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/util": "^2.29.0"
-          }
-        },
-        "@hpcc-js/common": {
-          "version": "2.48.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/common/-/common-2.48.0.tgz",
-          "integrity": "sha512-RtM7genqXIkEm8Z2kLIa+UCGTYqYiWoldALqX9Hk3Z2b7lNTtuZKx/DRcwaPhkI7SOuVA50ou1agbsBuFeOCvg==",
-          "requires": {
-            "@hpcc-js/util": "^2.29.0",
-            "@types/d3-array": "1.2.6",
-            "@types/d3-brush": "1.0.10",
-            "@types/d3-collection": "1.0.8",
-            "@types/d3-color": "1.2.2",
-            "@types/d3-dispatch": "1.0.7",
-            "@types/d3-drag": "1.2.3",
-            "@types/d3-dsv": "1.0.36",
-            "@types/d3-ease": "1.0.8",
-            "@types/d3-format": "1.3.1",
-            "@types/d3-interpolate": "1.3.1",
-            "@types/d3-scale": "1.0.14",
-            "@types/d3-selection": "1.4.1",
-            "@types/d3-time-format": "2.1.1",
-            "@types/d3-transition": "1.1.4",
-            "@types/d3-zoom": "1.7.4"
-          }
-        },
-        "@hpcc-js/dgrid": {
-          "version": "2.8.43",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/dgrid/-/dgrid-2.8.43.tgz",
-          "integrity": "sha512-HmdEQ0wDtS4eYzNZ+W4YwK4DajGMZKDpvqxdVORiYK9cW//PLe8NpzyzWSFFZcdBkVnHF6rto9shdWL9VCHWDg==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/ddl-shim": "^2.17.15",
-            "@hpcc-js/dgrid-shim": "^2.11.22",
-            "@hpcc-js/util": "^2.29.0"
-          }
-        },
-        "@hpcc-js/html": {
-          "version": "2.23.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/html/-/html-2.23.0.tgz",
-          "integrity": "sha512-p6yoaCCD5zAYTMcf2kOr51r4YfkWGYqkyrQm+6Ig/eWToL+ItowpCYsx2ZYcpdTbnuYnJkno6QzfNRr++lRHng==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/preact-shim": "^2.13.13",
-            "@hpcc-js/util": "^2.29.0"
-          }
-        },
-        "@hpcc-js/layout": {
-          "version": "2.25.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/layout/-/layout-2.25.0.tgz",
-          "integrity": "sha512-Ww159jvN/92n7jt793JEtgDumE7MzEArJmfkJFXxeGuaLfOXbwS549AZk/Q1y4LS8QUpSMF5k2m0WidriTVpXg==",
-          "requires": {
-            "@hpcc-js/api": "^2.8.43",
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/dgrid": "^2.8.43"
-          }
-        },
-        "@hpcc-js/react": {
-          "version": "2.30.0",
-          "resolved": "https://registry.npmjs.org/@hpcc-js/react/-/react-2.30.0.tgz",
-          "integrity": "sha512-tF6MSgCMmvehDOV7XDFJVHzQsEDBtdeqVQSE90JICNean6N0X58Sc8G6NJ73LJmyk5Zfb8UKmIuR7O/PjuqUDg==",
-          "requires": {
-            "@hpcc-js/common": "^2.48.0",
-            "@hpcc-js/preact-shim": "^2.13.13"
-          }
-        }
       }
     },
     "@hpcc-js/tree": {
-      "version": "2.20.0",
-      "resolved": "https://registry.npmjs.org/@hpcc-js/tree/-/tree-2.20.0.tgz",
-      "integrity": "sha512-1sVmgS/GyQj2oAqBkayEdSR8XI+FeGxROtmsLTNCWC0XGqiyr0p3Sm447roFKEnfmCSeSCupFWs0R7RTBD+M+Q==",
+      "version": "2.21.0",
+      "resolved": "https://registry.npmjs.org/@hpcc-js/tree/-/tree-2.21.0.tgz",
+      "integrity": "sha512-ihPUvAUIzroK8iOM2yuKCsTzKwBdpz5NK2XrFp/0vSom6lOG+oqOYBTdgvLeMdZYRd5AnEMUVi6R/Tlgfs9qcA==",
       "requires": {
-        "@hpcc-js/api": "^2.8.42",
-        "@hpcc-js/common": "^2.47.0"
+        "@hpcc-js/api": "^2.8.43",
+        "@hpcc-js/common": "^2.48.0"
       }
     },
     "@hpcc-js/util": {
@@ -1006,14 +1097,14 @@
       }
     },
     "@material-ui/core": {
-      "version": "4.11.3",
-      "resolved": "https://registry.npmjs.org/@material-ui/core/-/core-4.11.3.tgz",
-      "integrity": "sha512-Adt40rGW6Uds+cAyk3pVgcErpzU/qxc7KBR94jFHBYretU4AtWZltYcNsbeMn9tXL86jjVL1kuGcIHsgLgFGRw==",
+      "version": "4.11.4",
+      "resolved": "https://registry.npmjs.org/@material-ui/core/-/core-4.11.4.tgz",
+      "integrity": "sha512-oqb+lJ2Dl9HXI9orc6/aN8ZIAMkeThufA5iZELf2LQeBn2NtjVilF5D2w7e9RpntAzDb4jK5DsVhkfOvFY/8fg==",
       "requires": {
         "@babel/runtime": "^7.4.4",
-        "@material-ui/styles": "^4.11.3",
+        "@material-ui/styles": "^4.11.4",
         "@material-ui/system": "^4.11.3",
-        "@material-ui/types": "^5.1.0",
+        "@material-ui/types": "5.1.0",
         "@material-ui/utils": "^4.11.2",
         "@types/react-transition-group": "^4.2.0",
         "clsx": "^1.0.4",
@@ -1033,9 +1124,9 @@
       }
     },
     "@material-ui/lab": {
-      "version": "4.0.0-alpha.57",
-      "resolved": "https://registry.npmjs.org/@material-ui/lab/-/lab-4.0.0-alpha.57.tgz",
-      "integrity": "sha512-qo/IuIQOmEKtzmRD2E4Aa6DB4A87kmY6h0uYhjUmrrgmEAgbbw9etXpWPVXuRK6AGIQCjFzV6WO2i21m1R4FCw==",
+      "version": "4.0.0-alpha.58",
+      "resolved": "https://registry.npmjs.org/@material-ui/lab/-/lab-4.0.0-alpha.58.tgz",
+      "integrity": "sha512-GKHlJqLxUeHH3L3dGQ48ZavYrqGOTXkFkiEiuYMAnAvXAZP4rhMIqeHOPXSUQan4Bd8QnafDcpovOSLnadDmKw==",
       "requires": {
         "@babel/runtime": "^7.4.4",
         "@material-ui/utils": "^4.11.2",
@@ -1045,13 +1136,13 @@
       }
     },
     "@material-ui/styles": {
-      "version": "4.11.3",
-      "resolved": "https://registry.npmjs.org/@material-ui/styles/-/styles-4.11.3.tgz",
-      "integrity": "sha512-HzVzCG+PpgUGMUYEJ2rTEmQYeonGh41BYfILNFb/1ueqma+p1meSdu4RX6NjxYBMhf7k+jgfHFTTz+L1SXL/Zg==",
+      "version": "4.11.4",
+      "resolved": "https://registry.npmjs.org/@material-ui/styles/-/styles-4.11.4.tgz",
+      "integrity": "sha512-KNTIZcnj/zprG5LW0Sao7zw+yG3O35pviHzejMdcSGCdWbiO8qzRgOYL8JAxAsWBKOKYwVZxXtHWaB5T2Kvxew==",
       "requires": {
         "@babel/runtime": "^7.4.4",
         "@emotion/hash": "^0.8.0",
-        "@material-ui/types": "^5.1.0",
+        "@material-ui/types": "5.1.0",
         "@material-ui/utils": "^4.11.2",
         "clsx": "^1.0.4",
         "csstype": "^2.5.2",
@@ -1402,25 +1493,26 @@
       "integrity": "sha512-KfRL3PuHmqQLOG+2tGpRO26Ctg+Cq1E01D2DMriKEATHgWLfeNDmq9e29Q9WIky0dQ3NPkd1mzYH8Lm936Z9qw=="
     },
     "@types/react": {
-      "version": "16.14.4",
-      "resolved": "https://registry.npmjs.org/@types/react/-/react-16.14.4.tgz",
-      "integrity": "sha512-ETj7GbkPGjca/A4trkVeGvoIakmLV6ZtX3J8dcmOpzKzWVybbrOxanwaIPG71GZwImoMDY6Fq4wIe34lEqZ0FQ==",
+      "version": "16.14.6",
+      "resolved": "https://registry.npmjs.org/@types/react/-/react-16.14.6.tgz",
+      "integrity": "sha512-Ol/aFKune+P0FSFKIgf+XbhGzYGyz0p7g5befSt4rmbzfGLaZR0q7jPew9k7d3bvrcuaL8dPy9Oz3XGZmf9n+w==",
       "requires": {
         "@types/prop-types": "*",
+        "@types/scheduler": "*",
         "csstype": "^3.0.2"
       },
       "dependencies": {
         "csstype": {
-          "version": "3.0.6",
-          "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.0.6.tgz",
-          "integrity": "sha512-+ZAmfyWMT7TiIlzdqJgjMb7S4f1beorDbWbsocyK4RaiqA5RTX3K14bnBWmmA9QEM0gRdsjyyrEmcyga8Zsxmw=="
+          "version": "3.0.8",
+          "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.0.8.tgz",
+          "integrity": "sha512-jXKhWqXPmlUeoQnF/EhTtTl4C9SnrxSH/jZUih3jmO6lBKr99rP3/+FmrMj4EFpOXzMtXHAZkd3x0E6h6Fgflw=="
         }
       }
     },
     "@types/react-dom": {
-      "version": "16.9.11",
-      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-16.9.11.tgz",
-      "integrity": "sha512-3UuR4MoWf5spNgrG6cwsmT9DdRghcR4IDFOzNZ6+wcmacxkFykcb5ji0nNVm9ckBT4BCxvCrJJbM4+EYsEEVIg==",
+      "version": "16.9.12",
+      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-16.9.12.tgz",
+      "integrity": "sha512-i7NPZZpPte3jtVOoW+eLB7G/jsX5OM6GqQnH+lC0nq0rqwlK0x8WcMEvYDgFWqWhWMlTltTimzdMax6wYfZssA==",
       "dev": true,
       "requires": {
         "@types/react": "^16"
@@ -1434,6 +1526,11 @@
         "@types/react": "*"
       }
     },
+    "@types/scheduler": {
+      "version": "0.16.1",
+      "resolved": "https://registry.npmjs.org/@types/scheduler/-/scheduler-0.16.1.tgz",
+      "integrity": "sha512-EaCxbanVeyxDRTQBkdLb3Bvl/HK7PBK6UJjsSixB0iHKoWxE5uu2Q/DgtpOhPIojN0Zl1whvOd7PoHs2P0s5eA=="
+    },
     "@typescript-eslint/eslint-plugin": {
       "version": "3.10.1",
       "resolved": "https://registry.npmjs.org/@typescript-eslint/eslint-plugin/-/eslint-plugin-3.10.1.tgz",
@@ -1740,24 +1837,24 @@
       }
     },
     "@webpack-cli/configtest": {
-      "version": "1.0.1",
-      "resolved": "https://registry.npmjs.org/@webpack-cli/configtest/-/configtest-1.0.1.tgz",
-      "integrity": "sha512-B+4uBUYhpzDXmwuo3V9yBH6cISwxEI4J+NO5ggDaGEEHb0osY/R7MzeKc0bHURXQuZjMM4qD+bSJCKIuI3eNBQ==",
+      "version": "1.0.3",
+      "resolved": "https://registry.npmjs.org/@webpack-cli/configtest/-/configtest-1.0.3.tgz",
+      "integrity": "sha512-WQs0ep98FXX2XBAfQpRbY0Ma6ADw8JR6xoIkaIiJIzClGOMqVRvPCWqndTxf28DgFopWan0EKtHtg/5W1h0Zkw==",
       "dev": true
     },
     "@webpack-cli/info": {
-      "version": "1.2.2",
-      "resolved": "https://registry.npmjs.org/@webpack-cli/info/-/info-1.2.2.tgz",
-      "integrity": "sha512-5U9kUJHnwU+FhKH4PWGZuBC1hTEPYyxGSL5jjoBI96Gx8qcYJGOikpiIpFoTq8mmgX3im2zAo2wanv/alD74KQ==",
+      "version": "1.2.4",
+      "resolved": "https://registry.npmjs.org/@webpack-cli/info/-/info-1.2.4.tgz",
+      "integrity": "sha512-ogE2T4+pLhTTPS/8MM3IjHn0IYplKM4HbVNMCWA9N4NrdPzunwenpCsqKEXyejMfRu6K8mhauIPYf8ZxWG5O6g==",
       "dev": true,
       "requires": {
         "envinfo": "^7.7.3"
       }
     },
     "@webpack-cli/serve": {
-      "version": "1.3.0",
-      "resolved": "https://registry.npmjs.org/@webpack-cli/serve/-/serve-1.3.0.tgz",
-      "integrity": "sha512-k2p2VrONcYVX1wRRrf0f3X2VGltLWcv+JzXRBDmvCxGlCeESx4OXw91TsWeKOkp784uNoVQo313vxJFHXPPwfw==",
+      "version": "1.4.0",
+      "resolved": "https://registry.npmjs.org/@webpack-cli/serve/-/serve-1.4.0.tgz",
+      "integrity": "sha512-xgT/HqJ+uLWGX+Mzufusl3cgjAcnqYYskaB7o0vRcwOEfuu6hMzSILQpnIzFMGsTaeaX4Nnekl+6fadLbl1/Vg==",
       "dev": true
     },
     "@xtuc/ieee754": {
@@ -2813,9 +2910,9 @@
       "dev": true
     },
     "colorette": {
-      "version": "1.2.1",
-      "resolved": "https://registry.npmjs.org/colorette/-/colorette-1.2.1.tgz",
-      "integrity": "sha512-puCDz0CzydiSYOrnXpz/PKd69zRrribezjtE9yd4zvytoRc8+RY/KJPvtPFKZS3E3wP6neGyMe0vOTlHO5L3Pw==",
+      "version": "1.2.2",
+      "resolved": "https://registry.npmjs.org/colorette/-/colorette-1.2.2.tgz",
+      "integrity": "sha512-MKGMzyfeuutC/ZJ1cba9NqcNpfeqMUcYmyF1ZFY6/Cn7CNSAKx6a+s48sqLqyAiZuaP2TcqMhoo+dlwFnVxT9w==",
       "dev": true
     },
     "command-line-args": {
@@ -3216,9 +3313,9 @@
       "dev": true
     },
     "csstype": {
-      "version": "2.6.16",
-      "resolved": "https://registry.npmjs.org/csstype/-/csstype-2.6.16.tgz",
-      "integrity": "sha512-61FBWoDHp/gRtsoDkq/B1nWrCUG/ok1E3tUrcNbZjsE9Cxd9yzUirjS3+nAATB8U4cTtaQmAHbNndoFz5L6C9Q=="
+      "version": "2.6.17",
+      "resolved": "https://registry.npmjs.org/csstype/-/csstype-2.6.17.tgz",
+      "integrity": "sha512-u1wmTI1jJGzCJzWndZo8mk4wnPTZd1eOIYTYvuEyOQGfmDl3TrabCCfKnOC86FZwW/9djqTl933UF/cS425i9A=="
     },
     "cyclist": {
       "version": "1.0.1",
@@ -3646,18 +3743,18 @@
       }
     },
     "dom-helpers": {
-      "version": "5.2.0",
-      "resolved": "https://registry.npmjs.org/dom-helpers/-/dom-helpers-5.2.0.tgz",
-      "integrity": "sha512-Ru5o9+V8CpunKnz5LGgWXkmrH/20cGKwcHwS4m73zIvs54CN9epEmT/HLqFJW3kXpakAFkEdzgy1hzlJe3E4OQ==",
+      "version": "5.2.1",
+      "resolved": "https://registry.npmjs.org/dom-helpers/-/dom-helpers-5.2.1.tgz",
+      "integrity": "sha512-nRCa7CK3VTrM2NmGkIy4cbK7IZlgBE/PYMn55rrXefr5xXDP0LdtfPnblFDoVdcAfslJ7or6iqAUnx0CCGIWQA==",
       "requires": {
         "@babel/runtime": "^7.8.7",
         "csstype": "^3.0.2"
       },
       "dependencies": {
         "csstype": {
-          "version": "3.0.7",
-          "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.0.7.tgz",
-          "integrity": "sha512-KxnUB0ZMlnUWCsx2Z8MUsr6qV6ja1w9ArPErJaJaF8a5SOWoHLIszeCTKGRGRgtLgYrs1E8CHkNSP1VZTTPc9g=="
+          "version": "3.0.8",
+          "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.0.8.tgz",
+          "integrity": "sha512-jXKhWqXPmlUeoQnF/EhTtTl4C9SnrxSH/jZUih3jmO6lBKr99rP3/+FmrMj4EFpOXzMtXHAZkd3x0E6h6Fgflw=="
         }
       }
     },
@@ -3759,9 +3856,9 @@
       }
     },
     "envinfo": {
-      "version": "7.7.4",
-      "resolved": "https://registry.npmjs.org/envinfo/-/envinfo-7.7.4.tgz",
-      "integrity": "sha512-TQXTYFVVwwluWSFis6K2XKxgrD22jEv0FTuLCQI+OjH7rn93+iY0fSSFM5lrSxFY+H1+B0/cvvlamr3UsBivdQ==",
+      "version": "7.8.1",
+      "resolved": "https://registry.npmjs.org/envinfo/-/envinfo-7.8.1.tgz",
+      "integrity": "sha512-/o+BXHmB7ocbHEAs6F2EnG0ogybVVUdkRunTT2glZU9XAaGmhqskrvKwqXuDfNjEO0LZKWdejEEpnq8aM0tOaw==",
       "dev": true
     },
     "errno": {
@@ -3831,13 +3928,13 @@
       "dev": true
     },
     "eslint": {
-      "version": "7.21.0",
-      "resolved": "https://registry.npmjs.org/eslint/-/eslint-7.21.0.tgz",
-      "integrity": "sha512-W2aJbXpMNofUp0ztQaF40fveSsJBjlSCSWpy//gzfTvwC+USs/nceBrKmlJOiM8r1bLwP2EuYkCqArn/6QTIgg==",
+      "version": "7.26.0",
+      "resolved": "https://registry.npmjs.org/eslint/-/eslint-7.26.0.tgz",
+      "integrity": "sha512-4R1ieRf52/izcZE7AlLy56uIHHDLT74Yzz2Iv2l6kDaYvEu9x+wMB5dZArVL8SYGXSYV2YAg70FcW5Y5nGGNIg==",
       "dev": true,
       "requires": {
         "@babel/code-frame": "7.12.11",
-        "@eslint/eslintrc": "^0.4.0",
+        "@eslint/eslintrc": "^0.4.1",
         "ajv": "^6.10.0",
         "chalk": "^4.0.0",
         "cross-spawn": "^7.0.2",
@@ -3853,7 +3950,7 @@
         "file-entry-cache": "^6.0.1",
         "functional-red-black-tree": "^1.0.1",
         "glob-parent": "^5.0.0",
-        "globals": "^12.1.0",
+        "globals": "^13.6.0",
         "ignore": "^4.0.6",
         "import-fresh": "^3.0.0",
         "imurmurhash": "^0.1.4",
@@ -3861,7 +3958,7 @@
         "js-yaml": "^3.13.1",
         "json-stable-stringify-without-jsonify": "^1.0.1",
         "levn": "^0.4.1",
-        "lodash": "^4.17.20",
+        "lodash": "^4.17.21",
         "minimatch": "^3.0.4",
         "natural-compare": "^1.4.0",
         "optionator": "^0.9.1",
@@ -3885,9 +3982,9 @@
           }
         },
         "chalk": {
-          "version": "4.1.0",
-          "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.0.tgz",
-          "integrity": "sha512-qwx12AxXe2Q5xQ43Ac//I6v5aXTipYrSESdOgzrN+9XjgEpyjpKuvSGaN4qE93f7TQTlerQQ8S+EQ0EyDoVL1A==",
+          "version": "4.1.1",
+          "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.1.tgz",
+          "integrity": "sha512-diHzdDKxcU+bAsUboHLPEDQiw0qEe0qd7SYUn3HgcFlWgbDcfLGswOHYeGrHKzG9z6UYf01d9VFMfZxPM1xZSg==",
           "dev": true,
           "requires": {
             "ansi-styles": "^4.1.0",
@@ -3910,15 +4007,15 @@
           "dev": true
         },
         "eslint-visitor-keys": {
-          "version": "2.0.0",
-          "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-2.0.0.tgz",
-          "integrity": "sha512-QudtT6av5WXels9WjIM7qz1XD1cWGvX4gGXvp/zBn9nXG02D0utdU3Em2m/QjTnrsk6bBjmCygl3rmj118msQQ==",
+          "version": "2.1.0",
+          "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-2.1.0.tgz",
+          "integrity": "sha512-0rSmRBzXgDzIsD6mGdJgevzgezI534Cer5L/vyMX0kHzT/jiB43jRhd9YUlMGYLQy2zprNmoT8qasCGtY+QaKw==",
           "dev": true
         },
         "glob-parent": {
-          "version": "5.1.1",
-          "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.1.tgz",
-          "integrity": "sha512-FnI+VGOpnlGHWZxthPGR+QhR78fuiK0sNLkHQv+bL9fQi57lNNdquIbna/WrfROrolq8GK5Ek6BiMwqL/voRYQ==",
+          "version": "5.1.2",
+          "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
+          "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
           "dev": true,
           "requires": {
             "is-glob": "^4.0.1"
@@ -4563,9 +4660,9 @@
       "integrity": "sha512-2MSPMu7S1iOTL+BOa6K1S62hB2zUAYNF/lV0gSVlOaacd087lc6nR1H1r0e3B1CerTo+RceOmi1iJW+vp21xcQ=="
     },
     "get-stream": {
-      "version": "6.0.0",
-      "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-6.0.0.tgz",
-      "integrity": "sha512-A1B3Bh1UmL0bidM/YX2NsCOTnGJePL9rO/M+Mw3m9f2gUpfokS0hi5Eah0WSUEWZdZhIZtMjkIYS7mDfOqNHbg==",
+      "version": "6.0.1",
+      "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-6.0.1.tgz",
+      "integrity": "sha512-ts6Wi+2j3jQjqi70w5AlN8DFnkSwC+MqmxEzdEALB2qXZYV3X/b1CTfgPLGJNMeAWxdPfU8FO1ms3NUfaHCPYg==",
       "dev": true
     },
     "get-value": {
@@ -4651,12 +4748,20 @@
       }
     },
     "globals": {
-      "version": "12.4.0",
-      "resolved": "https://registry.npmjs.org/globals/-/globals-12.4.0.tgz",
-      "integrity": "sha512-BWICuzzDvDoH54NHKCseDanAhE3CeDorgDL5MT6LMXXj2WCnd9UC2szdk4AWLfjdgNBCXLUanXYcpBBKOSWGwg==",
+      "version": "13.8.0",
+      "resolved": "https://registry.npmjs.org/globals/-/globals-13.8.0.tgz",
+      "integrity": "sha512-rHtdA6+PDBIjeEvA91rpqzEvk/k3/i7EeNQiryiWuJH0Hw9cpyJMAt2jtbAwUaRdhD+573X4vWw6IcjKPasi9Q==",
       "dev": true,
       "requires": {
-        "type-fest": "^0.8.1"
+        "type-fest": "^0.20.2"
+      },
+      "dependencies": {
+        "type-fest": {
+          "version": "0.20.2",
+          "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.20.2.tgz",
+          "integrity": "sha512-Ne+eE4r0/iWnpAxD852z3A+N0Bt5RN//NjJwRd2VFHEmrywxf5vsZlh4R6lixl6B+wz/8d+maTSAkN1FIkI3LQ==",
+          "dev": true
+        }
       }
     },
     "globby": {
@@ -4841,9 +4946,9 @@
       }
     },
     "hosted-git-info": {
-      "version": "2.8.8",
-      "resolved": "https://registry.npmjs.org/hosted-git-info/-/hosted-git-info-2.8.8.tgz",
-      "integrity": "sha512-f/wzC2QaWBs7t9IYqB4T3sR1xviIViXJRJTWBlx2Gf3g0Xi5vI7Yy4koXQ1c9OYDGHN9sBy1DQ2AB8fqZBWhUg==",
+      "version": "2.8.9",
+      "resolved": "https://registry.npmjs.org/hosted-git-info/-/hosted-git-info-2.8.9.tgz",
+      "integrity": "sha512-mxIDAb9Lsm6DoOJ7xH+5+X4y1LU/4Hi50L9C5sIswK3JzULS4bwk1FvjdBgvYR4bzT4tuUQiC15FE2f5HbLvYw==",
       "dev": true
     },
     "hpack.js": {
@@ -5804,9 +5909,9 @@
       "dev": true
     },
     "jss": {
-      "version": "10.5.1",
-      "resolved": "https://registry.npmjs.org/jss/-/jss-10.5.1.tgz",
-      "integrity": "sha512-hbbO3+FOTqVdd7ZUoTiwpHzKXIo5vGpMNbuXH1a0wubRSWLWSBvwvaq4CiHH/U42CmjOnp6lVNNs/l+Z7ZdDmg==",
+      "version": "10.6.0",
+      "resolved": "https://registry.npmjs.org/jss/-/jss-10.6.0.tgz",
+      "integrity": "sha512-n7SHdCozmxnzYGXBHe0NsO0eUf9TvsHVq2MXvi4JmTn3x5raynodDVE/9VQmBdWFyyj9HpHZ2B4xNZ7MMy7lkw==",
       "requires": {
         "@babel/runtime": "^7.3.1",
         "csstype": "^3.0.2",
@@ -5816,77 +5921,77 @@
       },
       "dependencies": {
         "csstype": {
-          "version": "3.0.7",
-          "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.0.7.tgz",
-          "integrity": "sha512-KxnUB0ZMlnUWCsx2Z8MUsr6qV6ja1w9ArPErJaJaF8a5SOWoHLIszeCTKGRGRgtLgYrs1E8CHkNSP1VZTTPc9g=="
+          "version": "3.0.8",
+          "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.0.8.tgz",
+          "integrity": "sha512-jXKhWqXPmlUeoQnF/EhTtTl4C9SnrxSH/jZUih3jmO6lBKr99rP3/+FmrMj4EFpOXzMtXHAZkd3x0E6h6Fgflw=="
         }
       }
     },
     "jss-plugin-camel-case": {
-      "version": "10.5.1",
-      "resolved": "https://registry.npmjs.org/jss-plugin-camel-case/-/jss-plugin-camel-case-10.5.1.tgz",
-      "integrity": "sha512-9+oymA7wPtswm+zxVti1qiowC5q7bRdCJNORtns2JUj/QHp2QPXYwSNRD8+D2Cy3/CEMtdJzlNnt5aXmpS6NAg==",
+      "version": "10.6.0",
+      "resolved": "https://registry.npmjs.org/jss-plugin-camel-case/-/jss-plugin-camel-case-10.6.0.tgz",
+      "integrity": "sha512-JdLpA3aI/npwj3nDMKk308pvnhoSzkW3PXlbgHAzfx0yHWnPPVUjPhXFtLJzgKZge8lsfkUxvYSQ3X2OYIFU6A==",
       "requires": {
         "@babel/runtime": "^7.3.1",
         "hyphenate-style-name": "^1.0.3",
-        "jss": "10.5.1"
+        "jss": "10.6.0"
       }
     },
     "jss-plugin-default-unit": {
-      "version": "10.5.1",
-      "resolved": "https://registry.npmjs.org/jss-plugin-default-unit/-/jss-plugin-default-unit-10.5.1.tgz",
-      "integrity": "sha512-D48hJBc9Tj3PusvlillHW8Fz0y/QqA7MNmTYDQaSB/7mTrCZjt7AVRROExoOHEtd2qIYKOYJW3Jc2agnvsXRlQ==",
+      "version": "10.6.0",
+      "resolved": "https://registry.npmjs.org/jss-plugin-default-unit/-/jss-plugin-default-unit-10.6.0.tgz",
+      "integrity": "sha512-7y4cAScMHAxvslBK2JRK37ES9UT0YfTIXWgzUWD5euvR+JR3q+o8sQKzBw7GmkQRfZijrRJKNTiSt1PBsLI9/w==",
       "requires": {
         "@babel/runtime": "^7.3.1",
-        "jss": "10.5.1"
+        "jss": "10.6.0"
       }
     },
     "jss-plugin-global": {
-      "version": "10.5.1",
-      "resolved": "https://registry.npmjs.org/jss-plugin-global/-/jss-plugin-global-10.5.1.tgz",
-      "integrity": "sha512-jX4XpNgoaB8yPWw/gA1aPXJEoX0LNpvsROPvxlnYe+SE0JOhuvF7mA6dCkgpXBxfTWKJsno7cDSCgzHTocRjCQ==",
+      "version": "10.6.0",
+      "resolved": "https://registry.npmjs.org/jss-plugin-global/-/jss-plugin-global-10.6.0.tgz",
+      "integrity": "sha512-I3w7ji/UXPi3VuWrTCbHG9rVCgB4yoBQLehGDTmsnDfXQb3r1l3WIdcO8JFp9m0YMmyy2CU7UOV6oPI7/Tmu+w==",
       "requires": {
         "@babel/runtime": "^7.3.1",
-        "jss": "10.5.1"
+        "jss": "10.6.0"
       }
     },
     "jss-plugin-nested": {
-      "version": "10.5.1",
-      "resolved": "https://registry.npmjs.org/jss-plugin-nested/-/jss-plugin-nested-10.5.1.tgz",
-      "integrity": "sha512-xXkWKOCljuwHNjSYcXrCxBnjd8eJp90KVFW1rlhvKKRXnEKVD6vdKXYezk2a89uKAHckSvBvBoDGsfZrldWqqQ==",
+      "version": "10.6.0",
+      "resolved": "https://registry.npmjs.org/jss-plugin-nested/-/jss-plugin-nested-10.6.0.tgz",
+      "integrity": "sha512-fOFQWgd98H89E6aJSNkEh2fAXquC9aZcAVjSw4q4RoQ9gU++emg18encR4AT4OOIFl4lQwt5nEyBBRn9V1Rk8g==",
       "requires": {
         "@babel/runtime": "^7.3.1",
-        "jss": "10.5.1",
+        "jss": "10.6.0",
         "tiny-warning": "^1.0.2"
       }
     },
     "jss-plugin-props-sort": {
-      "version": "10.5.1",
-      "resolved": "https://registry.npmjs.org/jss-plugin-props-sort/-/jss-plugin-props-sort-10.5.1.tgz",
-      "integrity": "sha512-t+2vcevNmMg4U/jAuxlfjKt46D/jHzCPEjsjLRj/J56CvP7Iy03scsUP58Iw8mVnaV36xAUZH2CmAmAdo8994g==",
+      "version": "10.6.0",
+      "resolved": "https://registry.npmjs.org/jss-plugin-props-sort/-/jss-plugin-props-sort-10.6.0.tgz",
+      "integrity": "sha512-oMCe7hgho2FllNc60d9VAfdtMrZPo9n1Iu6RNa+3p9n0Bkvnv/XX5San8fTPujrTBScPqv9mOE0nWVvIaohNuw==",
       "requires": {
         "@babel/runtime": "^7.3.1",
-        "jss": "10.5.1"
+        "jss": "10.6.0"
       }
     },
     "jss-plugin-rule-value-function": {
-      "version": "10.5.1",
-      "resolved": "https://registry.npmjs.org/jss-plugin-rule-value-function/-/jss-plugin-rule-value-function-10.5.1.tgz",
-      "integrity": "sha512-3gjrSxsy4ka/lGQsTDY8oYYtkt2esBvQiceGBB4PykXxHoGRz14tbCK31Zc6DHEnIeqsjMUGbq+wEly5UViStQ==",
+      "version": "10.6.0",
+      "resolved": "https://registry.npmjs.org/jss-plugin-rule-value-function/-/jss-plugin-rule-value-function-10.6.0.tgz",
+      "integrity": "sha512-TKFqhRTDHN1QrPTMYRlIQUOC2FFQb271+AbnetURKlGvRl/eWLswcgHQajwuxI464uZk91sPiTtdGi7r7XaWfA==",
       "requires": {
         "@babel/runtime": "^7.3.1",
-        "jss": "10.5.1",
+        "jss": "10.6.0",
         "tiny-warning": "^1.0.2"
       }
     },
     "jss-plugin-vendor-prefixer": {
-      "version": "10.5.1",
-      "resolved": "https://registry.npmjs.org/jss-plugin-vendor-prefixer/-/jss-plugin-vendor-prefixer-10.5.1.tgz",
-      "integrity": "sha512-cLkH6RaPZWHa1TqSfd2vszNNgxT1W0omlSjAd6hCFHp3KIocSrW21gaHjlMU26JpTHwkc+tJTCQOmE/O1A4FKQ==",
+      "version": "10.6.0",
+      "resolved": "https://registry.npmjs.org/jss-plugin-vendor-prefixer/-/jss-plugin-vendor-prefixer-10.6.0.tgz",
+      "integrity": "sha512-doJ7MouBXT1lypLLctCwb4nJ6lDYqrTfVS3LtXgox42Xz0gXusXIIDboeh6UwnSmox90QpVnub7au8ybrb0krQ==",
       "requires": {
         "@babel/runtime": "^7.3.1",
         "css-vendor": "^2.0.8",
-        "jss": "10.5.1"
+        "jss": "10.6.0"
       }
     },
     "keygrip": {
@@ -6213,9 +6318,9 @@
       }
     },
     "lodash": {
-      "version": "4.17.20",
-      "resolved": "https://registry.npmjs.org/lodash/-/lodash-4.17.20.tgz",
-      "integrity": "sha512-PlhdFcillOINfeV7Ni6oF1TAEayyZBoZ8bcshTHqOYJYlrqzRK5hagpagky5o4HfCzzd1TRkXPMFq6cKk9rGmA=="
+      "version": "4.17.21",
+      "resolved": "https://registry.npmjs.org/lodash/-/lodash-4.17.21.tgz",
+      "integrity": "sha512-v2kDEe57lecTulaDIuNTPy3Ry4gLGJ6Z1O3vE1krgXZNrsQ+LFTGHVxVjcXPs17LhbZVGedAJv8XZ1tvj5FvSg=="
     },
     "lodash-es": {
       "version": "4.17.20",
@@ -6234,11 +6339,23 @@
       "integrity": "sha1-soqmKIorn8ZRA1x3EfZathkDMaY=",
       "dev": true
     },
+    "lodash.clonedeep": {
+      "version": "4.5.0",
+      "resolved": "https://registry.npmjs.org/lodash.clonedeep/-/lodash.clonedeep-4.5.0.tgz",
+      "integrity": "sha1-4j8/nE+Pvd6HJSnBBxhXoIblzO8=",
+      "dev": true
+    },
     "lodash.throttle": {
       "version": "4.1.1",
       "resolved": "https://registry.npmjs.org/lodash.throttle/-/lodash.throttle-4.1.1.tgz",
       "integrity": "sha1-wj6RtxAkKscMN/HhzaknTMOb8vQ="
     },
+    "lodash.truncate": {
+      "version": "4.4.2",
+      "resolved": "https://registry.npmjs.org/lodash.truncate/-/lodash.truncate-4.4.2.tgz",
+      "integrity": "sha1-WjUNoLERO4N+z//VgSy+WNbq4ZM=",
+      "dev": true
+    },
     "loglevel": {
       "version": "1.7.1",
       "resolved": "https://registry.npmjs.org/loglevel/-/loglevel-1.7.1.tgz",
@@ -9522,21 +9639,23 @@
       "integrity": "sha512-e900nM8RRtGhlV36KGEU9k65K3mPb1WV70OdjfxlG2EAuM1noi/E/BaW/uMhL7bPEssK8QV57vN3esixjUvcXQ=="
     },
     "table": {
-      "version": "6.0.7",
-      "resolved": "https://registry.npmjs.org/table/-/table-6.0.7.tgz",
-      "integrity": "sha512-rxZevLGTUzWna/qBLObOe16kB2RTnnbhciwgPbMMlazz1yZGVEgnZK762xyVdVznhqxrfCeBMmMkgOOaPwjH7g==",
+      "version": "6.7.0",
+      "resolved": "https://registry.npmjs.org/table/-/table-6.7.0.tgz",
+      "integrity": "sha512-SAM+5p6V99gYiiy2gT5ArdzgM1dLDed0nkrWmG6Fry/bUS/m9x83BwpJUOf1Qj/x2qJd+thL6IkIx7qPGRxqBw==",
       "dev": true,
       "requires": {
-        "ajv": "^7.0.2",
-        "lodash": "^4.17.20",
+        "ajv": "^8.0.1",
+        "lodash.clonedeep": "^4.5.0",
+        "lodash.truncate": "^4.4.2",
         "slice-ansi": "^4.0.0",
-        "string-width": "^4.2.0"
+        "string-width": "^4.2.0",
+        "strip-ansi": "^6.0.0"
       },
       "dependencies": {
         "ajv": {
-          "version": "7.1.1",
-          "resolved": "https://registry.npmjs.org/ajv/-/ajv-7.1.1.tgz",
-          "integrity": "sha512-ga/aqDYnUy/o7vbsRTFhhTsNeXiYb5JWDIcRIeZfwRNCefwjNTVYCGdGSUrEmiu3yDK3vFvNbgJxvrQW4JXrYQ==",
+          "version": "8.3.0",
+          "resolved": "https://registry.npmjs.org/ajv/-/ajv-8.3.0.tgz",
+          "integrity": "sha512-RYE7B5An83d7eWnDR8kbdaIFqmKCNsP16ay1hDbJEU+sa0e3H9SebskCt0Uufem6cfAVu7Col6ubcn/W+Sm8/Q==",
           "dev": true,
           "requires": {
             "fast-deep-equal": "^3.1.1",
@@ -9767,10 +9886,9 @@
       "dev": true
     },
     "tslib": {
-      "version": "2.1.0",
-      "resolved": "https://registry.npmjs.org/tslib/-/tslib-2.1.0.tgz",
-      "integrity": "sha512-hcVC3wYEziELGGmEEXue7D75zbwIIVUMWAVbHItGPx0ziyXxrOMQx4rQEVEV45Ut/1IotuEvwqPopzIOkDMf0A==",
-      "dev": true
+      "version": "2.2.0",
+      "resolved": "https://registry.npmjs.org/tslib/-/tslib-2.2.0.tgz",
+      "integrity": "sha512-gS9GVHRU+RGn5KQM2rllAlR3dU6m7AcpJKdtH8gFvQiC4Otgk98XnmMU+nZenHt/+VhnBPWwgrJsyrdcw6i23w=="
     },
     "tsscmp": {
       "version": "1.0.6",
@@ -9833,9 +9951,9 @@
       "dev": true
     },
     "typescript": {
-      "version": "4.2.3",
-      "resolved": "https://registry.npmjs.org/typescript/-/typescript-4.2.3.tgz",
-      "integrity": "sha512-qOcYwxaByStAWrBf4x0fibwZvMRG+r4cQoTjbPtUlrWjBHbmCAww1i448U0GJ+3cNNEtebDteo/cHOR3xJ4wEw==",
+      "version": "4.2.4",
+      "resolved": "https://registry.npmjs.org/typescript/-/typescript-4.2.4.tgz",
+      "integrity": "sha512-V+evlYHZnQkaz8TRBuxTA92yZBPotr5H+WhQ7bD3hZUndx5tGOa1fuCgeSjxAzM1RiN5IzvadIXTVefuuwZCRg==",
       "dev": true
     },
     "typical": {
@@ -9990,9 +10108,9 @@
       }
     },
     "url-parse": {
-      "version": "1.4.7",
-      "resolved": "https://registry.npmjs.org/url-parse/-/url-parse-1.4.7.tgz",
-      "integrity": "sha512-d3uaVyzDB9tQoSXFvuSUNFibTd9zxd2bkVrDRvF5TmvWWQwqE4lgYJ5m+x1DbecWkw+LK4RNl2CU1hHuOKPVlg==",
+      "version": "1.5.1",
+      "resolved": "https://registry.npmjs.org/url-parse/-/url-parse-1.5.1.tgz",
+      "integrity": "sha512-HOfCOUJt7iSYzEx/UqgtwKRMC6EU91NFhsCHMv9oM03VJcVo2Qrp8T8kI9D7amFf1cu+/3CEhgb3rF9zL7k85Q==",
       "dev": true,
       "requires": {
         "querystringify": "^2.1.1",
@@ -10041,9 +10159,9 @@
       "dev": true
     },
     "v8-compile-cache": {
-      "version": "2.2.0",
-      "resolved": "https://registry.npmjs.org/v8-compile-cache/-/v8-compile-cache-2.2.0.tgz",
-      "integrity": "sha512-gTpR5XQNKFwOd4clxfnhaqvfqMpqEwr4tOtCyz4MtYZX2JYhfr1JvBFKdS+7K/9rfpZR3VLX+YWBbKoxCgS43Q==",
+      "version": "2.3.0",
+      "resolved": "https://registry.npmjs.org/v8-compile-cache/-/v8-compile-cache-2.3.0.tgz",
+      "integrity": "sha512-l8lCEmLcLYZh4nbunNZvQCJc5pv7+RCwa8q/LdUx8u7lsWvPDKmpodJAJNwkAhJC//dFY48KuIEmjtd4RViDrA==",
       "dev": true
     },
     "validate-npm-package-license": {
@@ -10991,18 +11109,17 @@
       }
     },
     "webpack-cli": {
-      "version": "4.5.0",
-      "resolved": "https://registry.npmjs.org/webpack-cli/-/webpack-cli-4.5.0.tgz",
-      "integrity": "sha512-wXg/ef6Ibstl2f50mnkcHblRPN/P9J4Nlod5Hg9HGFgSeF8rsqDGHJeVe4aR26q9l62TUJi6vmvC2Qz96YJw1Q==",
+      "version": "4.7.0",
+      "resolved": "https://registry.npmjs.org/webpack-cli/-/webpack-cli-4.7.0.tgz",
+      "integrity": "sha512-7bKr9182/sGfjFm+xdZSwgQuFjgEcy0iCTIBxRUeteJ2Kr8/Wz0qNJX+jw60LU36jApt4nmMkep6+W5AKhok6g==",
       "dev": true,
       "requires": {
         "@discoveryjs/json-ext": "^0.5.0",
-        "@webpack-cli/configtest": "^1.0.1",
-        "@webpack-cli/info": "^1.2.2",
-        "@webpack-cli/serve": "^1.3.0",
+        "@webpack-cli/configtest": "^1.0.3",
+        "@webpack-cli/info": "^1.2.4",
+        "@webpack-cli/serve": "^1.4.0",
         "colorette": "^1.2.1",
         "commander": "^7.0.0",
-        "enquirer": "^2.3.6",
         "execa": "^5.0.0",
         "fastest-levenshtein": "^1.0.12",
         "import-local": "^3.0.2",
@@ -11013,9 +11130,9 @@
       },
       "dependencies": {
         "commander": {
-          "version": "7.0.0",
-          "resolved": "https://registry.npmjs.org/commander/-/commander-7.0.0.tgz",
-          "integrity": "sha512-ovx/7NkTrnPuIV8sqk/GjUIIM1+iUQeqA3ye2VNpq9sVoiZsooObWlQy+OPWGI17GDaEoybuAGJm6U8yC077BA==",
+          "version": "7.2.0",
+          "resolved": "https://registry.npmjs.org/commander/-/commander-7.2.0.tgz",
+          "integrity": "sha512-QrWXB+ZQSVPmIWIhtEO9H+gwHaMGYiF5ChvoJ+K9ZGHG/sVsa6yiesAD1GC/x46sET00Xlwo1u49RVVVzvcSkw==",
           "dev": true
         }
       }
diff --git a/esp/src/package.json b/esp/src/package.json
index b38a6b4d2..3ed4bff9c 100644
--- a/esp/src/package.json
+++ b/esp/src/package.json
@@ -33,27 +33,28 @@
   },
   "main": "src/stub.js",
   "dependencies": {
-    "@fluentui/react": "^8.1.4",
+    "@fluentui/react": "^8.14.5",
     "@fluentui/react-cards": "^1.0.0-beta.0",
-    "@fluentui/react-hooks": "^8.0.2",
-    "@hpcc-js/chart": "^2.57.0",
-    "@hpcc-js/codemirror": "^2.38.0",
-    "@hpcc-js/common": "^2.47.0",
-    "@hpcc-js/comms": "^2.40.0",
+    "@fluentui/react-hooks": "^8.2.0",
+    "@fluentui/react-icons-mdl2": "^1.1.0",
+    "@hpcc-js/chart": "^2.58.0",
+    "@hpcc-js/codemirror": "^2.40.0",
+    "@hpcc-js/common": "^2.48.0",
+    "@hpcc-js/comms": "^2.41.0",
     "@hpcc-js/dataflow": "^3.0.1",
-    "@hpcc-js/eclwatch": "^2.33.0",
-    "@hpcc-js/graph": "^2.52.0",
-    "@hpcc-js/html": "^2.22.0",
-    "@hpcc-js/layout": "^2.24.0",
-    "@hpcc-js/map": "^2.44.0",
-    "@hpcc-js/other": "^2.13.57",
-    "@hpcc-js/phosphor": "^2.14.37",
-    "@hpcc-js/react": "^2.29.0",
-    "@hpcc-js/tree": "^2.20.0",
+    "@hpcc-js/eclwatch": "^2.36.0",
+    "@hpcc-js/graph": "^2.54.0",
+    "@hpcc-js/html": "^2.23.0",
+    "@hpcc-js/layout": "^2.26.0",
+    "@hpcc-js/map": "^2.47.0",
+    "@hpcc-js/other": "^2.13.59",
+    "@hpcc-js/phosphor": "^2.14.39",
+    "@hpcc-js/react": "^2.30.0",
+    "@hpcc-js/tree": "^2.21.0",
     "@hpcc-js/util": "^2.29.0",
-    "@material-ui/core": "^4.11.3",
+    "@material-ui/core": "^4.11.4",
     "@material-ui/icons": "^4.11.2",
-    "@material-ui/lab": "^4.0.0-alpha.57",
+    "@material-ui/lab": "^4.0.0-alpha.58",
     "clipboard": "2.0.4",
     "codemirror": "5.50.2",
     "detect-browser": "5.0.0",
@@ -74,15 +75,15 @@
   },
   "devDependencies": {
     "@types/dojo": "^1.9.43",
-    "@types/react": "^16.14.4",
-    "@types/react-dom": "^16.9.11",
+    "@types/react": "^16.14.6",
+    "@types/react-dom": "^16.9.12",
     "@typescript-eslint/eslint-plugin": "^3.2.0",
     "@typescript-eslint/parser": "^3.2.0",
     "braces": ">=2.3.1",
     "cpx": "^1.5.0",
     "css-loader": "^3.4.2",
     "dojo-webpack-plugin": "^2.8.19",
-    "eslint": "^7.21.0",
+    "eslint": "^7.26.0",
     "eslint-plugin-react-hooks": "^4.2.0",
     "file-loader": "^5.1.0",
     "local-web-server": "^4.0.0",
@@ -91,11 +92,11 @@
     "rimraf": "^3.0.2",
     "source-map-loader": "^1.1.3",
     "style-loader": "^1.1.3",
-    "tslib": "^2.1.0",
-    "typescript": "^4.2.3",
+    "tslib": "^2.2.0",
+    "typescript": "^4.2.4",
     "url-loader": "^3.0.0",
     "webpack": "^4.45.0",
-    "webpack-cli": "^4.5.0",
+    "webpack-cli": "^4.7.0",
     "webpack-dev-server": "^3.11.2"
   },
   "author": "HPCC Systems",
diff --git a/esp/src/src-react/components/About.tsx b/esp/src/src-react/components/About.tsx
new file mode 100644
index 000000000..7f34b96e8
--- /dev/null
+++ b/esp/src/src-react/components/About.tsx
@@ -0,0 +1,71 @@
+import * as React from "react";
+import { DefaultButton, Dialog, DialogFooter, DialogType, Pivot, PivotItem } from "@fluentui/react";
+import { useConst } from "@fluentui/react-hooks";
+import { Bar } from "@hpcc-js/chart";
+import { fetchStats } from "src/KeyValStore";
+import nlsHPCC from "src/nlsHPCC";
+import { TpGetServerVersion } from "src/WsTopology";
+import { AutosizeHpccJSComponent } from "../layouts/HpccJSAdapter";
+import { TableGroup } from "./forms/Groups";
+
+interface AboutProps {
+    show?: boolean;
+    onClose?: () => void;
+}
+
+export const About: React.FunctionComponent<AboutProps> = ({
+    show = false,
+    onClose = () => { }
+}) => {
+
+    const [version, setVersion] = React.useState("");
+    const [browser, setBrowser] = React.useState([]);
+    const [os, setOS] = React.useState([]);
+
+    React.useEffect(() => {
+        TpGetServerVersion().then(version => {
+            setVersion(version);
+        });
+        fetchStats().then(response => {
+            setBrowser(response.browser);
+            setOS(response.os);
+        });
+    }, []);
+
+    const browserChart = useConst(new Bar().columns([nlsHPCC.Client, nlsHPCC.Count]));
+    browserChart
+        .data(browser)
+        ;
+    const osChart = useConst(new Bar().columns([nlsHPCC.Client, nlsHPCC.Count]));
+    osChart
+        .data(os)
+        ;
+
+    const dialogContentProps = {
+        type: DialogType.largeHeader,
+        title: nlsHPCC.AboutHPCCSystems
+    };
+
+    return <Dialog hidden={!show} onDismiss={onClose} dialogContentProps={dialogContentProps} minWidth="640px">
+        <Pivot>
+            <PivotItem itemKey="about" headerText={nlsHPCC.About}>
+                <div style={{ minHeight: "208px", paddingTop: "32px" }}>
+                    <TableGroup fields={{
+                        version: { label: nlsHPCC.Version, type: "string", value: version || "???", readonly: true },
+                        homepage: { label: nlsHPCC.Homepage, type: "link", href: "https://hpccsystems.com" },
+                    }}>
+                    </TableGroup>
+                </div>
+            </PivotItem>
+            <PivotItem itemKey="browser" headerText={nlsHPCC.BrowserStats} alwaysRender>
+                <AutosizeHpccJSComponent widget={browserChart} fixedHeight="240px" />
+            </PivotItem>
+            <PivotItem itemKey="os" headerText={nlsHPCC.OSStats} alwaysRender>
+                <AutosizeHpccJSComponent widget={osChart} fixedHeight="240px" />
+            </PivotItem>
+        </Pivot>
+        <DialogFooter>
+            <DefaultButton onClick={onClose} text={nlsHPCC.OK} />
+        </DialogFooter>
+    </Dialog>;
+};
diff --git a/esp/src/src-react/components/Activities.tsx b/esp/src/src-react/components/Activities.tsx
index 7e9f90677..b7e398b85 100644
--- a/esp/src/src-react/components/Activities.tsx
+++ b/esp/src/src-react/components/Activities.tsx
@@ -5,7 +5,7 @@ import * as ESPActivity from "src/ESPActivity";
 import * as Utility from "src/Utility";
 import nlsHPCC from "src/nlsHPCC";
 import { HolyGrail } from "../layouts/HolyGrail";
-import { ShortVerticalDivider } from "./Common";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid, selector, tree } from "./DojoGrid";
 
 class DelayedRefresh {
@@ -246,19 +246,7 @@ export const Activities: React.FunctionComponent<ActivitiesProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: !uiState.wuSelected || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                const wuids = selection.map(s => s.Wuid);
-                navigator?.clipboard?.writeText(wuids.join("\n"));
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: !uiState.wuSelected, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                Utility.downloadToCSV(grid, selection.map(row => ([row.Protected, row.Wuid, row.Owner, row.Jobname, row.Cluster, row.RoxieCluster, row.State, row.TotalClusterTime])), "workunits.csv");
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "activities.csv")
     ];
 
     //  Grid ---
@@ -408,7 +396,7 @@ export const Activities: React.FunctionComponent<ActivitiesProps> = ({
             }
         });
         setUIState(state);
-    // eslint-disable-next-line react-hooks/exhaustive-deps
+        // eslint-disable-next-line react-hooks/exhaustive-deps
     }, [selection]);
 
     return <HolyGrail
diff --git a/esp/src/src-react/components/Common.tsx b/esp/src/src-react/components/Common.tsx
index 771a72b43..3cd903a89 100644
--- a/esp/src/src-react/components/Common.tsx
+++ b/esp/src/src-react/components/Common.tsx
@@ -1,4 +1,24 @@
 import * as React from "react";
 import { VerticalDivider } from "@fluentui/react";
+import * as Utility from "src/Utility";
+import nlsHPCC from "src/nlsHPCC";
 
 export const ShortVerticalDivider = () => <VerticalDivider styles={{ divider: { paddingTop: "20%", height: "60%" } }} />;
+
+export function createCopyDownloadSelection(grid, selection: any, filename: string) {
+    return [{
+        key: "copy", text: nlsHPCC.CopySelectionToClipboard, disabled: !selection.length || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
+        onClick: () => {
+            const tsv = Utility.formatAsDelim(grid, selection, "\t");
+            navigator?.clipboard?.writeText(tsv);
+        }
+    },
+    {
+        key: "download", text: nlsHPCC.DownloadSelectionAsCSV, disabled: !selection.length, iconOnly: true, iconProps: { iconName: "Download" },
+        onClick: () => {
+            const csv = Utility.formatAsDelim(grid, selection, ",");
+            Utility.downloadText(csv, filename);
+        }
+    }];
+}
+
diff --git a/esp/src/src-react/components/Configuration.tsx b/esp/src/src-react/components/Configuration.tsx
new file mode 100644
index 000000000..c51251a01
--- /dev/null
+++ b/esp/src/src-react/components/Configuration.tsx
@@ -0,0 +1,27 @@
+import * as React from "react";
+import { XMLSourceEditor } from "./SourceEditor";
+import * as ESPRequest from "../../src/ESPRequest";
+
+interface ConfigurationProps {
+}
+
+export const Configuration: React.FunctionComponent<ConfigurationProps> = ({
+}) => {
+
+    const [configXml, setConfigXml] = React.useState("");
+
+    React.useEffect(() => {
+        ESPRequest.send("main", "", {
+            request: {
+                config_: "",
+                PlainText: "yes"
+            },
+            handleAs: "text"
+        }).then(response => {
+            setConfigXml(response);
+        });
+    }, []);
+
+    return <XMLSourceEditor text={configXml} readonly={true} />;
+
+};
\ No newline at end of file
diff --git a/esp/src/src-react/components/DFUWorkunits.tsx b/esp/src/src-react/components/DFUWorkunits.tsx
index 25397b386..2e10f3346 100644
--- a/esp/src/src-react/components/DFUWorkunits.tsx
+++ b/esp/src/src-react/components/DFUWorkunits.tsx
@@ -8,8 +8,9 @@ import * as Utility from "src/Utility";
 import nlsHPCC from "src/nlsHPCC";
 import { HolyGrail } from "../layouts/HolyGrail";
 import { pushParams } from "../util/history";
-import { Fields, Filter } from "./Filter";
-import { ShortVerticalDivider } from "./Common";
+import { Filter } from "./forms/Filter";
+import { Fields } from "./forms/Fields";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid, selector } from "./DojoGrid";
 
 const FilterFields: Fields = {
@@ -115,19 +116,7 @@ export const DFUWorkunits: React.FunctionComponent<DFUWorkunitsProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: !uiState.hasSelection || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                const wuids = selection.map(s => s.Wuid);
-                navigator?.clipboard?.writeText(wuids.join("\n"));
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: !uiState.hasSelection, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                Utility.downloadToCSV(grid, selection.map(row => ([row.Protected, row.Wuid, row.Owner, row.Jobname, row.Cluster, row.RoxieCluster, row.State, row.TotalClusterTime])), "workunits.csv");
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "dfuworkunits.csv")
     ];
 
     //  Grid ---
@@ -198,7 +187,7 @@ export const DFUWorkunits: React.FunctionComponent<DFUWorkunitsProps> = ({
 
     React.useEffect(() => {
         refreshTable();
-    // eslint-disable-next-line react-hooks/exhaustive-deps
+        // eslint-disable-next-line react-hooks/exhaustive-deps
     }, [filter]);
 
     //  Selection  ---
diff --git a/esp/src/src-react/components/DojoGrid.css b/esp/src/src-react/components/DojoGrid.css
index 160f76678..100cb636e 100644
--- a/esp/src/src-react/components/DojoGrid.css
+++ b/esp/src/src-react/components/DojoGrid.css
@@ -1,5 +1,4 @@
 :root {
-    --grid-font-family: "Segoe WPC", "Segoe UI", sans-serif;
     --header-font-size: 14px;
     --row-font-size: 13px;
     --grid-background: transparent;
@@ -10,57 +9,90 @@
 }
 
 .flat .dojo-component.dgrid.dgrid-grid {
-    font-family: var(--grid-font-family);
     border-style: hidden;
 }
 
-.flat .dojo-component.dgrid .dgrid-header-row {
+.flat .dgrid-header-row {
     background-color: var(--grid-background);
     font-size: var(--header-font-size);
     line-height: 32px;
 }
 
-.flat .dojo-component.dgrid .dgrid-header-row .dgrid-cell {
+.flat .dgrid-header-row .dgrid-cell {
     border-bottom-color: var(--grid-selectionBackground);
 }
 
-.flat .dojo-component.dgrid .dgrid-header-row:focus {
+.flat .dgrid-header-row:focus {
     outline-width: 0px;
 }
 
-.flat .dojo-component.dgrid .dgrid-header.dgrid-header-scroll {
+.flat .dgrid-header.dgrid-header-scroll {
     background-color: var(--grid-background);
 }
 
-.flat .dojo-component.dgrid .dgrid-row {
-    font-family: var(--grid-font-family);
+.flat .dgrid-row {
     font-size: var(--row-font-size);
     line-height: 22px;
 }
 
-.flat .dojo-component.dgrid .dgrid-row:hover {
+.flat .dgrid-row:hover {
     background-color: var(--grid-hoverBackground);
 }
 
-.flat .dojo-component.dgrid .dgrid-row.dgrid-selected:hover {
+.flat .dgrid-row.dgrid-selected:hover {
     background-color: var(--grid-selectionHoverBackground);
 }
 
-.flat .dojo-component.dgrid .dgrid-row .dgrid-selected {
+.flat .dgrid-row .dgrid-selected {
     background-color: var(--grid-selectionBackground);
     color: var(--grid-selectionForeground);
     border-color: var(--grid-background);
 }
 
-.flat .dojo-component.dgrid .dgrid-cell {
+.flat .dgrid-cell {
     border-color: var(--grid-background);
 }
 
-.flat .dojo-component.dgrid .dgrid-focus:focus {
+.flat .dgrid-focus:focus {
     outline-width: 0px;
 }
 
-.flat .dojo-component.dgrid .dgrid-fakeline {
+.flat .dgrid-fakeline {
     border: 0px;
     margin: 2px;
+}
+
+.flat .dgrid-footer {
+    background-color: var(--grid-background);
+}
+
+.flat .dgrid-pagination {
+    display: flex;
+    align-items: center;
+    justify-content: space-between;
+    font-size: 14px;
+    line-height: 14px;
+    padding: 4px 8px;
+}
+
+.flat .dgrid-pagination .dgrid-status {
+    flex-grow: 1;
+    padding: 0;
+}
+
+.flat .dgrid-pagination .dgrid-page-size {
+    margin: 0 10px 0 0;
+    padding: 2px;
+    width: 46px;
+    -webkit-box-shadow: none;
+    box-shadow: none;
+}
+
+.flat .dgrid-pagination .dgrid-navigation .dgrid-page-input {
+    padding: 0;
+    margin: 0;
+    background: var(--grid-background);
+    border-style: solid;
+    border-width: 1px;
+    color: inherit;
 }
\ No newline at end of file
diff --git a/esp/src/src-react/components/Files.tsx b/esp/src/src-react/components/Files.tsx
index 21da7f306..52d9af1d4 100644
--- a/esp/src/src-react/components/Files.tsx
+++ b/esp/src/src-react/components/Files.tsx
@@ -9,8 +9,9 @@ import * as Utility from "src/Utility";
 import nlsHPCC from "src/nlsHPCC";
 import { HolyGrail } from "../layouts/HolyGrail";
 import { pushParams } from "../util/history";
-import { Fields, Filter } from "./Filter";
-import { ShortVerticalDivider } from "./Common";
+import { Fields } from "./forms/Fields";
+import { Filter } from "./forms/Filter";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid, selector, tree } from "./DojoGrid";
 
 const FilterFields: Fields = {
@@ -18,7 +19,7 @@ const FilterFields: Fields = {
     "Description": { type: "string", label: nlsHPCC.Description, placeholder: nlsHPCC.SomeDescription },
     "Owner": { type: "string", label: nlsHPCC.Owner, placeholder: nlsHPCC.jsmi },
     "Index": { type: "checkbox", label: nlsHPCC.Index },
-    "NodeGroup": { type: "target-group", label: nlsHPCC.Cluster, placeholder: nlsHPCC.Owner },
+    "NodeGroup": { type: "target-group", label: nlsHPCC.Group, placeholder: nlsHPCC.Cluster },
     "FileSizeFrom": { type: "string", label: nlsHPCC.FromSizes, placeholder: "4096" },
     "FileSizeTo": { type: "string", label: nlsHPCC.ToSizes, placeholder: "16777216" },
     "FileType": { type: "file-type", label: nlsHPCC.FileType },
@@ -105,19 +106,7 @@ export const Files: React.FunctionComponent<FilesProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.CopyLogicalFiles, disabled: !uiState.hasSelection || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                const wuids = selection.map(s => s.Name);
-                navigator?.clipboard?.writeText(wuids.join("\n"));
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: !uiState.hasSelection, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                Utility.downloadToCSV(grid, selection.map(row => ([row.IsProtected, row.IsCompressed, row.IsKeyFile, row.__hpcc_displayName, row.Owner, row.SuperOwners, row.Description, row.NodeGroup, row.RecordCount, row.IntSize, row.Parts, row.Modified])), "workunits.csv");
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "logicalfiles.csv")
     ];
 
     //  Grid ---
diff --git a/esp/src/src-react/components/Filter.tsx b/esp/src/src-react/components/Filter.tsx
deleted file mode 100644
index 639b46b3e..000000000
--- a/esp/src/src-react/components/Filter.tsx
+++ /dev/null
@@ -1,305 +0,0 @@
-import * as React from "react";
-import { getTheme, mergeStyleSets, FontWeights, IDragOptions, IIconProps, ContextualMenu, DefaultButton, PrimaryButton, IconButton, Dropdown, IStackStyles, Modal, Stack, IDropdownProps, IDropdownOption } from "@fluentui/react";
-import { useId } from "@fluentui/react-hooks";
-import { TpGroupQuery } from "src/WsTopology";
-import nlsHPCC from "src/nlsHPCC";
-import { Details } from "./Details";
-
-type FieldType = "string" | "checkbox" | "datetime" |
-    "workunit-state" |
-    "file-type" | "file-sortby" |
-    "queries-suspend-state" | "queries-active-state" |
-    "target-cluster" | "target-group" |
-    "logicalfile-type" | "dfuworkunit-state";
-
-interface BaseField {
-    type: FieldType;
-    label: string;
-    disabled?: (params) => boolean;
-    placeholder?: string;
-    readonly?: boolean;
-}
-
-interface StringField extends BaseField {
-    type: "string";
-    value?: string;
-}
-
-interface DateTimeField extends BaseField {
-    type: "datetime";
-    value?: string;
-}
-
-interface CheckboxField extends BaseField {
-    type: "checkbox";
-    value?: boolean;
-}
-
-interface WorkunitStateField extends BaseField {
-    type: "workunit-state";
-    value?: string;
-}
-
-interface FileTypeField extends BaseField {
-    type: "file-type";
-    value?: string;
-}
-
-interface FileSortByField extends BaseField {
-    type: "file-sortby";
-    value?: string;
-}
-
-interface QueriesSuspendStateField extends BaseField {
-    type: "queries-suspend-state";
-    value?: string;
-}
-
-interface QueriesActiveStateField extends BaseField {
-    type: "queries-active-state";
-    value?: string;
-}
-
-interface TargetClusterField extends BaseField {
-    type: "target-cluster";
-    value?: string;
-}
-
-interface TargetGroupField extends BaseField {
-    type: "target-group";
-    value?: string;
-}
-
-interface LogicalFileType extends BaseField {
-    type: "logicalfile-type";
-    value?: string;
-}
-
-interface DFUWorkunitStateField extends BaseField {
-    type: "dfuworkunit-state";
-    value?: string;
-}
-
-type Field = StringField | CheckboxField | DateTimeField |
-    WorkunitStateField |
-    FileTypeField | FileSortByField |
-    QueriesSuspendStateField | QueriesActiveStateField |
-    TargetClusterField | TargetGroupField |
-    LogicalFileType | DFUWorkunitStateField;
-
-export type Fields = { [name: string]: Field };
-export type Values = { [name: string]: string | number | boolean | (string | number | boolean)[] };
-
-const fieldsToRequest = (fields: Fields) => {
-    const retVal: Values = {};
-    for (const name in fields) {
-        if (!fields[name].disabled(fields)) {
-            retVal[name] = fields[name].value;
-        }
-    }
-    return retVal;
-};
-
-export const TargetGroupTextField: React.FunctionComponent<IDropdownProps> = (props) => {
-
-    const [targetGroups, setTargetGroups] = React.useState<IDropdownOption[]>([]);
-
-    React.useEffect(() => {
-        TpGroupQuery({}).then(({ TpGroupQueryResponse }) => {
-            setTargetGroups(
-                TpGroupQueryResponse.TpGroups.TpGroup.map(n => {
-                    return {
-                        key: n.Name,
-                        text: n.Name + (n.Name !== n.Kind ? ` (${n.Kind})` : "")
-                    };
-                })
-            );
-        });
-    }, []);
-
-    return <Dropdown
-        {...props}
-        options={targetGroups}
-    />;
-};
-
-interface FormContentProps {
-    fields: Fields;
-    doSubmit: boolean;
-    doReset: boolean;
-    onSubmit: (fields: Values) => void;
-    onReset: (fields: Values) => void;
-}
-
-export const FormContent: React.FunctionComponent<FormContentProps> = ({
-    fields,
-    doSubmit,
-    doReset,
-    onSubmit,
-    onReset
-}) => {
-
-    const [localFields, setLocalFields] = React.useState<Fields>({ ...fields });
-
-    React.useEffect(() => {
-        if (doSubmit === false) return;
-        onSubmit(fieldsToRequest(localFields));
-        // eslint-disable-next-line react-hooks/exhaustive-deps
-    }, [doSubmit]);
-
-    React.useEffect(() => {
-        if (doReset === false) return;
-        for (const key in localFields) {
-            delete localFields[key].value;
-        }
-        setLocalFields(localFields);
-        onReset(fieldsToRequest(localFields));
-        // eslint-disable-next-line react-hooks/exhaustive-deps
-    }, [doReset]);
-
-    return <Details fields={localFields} onChange={(id, value) => {
-        const field = localFields[id];
-        switch (field.type) {
-            case "checkbox":
-                field.value = value;
-                setLocalFields({ ...localFields });
-                break;
-            default:
-                field.value = value;
-                setLocalFields({ ...localFields });
-                break;
-        }
-    }} />;
-};
-
-interface FilterProps {
-    filterFields: Fields;
-    onApply: (values: Values) => void;
-
-    showFilter: boolean;
-    setShowFilter: (_: boolean) => void;
-}
-
-export const Filter: React.FunctionComponent<FilterProps> = ({
-    filterFields,
-    onApply,
-    showFilter,
-    setShowFilter
-}) => {
-
-    const [doSubmit, setDoSubmit] = React.useState(false);
-    const [doReset, setDoReset] = React.useState(false);
-
-    const closeFilter = () => setShowFilter(false);
-
-    const titleId = useId("title");
-
-    const dragOptions: IDragOptions = {
-        moveMenuItemText: "Move",
-        closeMenuItemText: "Close",
-        menu: ContextualMenu,
-    };
-
-    const theme = getTheme();
-
-    const contentStyles = mergeStyleSets({
-        container: {
-            display: "flex",
-            flexFlow: "column nowrap",
-            alignItems: "stretch",
-        },
-        header: [
-            {
-                flex: "1 1 auto",
-                borderTop: `4px solid ${theme.palette.themePrimary}`,
-                color: theme.palette.neutralPrimary,
-                display: "flex",
-                alignItems: "center",
-                fontWeight: FontWeights.semibold,
-                padding: "12px 12px 14px 24px",
-            },
-        ],
-        body: {
-            flex: "4 4 auto",
-            padding: "0 24px 24px 24px",
-            overflowY: "hidden",
-            selectors: {
-                p: { margin: "14px 0" },
-                "p:first-child": { marginTop: 0 },
-                "p:last-child": { marginBottom: 0 },
-            },
-        },
-    });
-
-    const cancelIcon: IIconProps = { iconName: "Cancel" };
-    const iconButtonStyles = {
-        root: {
-            color: theme.palette.neutralPrimary,
-            marginLeft: "auto",
-            marginTop: "4px",
-            marginRight: "2px",
-        },
-        rootHovered: {
-            color: theme.palette.neutralDark,
-        },
-    };
-    const buttonStackStyles: IStackStyles = {
-        root: {
-            height: "56px",
-        },
-    };
-    return <Modal
-        titleAriaId={titleId}
-        isOpen={showFilter}
-        onDismiss={closeFilter}
-        isBlocking={false}
-        containerClassName={contentStyles.container}
-        dragOptions={dragOptions}
-    >
-        <div className={contentStyles.header}>
-            <span id={titleId}>Filter</span>
-            <IconButton
-                styles={iconButtonStyles}
-                iconProps={cancelIcon}
-                ariaLabel="Close popup modal"
-                onClick={closeFilter}
-            />
-        </div>
-        <div className={contentStyles.body}>
-            <Stack>
-                <FormContent
-                    fields={filterFields}
-                    doSubmit={doSubmit}
-                    doReset={doReset}
-                    onSubmit={fields => {
-                        setDoSubmit(false);
-                        onApply(fields);
-                    }}
-                    onReset={() => {
-                        setDoReset(false);
-                    }}
-                />
-            </Stack>
-            <Stack
-                horizontal
-                horizontalAlign="space-between"
-                verticalAlign="end"
-                styles={buttonStackStyles}
-            >
-                <DefaultButton
-                    text={nlsHPCC.Clear}
-                    onClick={() => {
-                        setDoReset(true);
-                    }}
-                />
-                <PrimaryButton
-                    text={nlsHPCC.Apply}
-                    onClick={() => {
-                        setDoSubmit(true);
-                        closeFilter();
-                    }}
-                />
-            </Stack>
-        </div>
-    </Modal>;
-};
diff --git a/esp/src/src-react/components/Helpers.tsx b/esp/src/src-react/components/Helpers.tsx
new file mode 100644
index 000000000..a0df75ca3
--- /dev/null
+++ b/esp/src/src-react/components/Helpers.tsx
@@ -0,0 +1,240 @@
+import * as React from "react";
+import { CommandBar, ContextualMenuItemType, ICommandBarItemProps } from "@fluentui/react";
+import { useConst } from "@fluentui/react-hooks";
+import * as domClass from "dojo/dom-class";
+import * as Observable from "dojo/store/Observable";
+import * as ESPRequest from "src/ESPRequest";
+import { Memory } from "src/Memory";
+import * as Utility from "src/Utility";
+import nlsHPCC from "src/nlsHPCC";
+import { HelperRow, useWorkunitHelpers } from "../hooks/Workunit";
+import { HolyGrail } from "../layouts/HolyGrail";
+import { ShortVerticalDivider } from "./Common";
+import { DojoGrid, selector } from "./DojoGrid";
+
+function canShowContent(type: string) {
+    switch (type) {
+        case "dll":
+            return false;
+    }
+    return true;
+}
+
+function getURL(item: HelperRow, option) {
+    let params = "";
+    switch (item.Type) {
+        case "dll":
+            const parts = item.Orig.Name.split("/");
+            if (parts.length) {
+                const leaf = parts[parts.length - 1];
+                params = "/WUFile/" + leaf + "?Wuid=" + item.workunit.Wuid + "&Name=" + item.Orig.Name + "&Type=" + item.Orig.Type;
+            }
+            break;
+        case "res":
+            params = "/WUFile/res.txt?Wuid=" + item.workunit.Wuid + "&Type=" + item.Orig.Type;
+            break;
+        case "EclAgentLog":
+            params = "/WUFile/" + item.Type + "?Wuid=" + item.workunit.Wuid + "&Process=" + item.Orig.PID + "&Name=" + item.Orig.Name + "&Type=" + item.Orig.Type;
+            break;
+        case "ThorSlaveLog":
+            params = "/WUFile?Wuid=" + item.workunit.Wuid + "&Process=" + item.Orig.ProcessName + "&ClusterGroup=" + item.Orig.ProcessName + "&LogDate=" + item.Orig.LogDate + "&SlaveNumber=" + item.Orig.SlaveNumber + "&Type=" + item.Type;
+            break;
+        case "Archive Query":
+            params = "/WUFile/ArchiveQuery?Wuid=" + item.workunit.Wuid + "&Name=ArchiveQuery&Type=ArchiveQuery";
+            break;
+        case "ECL":
+            params = "/WUFile?Wuid=" + item.workunit.Wuid + "&Type=WUECL";
+            break;
+        case "Workunit XML":
+            params = "/WUFile?Wuid=" + item.workunit.Wuid + "&Type=XML";
+            break;
+        case "log":
+        case "cpp":
+        case "hpp":
+            params = "/WUFile?Wuid=" + item.workunit.Wuid + "&Name=" + item.Orig.Name + "&IPAddress=" + item.Orig.IPAddress + "&Description=" + item.Orig.Description + "&Type=" + item.Orig.Type;
+            break;
+        case "xml":
+            if (option !== undefined)
+                params = "/WUFile?Wuid=" + item.workunit.Wuid + "&Name=" + item.Orig.Name + "&IPAddress=" + item.Orig.IPAddress + "&Description=" + item.Orig.Description + "&Type=" + item.Orig.Type;
+            break;
+        default:
+            if (item.Type.indexOf("ThorLog") === 0)
+                params = "/WUFile/" + item.Type + "?Wuid=" + item.workunit.Wuid + "&Process=" + item.Orig.PID + "&Name=" + item.Orig.Name + "&Type=" + item.Orig.Type;
+            break;
+    }
+
+    return ESPRequest.getBaseURL() + params + (option ? "&Option=" + option : "&Option=1");
+}
+
+function getTarget(id, row: HelperRow) {
+    if (canShowContent(row.Type)) {
+        let sourceMode = "text";
+        switch (row.Type) {
+            case "ECL":
+                sourceMode = "ecl";
+                break;
+            case "Workunit XML":
+            case "Archive Query":
+            case "xml":
+                sourceMode = "xml";
+                break;
+        }
+        return {
+            sourceMode,
+            url: getURL(row, id)
+        };
+    }
+    return null;
+}
+
+const defaultUIState = {
+    hasSelection: false,
+    canShowContent: false
+};
+
+interface HelpersProps {
+    wuid: string;
+}
+
+export const Helpers: React.FunctionComponent<HelpersProps> = ({
+    wuid
+}) => {
+
+    const [grid, setGrid] = React.useState<any>(undefined);
+    const [selection, setSelection] = React.useState([]);
+    const [uiState, setUIState] = React.useState({ ...defaultUIState });
+    const [helpers] = useWorkunitHelpers(wuid);
+
+    //  Command Bar  ---
+    const buttons: ICommandBarItemProps[] = [
+        {
+            key: "refresh", text: nlsHPCC.Refresh, iconProps: { iconName: "Refresh" },
+            onClick: () => refreshTable()
+        },
+        { key: "divider_1", itemType: ContextualMenuItemType.Divider, onRender: () => <ShortVerticalDivider /> },
+        {
+            key: "open", text: nlsHPCC.Open, disabled: !uiState.canShowContent, iconProps: { iconName: "WindowEdit" },
+            onClick: () => {
+                if (selection.length === 1) {
+                    const target = getTarget(selection[0].id, selection[0]);
+                    if (target) {
+                        window.location.href = `#/text?mode=${target.sourceMode}&src=${encodeURIComponent(target.url)}`;
+                    }
+                } else {
+                    for (let i = 0; i < selection.length; ++i) {
+                        const target = getTarget(selection[i].id, selection[i]);
+                        if (target) {
+                            window.open(`#/text?mode=${target.sourceMode}&src=${encodeURIComponent(target.url)}`, "_blank");
+                        }
+                    }
+                }
+            }
+        },
+        { key: "divider_2", itemType: ContextualMenuItemType.Divider, onRender: () => <ShortVerticalDivider /> },
+        {
+            key: "file", text: nlsHPCC.File, disabled: !uiState.hasSelection, iconProps: { iconName: "Download" },
+            onClick: () => {
+                selection.forEach(item => {
+                    window.open(getURL(item, 1));
+                });
+            }
+        },
+        {
+            key: "zip", text: nlsHPCC.Zip, disabled: !uiState.hasSelection, iconProps: { iconName: "Download" },
+            onClick: () => {
+                selection.forEach(item => {
+                    window.open(getURL(item, 2));
+                });
+            }
+        },
+        {
+            key: "gzip", text: nlsHPCC.GZip, disabled: !uiState.hasSelection, iconProps: { iconName: "Download" },
+            onClick: () => {
+                selection.forEach(item => {
+                    window.open(getURL(item, 3));
+                });
+            }
+        }
+
+    ];
+
+    const rightButtons: ICommandBarItemProps[] = [
+        {
+            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: true, iconOnly: true, iconProps: { iconName: "Copy" },
+            onClick: () => {
+                //  TODO:  HPCC-25473
+            }
+        },
+        {
+            key: "download", text: nlsHPCC.DownloadToCSV, disabled: true, iconOnly: true, iconProps: { iconName: "Download" },
+            onClick: () => {
+                //  TODO:  HPCC-25473
+            }
+        }
+    ];
+
+    //  Grid ---
+    const gridStore = useConst(new Observable(new Memory("id")));
+    const gridQuery = useConst({});
+    const gridColumns = useConst({
+        sel: selector({
+            width: 27,
+            selectorType: "checkbox"
+        }),
+        Type: {
+            label: nlsHPCC.Type,
+            width: 160,
+            formatter: function (Type, row) {
+                const target = getTarget(row.id, row);
+                if (target) {
+                    return `<a href='#/text?mode=${target.sourceMode}&src=${encodeURIComponent(target.url)}'>${Type + (row?.Orig?.Description ? " (" + row.Orig.Description + ")" : "")}</a>`;
+                }
+                return Type;
+            }
+        },
+        Description: {
+            label: nlsHPCC.Description
+        },
+        FileSize: {
+            label: nlsHPCC.FileSize,
+            width: 90,
+            renderCell: function (object, value, node, options) {
+                domClass.add(node, "justify-right");
+                node.innerText = Utility.valueCleanUp(value);
+            },
+        }
+    });
+
+    const refreshTable = (clearSelection = false) => {
+        grid?.set("query", gridQuery);
+        if (clearSelection) {
+            grid?.clearSelection();
+        }
+    };
+
+    //  Selection  ---
+    React.useEffect(() => {
+        const state = { ...defaultUIState };
+
+        selection.forEach(row => {
+            state.hasSelection = true;
+            if (canShowContent(row.Type)) {
+                state.canShowContent = true;
+            }
+        });
+        setUIState(state);
+    }, [selection]);
+
+    React.useEffect(() => {
+        gridStore.setData(helpers);
+        refreshTable();
+        // eslint-disable-next-line react-hooks/exhaustive-deps
+    }, [gridStore, helpers]);
+
+    return <HolyGrail
+        header={<CommandBar items={buttons} overflowButtonProps={{}} farItems={rightButtons} />}
+        main={
+            <DojoGrid store={gridStore} query={gridQuery} columns={gridColumns} setGrid={setGrid} setSelection={setSelection} />
+        }
+    />;
+};
diff --git a/esp/src/src-react/components/IFrame.tsx b/esp/src/src-react/components/IFrame.tsx
new file mode 100644
index 000000000..6a574e3f9
--- /dev/null
+++ b/esp/src/src-react/components/IFrame.tsx
@@ -0,0 +1,12 @@
+import * as React from "react";
+
+interface IFrameProps {
+    src: string;
+}
+
+export const IFrame: React.FunctionComponent<IFrameProps> = ({
+    src
+}) => {
+
+    return <iframe src={src} width="100%" height="100%" style={{ border: "none" }} ></iframe>;
+};
diff --git a/esp/src/src-react/components/InfoGrid.tsx b/esp/src/src-react/components/InfoGrid.tsx
new file mode 100644
index 000000000..48e0b484d
--- /dev/null
+++ b/esp/src/src-react/components/InfoGrid.tsx
@@ -0,0 +1,184 @@
+import * as React from "react";
+import { Checkbox, CommandBar, ICommandBarItemProps } from "@fluentui/react";
+import { useConst } from "@fluentui/react-hooks";
+import * as domClass from "dojo/dom-class";
+import * as Observable from "dojo/store/Observable";
+import { Memory } from "src/Memory";
+import * as Utility from "src/Utility";
+import nlsHPCC from "src/nlsHPCC";
+import { useWorkunitExceptions } from "../hooks/Workunit";
+import { HolyGrail } from "../layouts/HolyGrail";
+import { DojoGrid } from "./DojoGrid";
+import { createCopyDownloadSelection } from "./Common";
+
+function extractGraphInfo(msg) {
+    const retVal: { graphID?: string, subgraphID?: string, activityID?: string, activityName?: string } = {};
+    const parts = msg.split("Graph graph");
+    if (parts.length > 1) {
+        const parts1 = parts[1].split("[");
+        if (parts1.length > 1) {
+            retVal.graphID = "graph" + parts1[0];
+            parts1.shift();
+            const parts2 = parts1.join("[").split("], ");
+            retVal.subgraphID = parts2[0];
+            if (parts2.length > 1) {
+                const parts3 = parts2[1].split("[");
+                retVal.activityName = parts3[0];
+                if (parts3.length > 1) {
+                    const parts4 = parts3[1].split("]");
+                    retVal.activityID = parts4[0];
+                }
+            }
+        }
+    }
+    return retVal;
+}
+
+interface InfoGridProps {
+    wuid: string;
+}
+
+export const InfoGrid: React.FunctionComponent<InfoGridProps> = ({
+    wuid
+}) => {
+
+    const [errorChecked, setErrorChecked] = React.useState(true);
+    const [warningChecked, setWarningChecked] = React.useState(true);
+    const [infoChecked, setInfoChecked] = React.useState(true);
+    const [otherChecked, setOtherChecked] = React.useState(true);
+    const [filterCounts, setFilterCounts] = React.useState<any>({});
+    const [grid, setGrid] = React.useState<any>(undefined);
+    const [exceptions] = useWorkunitExceptions(wuid);
+    const [selection, setSelection] = React.useState([]);
+
+    //  Command Bar  ---
+    const buttons: ICommandBarItemProps[] = [
+        { key: "errors", onRender: () => <Checkbox defaultChecked label={`${filterCounts.error || 0} ${nlsHPCC.Errors}`} onChange={(ev, value) => setErrorChecked(value)} styles={{ root: { paddingTop: 8, paddingRight: 8 } }} /> },
+        { key: "warnings", onRender: () => <Checkbox defaultChecked label={`${filterCounts.warning || 0} ${nlsHPCC.Warnings}`} onChange={(ev, value) => setWarningChecked(value)} styles={{ root: { paddingTop: 8, paddingRight: 8 } }} /> },
+        { key: "infos", onRender: () => <Checkbox defaultChecked label={`${filterCounts.info || 0} ${nlsHPCC.Infos}`} onChange={(ev, value) => setInfoChecked(value)} styles={{ root: { paddingTop: 8, paddingRight: 8 } }} /> },
+        { key: "others", onRender: () => <Checkbox defaultChecked label={`${filterCounts.other || 0} ${nlsHPCC.Others}`} onChange={(ev, value) => setOtherChecked(value)} styles={{ root: { paddingTop: 8, paddingRight: 8 } }} /> }
+    ];
+
+    const rightButtons: ICommandBarItemProps[] = [
+        ...createCopyDownloadSelection(grid, selection, "errorwarnings.csv")
+    ];
+
+    //  Grid ---
+    const gridStore = useConst(new Observable(new Memory("id")));
+    const gridColumns = useConst({
+        Severity: {
+            label: nlsHPCC.Severity, field: "", width: 72, sortable: false,
+            renderCell: function (object, value, node, options) {
+                switch (value) {
+                    case "Error":
+                        domClass.add(node, "ErrorCell");
+                        break;
+                    case "Alert":
+                        domClass.add(node, "AlertCell");
+                        break;
+                    case "Warning":
+                        domClass.add(node, "WarningCell");
+                        break;
+                }
+                node.innerText = value;
+            }
+        },
+        Source: { label: nlsHPCC.Source, field: "", width: 144, sortable: false },
+        Code: { label: nlsHPCC.Code, field: "", width: 45, sortable: false },
+        Message: {
+            label: nlsHPCC.Message, field: "",
+            sortable: false,
+            formatter: function (Message, idx) {
+                const info = extractGraphInfo(Message);
+                if (info.graphID && info.subgraphID && info.activityID) {
+                    const txt = "Graph " + info.graphID + "[" + info.subgraphID + "], " + info.activityName + "[" + info.activityID + "]";
+                    Message = Message.replace(txt, "<a href='#' onClick='return false;' class='dgrid-row-url'>" + txt + "</a>");
+                } else if (info.graphID && info.subgraphID) {
+                    const txt = "Graph " + info.graphID + "[" + info.subgraphID + "]";
+                    Message = Message.replace(txt, "<a href='#' onClick='return false;' class='dgrid-row-url'>" + txt + "</a>");
+                } else {
+                    Message = Utility.xmlEncode2(Message);
+                }
+                return Message;
+            }
+        },
+        Column: { label: nlsHPCC.Col, field: "", width: 36, sortable: false },
+        LineNo: { label: nlsHPCC.Line, field: "", width: 36, sortable: false },
+        FileName: { label: nlsHPCC.FileName, field: "", width: 360, sortable: false }
+    });
+
+    const refreshTable = (clearSelection = false) => {
+        grid?.set("query", {});
+        if (clearSelection) {
+            grid?.clearSelection();
+        }
+    };
+
+    React.useEffect(() => {
+        const filterCounts = {
+            error: 0,
+            warning: 0,
+            info: 0,
+            other: 0
+        };
+        const filteredExceptions = exceptions.map((row, idx) => {
+            switch (row.Severity) {
+                case "Error":
+                    filterCounts.error++;
+                    break;
+                case "Warning":
+                    filterCounts.warning++;
+                    break;
+                case "Info":
+                    filterCounts.info++;
+                    break;
+                default:
+                    filterCounts.other++;
+                    break;
+            }
+            return {
+                id: idx,
+                ...row
+            };
+        }).filter(row => {
+            if (!errorChecked && row.Severity === "Error") {
+                return false;
+            } else if (!warningChecked && row.Severity === "Warning") {
+                return false;
+            } else if (!infoChecked && row.Severity === "Info") {
+                return false;
+            } else if (!otherChecked && row.Severity !== "Error" && row.Severity !== "Warning" && row.Severity !== "Info") {
+                return false;
+            }
+            return true;
+        }).sort((l, r) => {
+            if (l.Severity === r.Severity) {
+                return 0;
+            } else if (l.Severity === "Error") {
+                return -1;
+            } else if (r.Severity === "Error") {
+                return 1;
+            } else if (l.Severity === "Alert") {
+                return -1;
+            } else if (r.Severity === "Alert") {
+                return 1;
+            } else if (l.Severity === "Warning") {
+                return -1;
+            } else if (r.Severity === "Warning") {
+                return 1;
+            }
+            return l.Severity.localeCompare(r.Severity);
+        });
+        gridStore.setData(filteredExceptions);
+        refreshTable();
+        setFilterCounts(filterCounts);
+        // eslint-disable-next-line react-hooks/exhaustive-deps
+    }, [gridStore, exceptions, errorChecked, warningChecked, infoChecked, otherChecked]);
+
+    return <HolyGrail
+        header={<CommandBar items={buttons} overflowButtonProps={{}} farItems={rightButtons} />}
+        main={
+            <DojoGrid type={"SimpleGrid"} store={gridStore} query={{}} sort={{}} columns={gridColumns} setGrid={setGrid} setSelection={setSelection} />
+        }
+    />;
+};
diff --git a/esp/src/src-react/components/Queries.tsx b/esp/src/src-react/components/Queries.tsx
index 9620282bd..db9091a0f 100644
--- a/esp/src/src-react/components/Queries.tsx
+++ b/esp/src/src-react/components/Queries.tsx
@@ -7,8 +7,9 @@ import * as Utility from "src/Utility";
 import nlsHPCC from "src/nlsHPCC";
 import { HolyGrail } from "../layouts/HolyGrail";
 import { pushParams } from "../util/history";
-import { Fields, Filter } from "./Filter";
-import { ShortVerticalDivider } from "./Common";
+import { Fields } from "./forms/Fields";
+import { Filter } from "./forms/Filter";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid, selector } from "./DojoGrid";
 
 const FilterFields: Fields = {
@@ -23,14 +24,20 @@ const FilterFields: Fields = {
     "Activated": { type: "queries-active-state", label: nlsHPCC.Activated }
 };
 
-function formatQuery(filter) {
+function formatQuery(filter: any, wuid?: string) {
+    if (wuid !== undefined) {
+        return {
+            WUID: wuid
+        };
+    }
+    const retVal = { ...filter };
     if (filter.StartDate) {
-        filter.StartDate = new Date(filter.StartDate).toISOString();
+        retVal.StartDate = new Date(filter.StartDate).toISOString();
     }
     if (filter.EndDate) {
-        filter.EndDate = new Date(filter.StartDate).toISOString();
+        retVal.EndDate = new Date(filter.StartDate).toISOString();
     }
-    return filter;
+    return retVal;
 }
 
 const defaultUIState = {
@@ -42,6 +49,7 @@ const defaultUIState = {
 };
 
 interface QueriesProps {
+    wuid?: string;
     filter?: object;
     store?: any;
 }
@@ -49,6 +57,7 @@ interface QueriesProps {
 const emptyFilter = {};
 
 export const Queries: React.FunctionComponent<QueriesProps> = ({
+    wuid,
     filter = emptyFilter,
     store
 }) => {
@@ -106,7 +115,7 @@ export const Queries: React.FunctionComponent<QueriesProps> = ({
         },
         { key: "divider_3", itemType: ContextualMenuItemType.Divider, onRender: () => <ShortVerticalDivider /> },
         {
-            key: "filter", text: nlsHPCC.Filter, disabled: !!store, iconProps: { iconName: "Filter" },
+            key: "filter", text: nlsHPCC.Filter, disabled: store !== undefined || wuid !== undefined, iconProps: { iconName: "Filter" },
             onClick: () => {
                 setShowFilter(true);
             }
@@ -120,24 +129,12 @@ export const Queries: React.FunctionComponent<QueriesProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: !uiState.hasSelection || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                const wuids = selection.map(s => s.Wuid);
-                navigator?.clipboard?.writeText(wuids.join("\n"));
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: !uiState.hasSelection, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                Utility.downloadToCSV(grid, selection.map(row => ([row.Protected, row.Wuid, row.Owner, row.Jobname, row.Cluster, row.RoxieCluster, row.State, row.TotalClusterTime])), "workunits.csv");
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "roxiequeries.csv")
     ];
 
     //  Grid ---
     const gridStore = useConst(store || ESPQuery.CreateQueryStore({}));
-    const gridQuery = useConst(formatQuery(filter));
+    const gridQuery = useConst(formatQuery(filter, wuid));
     const gridSort = useConst([{ attribute: "Id" }]);
     const gridColumns = useConst({
         col1: selector({
@@ -235,7 +232,7 @@ export const Queries: React.FunctionComponent<QueriesProps> = ({
     });
 
     const refreshTable = (clearSelection = false) => {
-        grid?.set("query", formatQuery(filter));
+        grid?.set("query", formatQuery(filter, wuid));
         if (clearSelection) {
             grid?.clearSelection();
         }
diff --git a/esp/src/src-react/components/Resources.tsx b/esp/src/src-react/components/Resources.tsx
new file mode 100644
index 000000000..8e86093fc
--- /dev/null
+++ b/esp/src/src-react/components/Resources.tsx
@@ -0,0 +1,129 @@
+import * as React from "react";
+import { CommandBar, ContextualMenuItemType, ICommandBarItemProps } from "@fluentui/react";
+import { useConst } from "@fluentui/react-hooks";
+import { AlphaNumSortMemory } from "src/Memory";
+import * as Observable from "dojo/store/Observable";
+import nlsHPCC from "src/nlsHPCC";
+import { useWorkunitResources } from "../hooks/Workunit";
+import { HolyGrail } from "../layouts/HolyGrail";
+import { ShortVerticalDivider } from "./Common";
+import { DojoGrid, selector } from "./DojoGrid";
+
+const defaultUIState = {
+    hasSelection: false
+};
+
+interface ResourcesProps {
+    wuid: string;
+}
+
+export const Resources: React.FunctionComponent<ResourcesProps> = ({
+    wuid
+}) => {
+
+    const [grid, setGrid] = React.useState<any>(undefined);
+    const [selection, setSelection] = React.useState([]);
+    const [uiState, setUIState] = React.useState({ ...defaultUIState });
+    const [resources] = useWorkunitResources(wuid);
+
+    //  Command Bar  ---
+    const buttons: ICommandBarItemProps[] = [
+        {
+            key: "refresh", text: nlsHPCC.Refresh, iconProps: { iconName: "Refresh" },
+            onClick: () => refreshTable()
+        },
+        { key: "divider_1", itemType: ContextualMenuItemType.Divider, onRender: () => <ShortVerticalDivider /> },
+        {
+            key: "open", text: nlsHPCC.Open, disabled: !uiState.hasSelection, iconProps: { iconName: "WindowEdit" },
+            onClick: () => {
+                if (selection.length === 1) {
+                    window.location.href = `#/iframe?src=${encodeURIComponent(`WsWorkunits/${selection[0].URL}`)}`;
+                } else {
+                    for (let i = selection.length - 1; i >= 0; --i) {
+                        window.open(`#/iframe?src=${encodeURIComponent(`WsWorkunits/${selection[i].URL}`)}`, "_blank");
+                    }
+                }
+            }
+        },
+        {
+            key: "content", text: nlsHPCC.Content, disabled: !uiState.hasSelection, iconProps: { iconName: "WindowEdit" },
+            onClick: () => {
+                if (selection.length === 1) {
+                    window.location.href = `#/text?src=${encodeURIComponent(`WsWorkunits/${selection[0].URL}`)}`;
+                } else {
+                    for (let i = selection.length - 1; i >= 0; --i) {
+                        window.open(`#/text?src=${encodeURIComponent(`WsWorkunits/${selection[i].URL}`)}`, "_blank");
+                    }
+                }
+            }
+        },
+    ];
+
+    const rightButtons: ICommandBarItemProps[] = [
+        {
+            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: true, iconOnly: true, iconProps: { iconName: "Copy" },
+            onClick: () => {
+                //  TODO:  HPCC-25473
+            }
+        },
+        {
+            key: "download", text: nlsHPCC.DownloadToCSV, disabled: true, iconOnly: true, iconProps: { iconName: "Download" },
+            onClick: () => {
+                //  TODO:  HPCC-25473
+            }
+        }
+    ];
+
+    //  Grid ---
+    const gridStore = useConst(new Observable(new AlphaNumSortMemory("DisplayPath", { Name: true, Value: true })));
+    const gridQuery = useConst({});
+    const gridSort = useConst([{ attribute: "Wuid", "descending": true }]);
+    const gridColumns = useConst({
+        col1: selector({
+            width: 27,
+            selectorType: "checkbox"
+        }),
+        DisplayPath: {
+            label: nlsHPCC.Name, sortable: true,
+            formatter: function (url, row) {
+                return `<a href='#/iframe?src=${encodeURIComponent(`WsWorkunits/${row.URL}`)}' class='dgrid-row-url'>${url}</a>`;
+            }
+        }
+    });
+
+    const refreshTable = (clearSelection = false) => {
+        grid?.set("query", gridQuery);
+        if (clearSelection) {
+            grid?.clearSelection();
+        }
+    };
+
+    //  Selection  ---
+    React.useEffect(() => {
+        const state = { ...defaultUIState };
+
+        for (let i = 0; i < selection.length; ++i) {
+            state.hasSelection = true;
+            break;
+        }
+        setUIState(state);
+    }, [selection]);
+
+    React.useEffect(() => {
+        gridStore.setData(resources.filter((row, idx) => idx > 0).map(row => {
+            return {
+                URL: row,
+                DisplayPath: row.substring(`res/${wuid}/`.length)
+            };
+        }));
+        refreshTable();
+        // eslint-disable-next-line react-hooks/exhaustive-deps
+    }, [gridStore, resources]);
+
+    return <HolyGrail
+        header={<CommandBar items={buttons} overflowButtonProps={{}} farItems={rightButtons} />}
+        main={
+            <DojoGrid store={gridStore} query={gridQuery} sort={gridSort} columns={gridColumns} setGrid={setGrid} setSelection={setSelection} />
+        }
+    />;
+};
diff --git a/esp/src/src-react/components/Result.tsx b/esp/src/src-react/components/Result.tsx
new file mode 100644
index 000000000..ea54abbf9
--- /dev/null
+++ b/esp/src/src-react/components/Result.tsx
@@ -0,0 +1,305 @@
+import * as React from "react";
+import * as ReactDOM from "react-dom";
+import { Checkbox, CommandBar, ContextualMenuItemType, DefaultButton, Dialog, DialogFooter, DialogType, ICommandBarItemProps, PrimaryButton, SpinButton, Stack } from "@fluentui/react";
+import { useConst } from "@fluentui/react-hooks";
+import { Result as CommsResult, XSDXMLNode } from "@hpcc-js/comms";
+import { WUResult } from "@hpcc-js/eclwatch";
+import nlsHPCC from "src/nlsHPCC";
+import { ESPBase } from "src/ESPBase";
+import { csvEncode } from "src/Utility";
+import { HolyGrail } from "../layouts/HolyGrail";
+import { pushParams } from "../util/history";
+import { AutosizeHpccJSComponent } from "../layouts/HpccJSAdapter";
+import { ShortVerticalDivider } from "./Common";
+import { Fields } from "./forms/Fields";
+import { Filter } from "./forms/Filter";
+
+import "srcReact/components/DojoGrid.css";
+
+function eclTypeTPL(type: string, isSet: boolean) {
+    const prefix = isSet ? "SET OF " : "";
+    switch (type) {
+        case "xs:boolean":
+            return prefix + "BOOLEAN";
+        case "xs:integer":
+            return prefix + "INTEGER";
+        case "xs:nonNegativeInteger":
+            return prefix + "UNSIGNED INTEGER";
+        case "xs:real":
+            return prefix + "REAL";
+        case "xs:string":
+            return prefix + "VARSTRING";
+        case "xs:hexBinary":
+            return prefix + "DATA";
+        default:
+            return prefix + type.toUpperCase();
+    }
+}
+
+function valueTPL(value: string | number | boolean) {
+    switch (typeof value) {
+        case "string":
+            return `'${value.split("'").join("\\'").trimRight()}'`;
+        case "number":
+            return value;
+        case "boolean":
+            return value === true ? "TRUE" : "FALSE";
+    }
+}
+function rowTPL(row: object) {
+    return `{${Object.values(row).map(field => {
+        if (field.Item) {
+            return `[${field.Item.map(valueTPL).join(", ")}]`;
+        }
+        return valueTPL(field);
+    }).join(", ")}}`;
+}
+
+function eclRowsTPL(row: object[], prefix = "    ") {
+    return row.map(row => `${prefix}${rowTPL(row)}`).join(",\n");
+}
+
+function copyECLRowsTPL(fields: XSDXMLNode[], row: object[]) {
+    return `
+r := RECORD
+${fields.map(f => `    ${eclTypeTPL(f.type, f.isSet)} ${f.name};`).join("\n")}
+END;
+
+d := DATASET([
+${eclRowsTPL(row)}
+], r);
+`;
+}
+
+interface DownloadDialogProps {
+    totalRows: number;
+    column: boolean;
+    onClose: (rowsToDownload: number, dedup: boolean) => void;
+}
+
+const DownloadDialog: React.FunctionComponent<DownloadDialogProps> = ({
+    totalRows,
+    column = false,
+    onClose,
+}) => {
+    const dialogContentProps = {
+        type: DialogType.largeHeader,
+        title: "Download Results",
+        subText: `Confirm total number of rows to download(max ${totalRows} rows).`,
+    };
+    const stackTokens = { childrenGap: 10 };
+
+    const [hideDialog, setHideDialog] = React.useState(false);
+    const handleOk = () => {
+        setHideDialog(true);
+        onClose(downloadTotal, dedup);
+    };
+    const handleCancel = () => {
+        setHideDialog(true);
+        onClose(0, dedup);
+    };
+
+    const [downloadTotal, setDownloadTotal] = React.useState(totalRows);
+    const onDownloadTotalValidate = (value: string) => {
+        let v: number = parseInt(value);
+        if (isNaN(v)) {
+            v = totalRows;
+        } else if (v < 0) {
+            v = 0;
+        } else if (v > totalRows) {
+            v = totalRows;
+        }
+        setDownloadTotal(v);
+        return String(v);
+    };
+
+    const [dedup] = React.useState(true);
+    const onDedup = (ev: React.FormEvent<HTMLElement>, isChecked: boolean) => {
+    };
+
+    return <Dialog
+        hidden={hideDialog}
+        onDismiss={handleCancel}
+        dialogContentProps={dialogContentProps}
+    >
+        <Stack tokens={stackTokens}>
+            <SpinButton
+                defaultValue={`${totalRows} `}
+                label={"Download:"}
+                min={0}
+                max={totalRows}
+                step={1}
+                incrementButtonAriaLabel={"Increase value by 1"}
+                decrementButtonAriaLabel={"Decrease value by 1"}
+                onValidate={onDownloadTotalValidate}
+            />
+            {column ?
+                <Checkbox label="De-duplicate" boxSide="end" defaultChecked onChange={onDedup} /> :
+                undefined}
+        </Stack>
+        <DialogFooter>
+            <PrimaryButton onClick={handleOk} text="Ok" />
+            <DefaultButton onClick={handleCancel} text="Cancel" />
+        </DialogFooter>
+    </Dialog>;
+};
+
+class ResultWidget extends WUResult {
+
+    reset() {
+        delete this._prevResultHash;
+        delete this._prevStoreHash;
+        delete this._prevQueryHash;
+    }
+
+    confirmDownload(column: boolean = false): Promise<{ downloadTotal: number, dedup: boolean }> {
+        if (!column && this._result.Total <= 1000) return Promise.resolve({ downloadTotal: this._result.Total, dedup: false });
+        return new Promise(resolve => {
+            const element = document.createElement("div");
+            ReactDOM.render(<DownloadDialog
+                totalRows={this._result.Total}
+                column={column}
+                onClose={(downloadTotal, dedup) => resolve({ downloadTotal, dedup })}
+            />, element);
+        });
+    }
+
+    async copyAsCSV() {
+        const copyCSVHeaderTPL = (fields: XSDXMLNode[]) => `${fields.map(f => `${csvEncode(f.name)}`).join("\t")}`;
+        const copyCSVRowTPL = (row: object) => `${Object.values(row).map(cell => `${csvEncode(cell)}`).join("\t")}`;
+        const copyCSVRowsTPL = (rows: object[]) => `${rows.map(copyCSVRowTPL).join("\n")}`;
+
+        const { downloadTotal } = await this.confirmDownload();
+        if (downloadTotal > 0) {
+            this.fetch(0, downloadTotal).then(rows => {
+                const tsv = `\
+${copyCSVHeaderTPL(this._result.fields())}
+${copyCSVRowsTPL(rows)} \
+`;
+                navigator?.clipboard?.writeText(tsv);
+            });
+        }
+    }
+
+    async copyAsECL() {
+        const { downloadTotal } = await this.confirmDownload();
+        if (downloadTotal > 0) {
+            this.fetch(0, downloadTotal).then(rows => {
+                const tsv = copyECLRowsTPL(this._result.fields(), rows);
+                navigator?.clipboard?.writeText(tsv);
+            });
+        }
+    }
+}
+
+function doDownload(type: string, wuid: string, sequence?: number, logicalName?: string) {
+    const base = new ESPBase();
+    if (sequence !== undefined) {
+        window.open(base.getBaseURL() + "/WUResultBin?Format=" + type + "&Wuid=" + wuid + "&Sequence=" + sequence, "_blank");
+    } else if (logicalName !== undefined) {
+        window.open(base.getBaseURL() + "/WUResultBin?Format=" + type + "&LogicalName=" + logicalName, "_blank");
+    }
+}
+
+interface ResultProps {
+    wuid: string;
+    resultName: string;
+    filter?: { [key: string]: any };
+}
+
+const emptyFilter: { [key: string]: any } = {};
+
+export const Result: React.FunctionComponent<ResultProps> = ({
+    wuid,
+    resultName,
+    filter = emptyFilter
+}) => {
+
+    const resultTable: ResultWidget = useConst(new ResultWidget()
+        .baseUrl("")
+        .wuid(wuid)
+        .resultName(resultName)
+        .pagination(true)
+        .pageSize(50) as ResultWidget
+    );
+
+    resultTable
+        .filter(filter)
+        .lazyRender()
+        ;
+
+    const [result] = React.useState<CommsResult>(resultTable.calcResult());
+    const [FilterFields, setFilterFields] = React.useState<Fields>({});
+    const [showFilter, setShowFilter] = React.useState(false);
+
+    React.useEffect(() => {
+        result?.fetchXMLSchema().then(() => {
+            const filterFields: Fields = {};
+            const fields = result.fields();
+            fields.forEach(field => {
+                filterFields[field.name] = {
+                    type: "string",
+                    label: field.name
+                };
+            });
+            setFilterFields(filterFields);
+        });
+    }, [result]);
+
+    //  Command Bar  ---
+    const buttons: ICommandBarItemProps[] = [
+        {
+            key: "refresh", text: nlsHPCC.Refresh, iconProps: { iconName: "Refresh" },
+            onClick: () => {
+                resultTable.reset();
+                resultTable.lazyRender();
+            }
+        },
+        { key: "divider_1", itemType: ContextualMenuItemType.Divider, onRender: () => <ShortVerticalDivider /> },
+        {
+            key: "filter", text: nlsHPCC.Filter, iconProps: { iconName: "Filter" },
+            onClick: () => {
+                setShowFilter(true);
+            }
+        },
+    ];
+
+    //  Filter  ---
+    const filterFields: Fields = {};
+    for (const fieldID in FilterFields) {
+        filterFields[fieldID] = { ...FilterFields[fieldID], value: filter[fieldID] };
+    }
+
+    const rightButtons: ICommandBarItemProps[] = [
+        {
+            key: "copy", text: nlsHPCC.CopyWUIDs, iconOnly: true, iconProps: { iconName: "Copy" },
+            subMenuProps: {
+                items: [
+                    { key: "tsv", text: nlsHPCC.CSV, onClick: () => resultTable.copyAsCSV() },
+                    { key: "ecl", text: nlsHPCC.ECL, onClick: () => resultTable.copyAsECL() }
+                ]
+            }
+        },
+        {
+            key: "download", text: nlsHPCC.DownloadToCSV, iconOnly: true, iconProps: { iconName: "Download" },
+            subMenuProps: {
+                items: [
+                    { key: "zip", text: nlsHPCC.Zip, onClick: () => doDownload("zip", wuid, result.Sequence) },
+                    { key: "gzip", text: nlsHPCC.GZip, onClick: () => doDownload("gzip", wuid, result.Sequence) },
+                    { key: "xls", text: nlsHPCC.XLS, onClick: () => doDownload("xls", wuid, result.Sequence) },
+                    { key: "csv", text: nlsHPCC.CSV, onClick: () => doDownload("csv", wuid, result.Sequence) },
+                ]
+            }
+        }
+    ];
+
+    return <HolyGrail
+        header={<CommandBar items={buttons} overflowButtonProps={{}} farItems={rightButtons} />}
+        main={
+            <>
+                <AutosizeHpccJSComponent widget={resultTable} />
+                <Filter showFilter={showFilter} setShowFilter={setShowFilter} filterFields={filterFields} onApply={pushParams} />
+            </>
+        }
+    />;
+};
diff --git a/esp/src/src-react/components/Results.tsx b/esp/src/src-react/components/Results.tsx
index e3b869b81..a9821169e 100644
--- a/esp/src/src-react/components/Results.tsx
+++ b/esp/src/src-react/components/Results.tsx
@@ -3,11 +3,10 @@ import { CommandBar, ContextualMenuItemType, ICommandBarItemProps } from "@fluen
 import { useConst } from "@fluentui/react-hooks";
 import { AlphaNumSortMemory } from "src/Memory";
 import * as Observable from "dojo/store/Observable";
-import * as Utility from "src/Utility";
 import nlsHPCC from "src/nlsHPCC";
 import { useWorkunitResults } from "../hooks/Workunit";
 import { HolyGrail } from "../layouts/HolyGrail";
-import { ShortVerticalDivider } from "./Common";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid, selector } from "./DojoGrid";
 
 const defaultUIState = {
@@ -61,19 +60,7 @@ export const Results: React.FunctionComponent<ResultsProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: !uiState.hasSelection || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                const wuids = selection.map(s => s.Wuid);
-                navigator?.clipboard?.writeText(wuids.join("\n"));
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: !uiState.hasSelection, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                Utility.downloadToCSV(grid, selection.map(row => ([row.Protected, row.Wuid, row.Owner, row.Jobname, row.Cluster, row.RoxieCluster, row.State, row.TotalClusterTime])), "workunits.csv");
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "results.csv")
     ];
 
     //  Grid ---
diff --git a/esp/src/src-react/components/Search.tsx b/esp/src/src-react/components/Search.tsx
index 17261b6a8..e88f0066b 100644
--- a/esp/src/src-react/components/Search.tsx
+++ b/esp/src/src-react/components/Search.tsx
@@ -2,10 +2,9 @@ import * as React from "react";
 import { CommandBar, ContextualMenuItemType, ICommandBarItemProps, Pivot, PivotItem, ProgressIndicator } from "@fluentui/react";
 import { useConst } from "@fluentui/react-hooks";
 import { ESPSearch } from "src/ESPSearch";
-import * as Utility from "src/Utility";
 import nlsHPCC from "src/nlsHPCC";
 import { HolyGrail } from "../layouts/HolyGrail";
-import { ShortVerticalDivider } from "./Common";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid, selector } from "./DojoGrid";
 import { Workunits } from "./Workunits";
 import { Files } from "./Files";
@@ -84,19 +83,7 @@ export const Search: React.FunctionComponent<SearchProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: !uiState.hasSelection || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                const wuids = selection.map(s => s.Wuid);
-                navigator?.clipboard?.writeText(wuids.join("\n"));
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: !uiState.hasSelection, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                Utility.downloadToCSV(grid, selection.map(row => ([row.Protected, row.Wuid, row.Owner, row.Jobname, row.Cluster, row.RoxieCluster, row.State, row.TotalClusterTime])), "workunits.csv");
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "search.csv")
     ];
 
     //  Grid ---
@@ -151,11 +138,11 @@ export const Search: React.FunctionComponent<SearchProps> = ({
             </>}
             main={<DojoGrid store={search.store} columns={gridColumns} setGrid={setGrid} setSelection={setSelection} />}
         /> : selectedKey === "ecl" ?
-                <Workunits store={search.eclStore} /> : selectedKey === "dfu" ?
-                    <DFUWorkunits store={search.dfuStore} /> : selectedKey === "file" ?
-                        <Files store={search.fileStore} /> : selectedKey === "query" ?
-                            <Queries store={search.queryStore} /> :
-                            undefined
+            <Workunits store={search.eclStore} /> : selectedKey === "dfu" ?
+                <DFUWorkunits store={search.dfuStore} /> : selectedKey === "file" ?
+                    <Files store={search.fileStore} /> : selectedKey === "query" ?
+                        <Queries store={search.queryStore} /> :
+                        undefined
         }
     />;
 };
diff --git a/esp/src/src-react/components/SourceEditor.tsx b/esp/src/src-react/components/SourceEditor.tsx
index f61a945d5..269d63789 100644
--- a/esp/src/src-react/components/SourceEditor.tsx
+++ b/esp/src/src-react/components/SourceEditor.tsx
@@ -1,23 +1,29 @@
 import * as React from "react";
-import { CommandBar, ContextualMenuItemType, ICommandBarItemProps } from "@fluentui/react";
-import { useConst } from "@fluentui/react-hooks";
-import { XMLEditor } from "@hpcc-js/codemirror";
+import { CommandBar, ContextualMenuItemType, getTheme, ICommandBarItemProps } from "@fluentui/react";
+import { useConst, useOnEvent } from "@fluentui/react-hooks";
+import { Editor, XMLEditor } from "@hpcc-js/codemirror";
 import nlsHPCC from "src/nlsHPCC";
 import { HolyGrail } from "../layouts/HolyGrail";
 import { AutosizeHpccJSComponent } from "../layouts/HpccJSAdapter";
 import { useWorkunitXML } from "../hooks/Workunit";
+import { darkTheme } from "../themes";
 import { ShortVerticalDivider } from "./Common";
+import "codemirror/theme/darcula.css";
 
 interface SourceEditorProps {
-    text: string;
+    text?: string;
     readonly?: boolean;
+    mode?: "ecl" | "xml" | "text";
 }
 
-export const XMLSourceEditor: React.FunctionComponent<SourceEditorProps> = ({
+const SourceEditor: React.FunctionComponent<SourceEditorProps> = ({
     text = "",
-    readonly = false
+    readonly = false,
+    mode = "text"
 }) => {
 
+    const theme = getTheme();
+
     //  Command Bar  ---
     const buttons: ICommandBarItemProps[] = [
         {
@@ -29,7 +35,7 @@ export const XMLSourceEditor: React.FunctionComponent<SourceEditorProps> = ({
         { key: "divider_1", itemType: ContextualMenuItemType.Divider, onRender: () => <ShortVerticalDivider /> },
     ];
 
-    const editor = useConst(new XMLEditor());
+    const editor = useConst(mode === "text" ? new Editor() : new XMLEditor());
     React.useEffect(() => {
         editor
             .text(text)
@@ -37,7 +43,22 @@ export const XMLSourceEditor: React.FunctionComponent<SourceEditorProps> = ({
             .lazyRender()
             ;
 
-    }, [editor, readonly, text]);
+        if (theme.semanticColors.link === darkTheme.palette.themePrimary) {
+            editor.setOption("theme", "darcula");
+        }
+
+    }, [editor, readonly, text, theme.semanticColors.link]);
+
+    const handleThemeToggle = (evt) => {
+        if (!editor) return;
+        if (evt.detail && evt.detail.dark === true) {
+            editor.setOption("theme", "darcula");
+        } else {
+            editor.setOption("theme", "default");
+        }
+    };
+
+    useOnEvent(document, "eclwatch-theme-toggle", handleThemeToggle);
 
     return <HolyGrail
         header={<CommandBar items={buttons} overflowButtonProps={{}} />}
@@ -47,6 +68,32 @@ export const XMLSourceEditor: React.FunctionComponent<SourceEditorProps> = ({
     />;
 };
 
+interface TextSourceEditorProps {
+    text: string;
+    readonly?: boolean;
+}
+
+export const TextSourceEditor: React.FunctionComponent<TextSourceEditorProps> = ({
+    text = "",
+    readonly = false
+}) => {
+
+    return <SourceEditor text={text} readonly={readonly} mode="text"></SourceEditor>;
+};
+
+interface XMLSourceEditorProps {
+    text: string;
+    readonly?: boolean;
+}
+
+export const XMLSourceEditor: React.FunctionComponent<XMLSourceEditorProps> = ({
+    text = "",
+    readonly = false
+}) => {
+
+    return <SourceEditor text={text} readonly={readonly} mode="xml"></SourceEditor>;
+};
+
 export interface WUXMLSourceEditorProps {
     wuid: string;
 }
@@ -59,3 +106,50 @@ export const WUXMLSourceEditor: React.FunctionComponent<WUXMLSourceEditorProps>
 
     return <XMLSourceEditor text={xml} readonly={true} />;
 };
+
+export interface WUResourceEditorProps {
+    src: string;
+}
+
+export const WUResourceEditor: React.FunctionComponent<WUResourceEditorProps> = ({
+    src
+}) => {
+
+    const [text, setText] = React.useState("");
+
+    React.useEffect(() => {
+        fetch(src).then(response => {
+            return response.text();
+        }).then(content => {
+            setText(content);
+        });
+    }, [src]);
+
+    return <SourceEditor text={text} readonly={true} mode="text"></SourceEditor>;
+};
+
+interface FetchEditor {
+    url: string;
+    readonly?: boolean;
+    mode?: "ecl" | "xml" | "text";
+}
+
+export const FetchEditor: React.FunctionComponent<FetchEditor> = ({
+    url,
+    readonly = true,
+    mode = "text"
+}) => {
+
+    const [text, setText] = React.useState("");
+
+    React.useEffect(() => {
+        fetch(url).then(response => {
+            return response.text();
+        }).then(content => {
+            setText(content);
+        });
+    }, [url]);
+
+    return <SourceEditor text={text} readonly={readonly} mode={mode}></SourceEditor>;
+};
+
diff --git a/esp/src/src-react/components/SourceFiles.tsx b/esp/src/src-react/components/SourceFiles.tsx
index 9602dea99..910ad219f 100644
--- a/esp/src/src-react/components/SourceFiles.tsx
+++ b/esp/src/src-react/components/SourceFiles.tsx
@@ -8,7 +8,7 @@ import * as Utility from "src/Utility";
 import nlsHPCC from "src/nlsHPCC";
 import { useWorkunitSourceFiles } from "../hooks/Workunit";
 import { HolyGrail } from "../layouts/HolyGrail";
-import { ShortVerticalDivider } from "./Common";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid, selector, tree } from "./DojoGrid";
 
 const defaultUIState = {
@@ -61,19 +61,7 @@ export const SourceFiles: React.FunctionComponent<SourceFilesProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: !uiState.hasSelection || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                const wuids = selection.map(s => s.Wuid);
-                navigator?.clipboard?.writeText(wuids.join("\n"));
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: !uiState.hasSelection, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                Utility.downloadToCSV(grid, selection.map(row => ([row.Protected, row.Wuid, row.Owner, row.Jobname, row.Cluster, row.RoxieCluster, row.State, row.TotalClusterTime])), "workunits.csv");
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "sourcefiles.csv")
     ];
 
     //  Grid ---
diff --git a/esp/src/src-react/components/Title.tsx b/esp/src/src-react/components/Title.tsx
index 2fafae1fa..3736b3118 100644
--- a/esp/src/src-react/components/Title.tsx
+++ b/esp/src/src-react/components/Title.tsx
@@ -1,5 +1,6 @@
 import * as React from "react";
 import { Breadcrumb, ContextualMenuItemType, DefaultPalette, FontSizes, IBreadcrumbItem, IBreadcrumbStyleProps, IBreadcrumbStyles, IconButton, IContextualMenuProps, IIconProps, Image, IStyleFunctionOrObject, Link, SearchBox, Stack, Toggle } from "@fluentui/react";
+import { About } from "./About";
 
 import nlsHPCC from "src/nlsHPCC";
 
@@ -7,6 +8,8 @@ const breadCrumbStyles: IStyleFunctionOrObject<IBreadcrumbStyleProps, IBreadcrum
     itemLink: { fontSize: FontSizes.size10, lineHeight: 14, paddingLeft: 2, paddingRight: 2 },
 };
 
+const collapseMenuIcon: IIconProps = { iconName: "CollapseMenu" };
+
 interface DevTitleProps {
     paths: string[],
     useDarkMode: boolean,
@@ -19,6 +22,8 @@ export const DevTitle: React.FunctionComponent<DevTitleProps> = ({
     setUseDarkMode
 }) => {
 
+    const [showAbout, setShowAbout] = React.useState(false);
+
     let fullPath = "#";
     const itemsWithHref = [{ text: "HOME", key: "home", href: "#/" },
     ...paths.filter(path => !!path).map((path, idx) => {
@@ -37,25 +42,27 @@ export const DevTitle: React.FunctionComponent<DevTitleProps> = ({
             { key: "docs", href: "https://hpccsystems.com/training/documentation/", text: nlsHPCC.Documentation, target: "_blank" },
             { key: "downloads", href: "https://hpccsystems.com/download", text: nlsHPCC.Downloads, target: "_blank" },
             { key: "releaseNotes", href: "https://hpccsystems.com/download/release-notes", text: nlsHPCC.ReleaseNotes, target: "_blank" },
-            { key: "additionalResources", text: nlsHPCC.AdditionalResources, subMenuProps: {
-                items: [
-                    { key: "redBook", href: "https://wiki.hpccsystems.com/display/hpcc/HPCC+Systems+Red+Book", text: nlsHPCC.RedBook, target: "_blank" },
-                    { key: "forums", href: "https://hpccsystems.com/bb/", text: nlsHPCC.Forums, target: "_blank" },
-                    { key: "issues", href: "https://track.hpccsystems.com/issues/", text: nlsHPCC.IssueReporting, target: "_blank" },
-                ]
-            }},
+            {
+                key: "additionalResources", text: nlsHPCC.AdditionalResources, subMenuProps: {
+                    items: [
+                        { key: "redBook", href: "https://wiki.hpccsystems.com/display/hpcc/HPCC+Systems+Red+Book", text: nlsHPCC.RedBook, target: "_blank" },
+                        { key: "forums", href: "https://hpccsystems.com/bb/", text: nlsHPCC.Forums, target: "_blank" },
+                        { key: "issues", href: "https://track.hpccsystems.com/issues/", text: nlsHPCC.IssueReporting, target: "_blank" },
+                    ]
+                }
+            },
             { key: "divider_3", itemType: ContextualMenuItemType.Divider },
             { key: "lock", text: nlsHPCC.Lock },
             { key: "logout", text: nlsHPCC.Logout },
             { key: "divider_4", itemType: ContextualMenuItemType.Divider },
-            { key: "config", text: nlsHPCC.Configuration },
-            { key: "about", text: nlsHPCC.About },
+            { key: "legacy", text: nlsHPCC.OpenLegacyECLWatch, href: "/esp/files/stub.htm" },
+            { key: "divider_5", itemType: ContextualMenuItemType.Divider },
+            { key: "config", href: "#/config", text: nlsHPCC.Configuration },
+            { key: "about", text: nlsHPCC.About, onClick: () => setShowAbout(true) }
         ],
         directionalHintFixed: true
     };
 
-    const advMenuIconProps: IIconProps = { iconName: "ContextMenu" };
-
     return <>
         <Stack tokens={{ padding: 9, childrenGap: 9 }} >
             <Stack horizontal disableShrink horizontalAlign="space-between">
@@ -72,21 +79,27 @@ export const DevTitle: React.FunctionComponent<DevTitleProps> = ({
                 </Stack>
                 <Stack horizontal tokens={{ childrenGap: 18 }} >
                     <Stack.Item align="center">
-                        <Link href="/esp/files/stub.htm">Legacy ECL Watch</Link>
                         <Toggle
                             label="Change themes"
                             onText="Dark Mode"
                             offText="Light Mode"
-                            onChange={() => setUseDarkMode(!useDarkMode)}
+                            onChange={() => {
+                                setUseDarkMode(!useDarkMode);
+                                const themeChangeEvent = new CustomEvent("eclwatch-theme-toggle", {
+                                    detail: { dark: !useDarkMode }
+                                });
+                                document.dispatchEvent(themeChangeEvent);
+                            }}
                         />
                     </Stack.Item>
-                    <Stack.Item>
-                        <IconButton title="Advanced" ariaLabel="Advanced" menuProps={ advMenuProps } iconProps={ advMenuIconProps } />
+                    <Stack.Item align="center">
+                        <IconButton title={nlsHPCC.Advanced} iconProps={collapseMenuIcon} menuProps={advMenuProps} />
                     </Stack.Item>
                 </Stack>
             </Stack>
         </Stack>
         <Stack horizontal styles={{ root: { background: DefaultPalette.themeLighter } }} >
         </Stack>
+        <About show={showAbout} onClose={() => setShowAbout(false)} ></About>
     </>;
 };
diff --git a/esp/src/src-react/components/Variables.tsx b/esp/src/src-react/components/Variables.tsx
index f3d86929d..ac2e7cc95 100644
--- a/esp/src/src-react/components/Variables.tsx
+++ b/esp/src/src-react/components/Variables.tsx
@@ -3,17 +3,12 @@ import { CommandBar, ContextualMenuItemType, ICommandBarItemProps } from "@fluen
 import { useConst } from "@fluentui/react-hooks";
 import * as Observable from "dojo/store/Observable";
 import { AlphaNumSortMemory } from "src/Memory";
-import * as Utility from "src/Utility";
 import nlsHPCC from "src/nlsHPCC";
 import { useWorkunitVariables } from "../hooks/Workunit";
 import { HolyGrail } from "../layouts/HolyGrail";
-import { ShortVerticalDivider } from "./Common";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid } from "./DojoGrid";
 
-const defaultUIState = {
-    hasSelection: false
-};
-
 interface VariablesProps {
     wuid: string;
 }
@@ -24,7 +19,6 @@ export const Variables: React.FunctionComponent<VariablesProps> = ({
 
     const [grid, setGrid] = React.useState<any>(undefined);
     const [selection, setSelection] = React.useState([]);
-    const [uiState, setUIState] = React.useState({ ...defaultUIState });
     const [variables] = useWorkunitVariables(wuid);
 
     //  Command Bar  ---
@@ -37,19 +31,7 @@ export const Variables: React.FunctionComponent<VariablesProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: !uiState.hasSelection || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                const wuids = selection.map(s => s.Wuid);
-                navigator?.clipboard?.writeText(wuids.join("\n"));
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: !uiState.hasSelection, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                Utility.downloadToCSV(grid, selection.map(row => ([row.Protected, row.Wuid, row.Owner, row.Jobname, row.Cluster, row.RoxieCluster, row.State, row.TotalClusterTime])), "workunits.csv");
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "variables.csv")
     ];
 
     //  Grid ---
@@ -68,17 +50,6 @@ export const Variables: React.FunctionComponent<VariablesProps> = ({
         }
     };
 
-    //  Selection  ---
-    React.useEffect(() => {
-        const state = { ...defaultUIState };
-
-        for (let i = 0; i < selection.length; ++i) {
-            state.hasSelection = true;
-            break;
-        }
-        setUIState(state);
-    }, [selection]);
-
     React.useEffect(() => {
         gridStore.setData(variables.map((row, idx) => {
             return {
diff --git a/esp/src/src-react/components/Workflows.tsx b/esp/src/src-react/components/Workflows.tsx
index b47d36120..a4d99a28e 100644
--- a/esp/src/src-react/components/Workflows.tsx
+++ b/esp/src/src-react/components/Workflows.tsx
@@ -6,7 +6,7 @@ import * as Observable from "dojo/store/Observable";
 import nlsHPCC from "src/nlsHPCC";
 import { useWorkunitWorkflows } from "../hooks/Workunit";
 import { HolyGrail } from "../layouts/HolyGrail";
-import { ShortVerticalDivider } from "./Common";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid } from "./DojoGrid";
 
 interface WorkflowsProps {
@@ -18,7 +18,7 @@ export const Workflows: React.FunctionComponent<WorkflowsProps> = ({
 }) => {
 
     const [grid, setGrid] = React.useState<any>(undefined);
-    const [, setSelection] = React.useState([]);
+    const [selection, setSelection] = React.useState([]);
     const [workflows, , refreshWorkflow] = useWorkunitWorkflows(wuid);
 
     //  Command Bar  ---
@@ -33,18 +33,7 @@ export const Workflows: React.FunctionComponent<WorkflowsProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.Copy, disabled: true, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                //  TODO: See HPCC-25473 
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: true, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                //  TODO: See HPCC-25473 
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "workflows.csv")
     ];
 
     //  Grid ---
diff --git a/esp/src/src-react/components/WorkunitDetails.tsx b/esp/src/src-react/components/WorkunitDetails.tsx
index 86d48dad3..4031eeb64 100644
--- a/esp/src/src-react/components/WorkunitDetails.tsx
+++ b/esp/src/src-react/components/WorkunitDetails.tsx
@@ -13,7 +13,11 @@ import { ShortVerticalDivider } from "./Common";
 import { Results } from "./Results";
 import { Variables } from "./Variables";
 import { SourceFiles } from "./SourceFiles";
-import { Details } from "./Details";
+import { TableGroup } from "./forms/Groups";
+import { Helpers } from "./Helpers";
+import { InfoGrid } from "./InfoGrid";
+import { Queries } from "./Queries";
+import { Resources } from "./Resources";
 import { WUXMLSourceEditor } from "./SourceEditor";
 import { Workflows } from "./Workflows";
 
@@ -57,20 +61,6 @@ const pivotItemStyle = (size, padding: number = 4) => {
     return { position: "absolute", padding: `${padding}px`, overflow: "auto", zIndex: 0, width: size.width - padding * 2, height: size.height - 45 - padding * 2 } as React.CSSProperties;
 };
 
-interface InfoGridProps {
-    wuid: string;
-    dimensions?: any;
-}
-
-const InfoGrid: React.FunctionComponent<InfoGridProps> = ({
-    wuid,
-    dimensions
-}) => {
-    return <div className="pane-content" style={{ height: dimensions.height }}>
-        <DojoAdapter widgetClassID="InfoGridWidget" params={{ Wuid: wuid }} delayProps={{ showToolbar: true }} />
-    </div>;
-};
-
 interface WorkunitDetailsProps {
     wuid: string;
     tab?: string;
@@ -130,9 +120,10 @@ export const WorkunitDetails: React.FunctionComponent<WorkunitDetailsProps> = ({
     const protectedImage = getImageURL(workunit?.Protected ? "locked.png" : "unlocked.png");
     const stateIconClass = getStateIconClass(workunit?.StateID, workunit?.isComplete(), workunit?.Archived);
     const serviceNames = workunit?.ServiceNames?.Item?.join("\n") || "";
+    const resourceCount = workunit?.ResourceURLCount > 1 ? workunit?.ResourceURLCount - 1 : undefined;
 
     return <SizeMe monitorHeight>{({ size }) =>
-        <Pivot overflowBehavior="menu" style={{ height: "100%" }} defaultSelectedKey={tab} onLinkClick={evt => pushUrl(`/workunits/${wuid}/${evt.props.itemKey}`)}>
+        <Pivot overflowBehavior="menu" style={{ height: "100%" }} selectedKey={tab} onLinkClick={evt => pushUrl(`/workunits/${wuid}/${evt.props.itemKey}`)}>
             <PivotItem headerText={wuid} itemKey="summary" style={pivotItemStyle(size)}>
                 <div style={{ height: "100%", position: "relative" }}>
                     <ReflexContainer orientation="horizontal">
@@ -152,7 +143,7 @@ export const WorkunitDetails: React.FunctionComponent<WorkunitDetailsProps> = ({
                                             <WUStatus wuid={wuid}></WUStatus>
                                         </div>
                                     </Sticky>
-                                    <Details fields={{
+                                    <TableGroup fields={{
                                         "wuid": { label: nlsHPCC.WUID, type: "string", value: wuid, readonly: true },
                                         "action": { label: nlsHPCC.Action, type: "string", value: workunit?.ActionEx, readonly: true },
                                         "state": { label: nlsHPCC.State, type: "string", value: workunit?.State, readonly: true },
@@ -186,8 +177,8 @@ export const WorkunitDetails: React.FunctionComponent<WorkunitDetailsProps> = ({
                         <ReflexSplitter style={{ position: "relative", height: "5px", backgroundColor: "transparent", borderStyle: "none" }}>
                             <div className={classNames.reflexSplitterDiv}></div>
                         </ReflexSplitter>
-                        <ReflexElement propagateDimensions={true} className={classNames.reflexPane}>
-                            <InfoGrid wuid={wuid} />
+                        <ReflexElement propagateDimensions={true} className={classNames.reflexPane} style={{ overflow: "hidden" }}>
+                            <InfoGrid wuid={wuid}></InfoGrid>
                         </ReflexElement>
                     </ReflexContainer>
                 </div>
@@ -211,13 +202,13 @@ export const WorkunitDetails: React.FunctionComponent<WorkunitDetailsProps> = ({
                 <Workflows wuid={wuid} />
             </PivotItem>
             <PivotItem headerText={nlsHPCC.Queries} itemIcon="Search" itemKey="queries" style={pivotItemStyle(size, 0)}>
-                <DojoAdapter widgetClassID="QuerySetQueryWidget" params={{ Wuid: wuid }} />
+                <Queries wuid={wuid} />
             </PivotItem>
-            <PivotItem headerText={nlsHPCC.Resources} itemKey="resources" style={pivotItemStyle(size, 0)}>
-                <DojoAdapter widgetClassID="ResourcesWidget" params={{ Wuid: wuid }} />
+            <PivotItem headerText={nlsHPCC.Resources} itemKey="resources" itemCount={resourceCount} style={pivotItemStyle(size, 0)}>
+                <Resources wuid={wuid} />
             </PivotItem>
             <PivotItem headerText={nlsHPCC.Helpers} itemKey="helpers" itemCount={workunit?.HelpersCount} style={pivotItemStyle(size, 0)}>
-                <DojoAdapter widgetClassID="HelpersWidget" params={{ Wuid: wuid }} />
+                <Helpers wuid={wuid} />
             </PivotItem>
             <PivotItem headerText={nlsHPCC.ECL} itemKey="eclsummary" style={pivotItemStyle(size, 0)}>
                 <DojoAdapter widgetClassID="ECLArchiveWidget" params={{ Wuid: wuid }} />
diff --git a/esp/src/src-react/components/Workunits.tsx b/esp/src/src-react/components/Workunits.tsx
index 988e0b8df..7be4e4bd1 100644
--- a/esp/src/src-react/components/Workunits.tsx
+++ b/esp/src/src-react/components/Workunits.tsx
@@ -8,8 +8,9 @@ import * as Utility from "src/Utility";
 import nlsHPCC from "src/nlsHPCC";
 import { HolyGrail } from "../layouts/HolyGrail";
 import { pushParams } from "../util/history";
-import { Fields, Filter } from "./Filter";
-import { ShortVerticalDivider } from "./Common";
+import { Fields } from "./forms/Fields";
+import { Filter } from "./forms/Filter";
+import { createCopyDownloadSelection, ShortVerticalDivider } from "./Common";
 import { DojoGrid, selector } from "./DojoGrid";
 
 const FilterFields: Fields = {
@@ -17,8 +18,8 @@ const FilterFields: Fields = {
     "Wuid": { type: "string", label: nlsHPCC.WUID, placeholder: "W20200824-060035" },
     "Owner": { type: "string", label: nlsHPCC.Owner, placeholder: nlsHPCC.jsmi },
     "Jobname": { type: "string", label: nlsHPCC.JobName, placeholder: nlsHPCC.log_analysis_1 },
-    "Cluster": { type: "target-cluster", label: nlsHPCC.Cluster, placeholder: nlsHPCC.Owner },
-    "State": { type: "workunit-state", label: nlsHPCC.State, placeholder: nlsHPCC.Created },
+    "Cluster": { type: "target-cluster", label: nlsHPCC.Cluster, placeholder: "" },
+    "State": { type: "workunit-state", label: nlsHPCC.State, placeholder: "" },
     "ECL": { type: "string", label: nlsHPCC.ECL, placeholder: nlsHPCC.dataset },
     "LogicalFile": { type: "string", label: nlsHPCC.LogicalFile, placeholder: nlsHPCC.somefile },
     "LogicalFileSearchType": { type: "logicalfile-type", label: nlsHPCC.LogicalFileType, placeholder: "", disabled: (params: Fields) => !params.LogicalFile.value },
@@ -137,19 +138,7 @@ export const Workunits: React.FunctionComponent<WorkunitsProps> = ({
     ];
 
     const rightButtons: ICommandBarItemProps[] = [
-        {
-            key: "copy", text: nlsHPCC.CopyWUIDs, disabled: !uiState.hasSelection || !navigator?.clipboard?.writeText, iconOnly: true, iconProps: { iconName: "Copy" },
-            onClick: () => {
-                const wuids = selection.map(s => s.Wuid);
-                navigator?.clipboard?.writeText(wuids.join("\n"));
-            }
-        },
-        {
-            key: "download", text: nlsHPCC.DownloadToCSV, disabled: !uiState.hasSelection, iconOnly: true, iconProps: { iconName: "Download" },
-            onClick: () => {
-                Utility.downloadToCSV(grid, selection.map(row => ([row.Protected, row.Wuid, row.Owner, row.Jobname, row.Cluster, row.RoxieCluster, row.State, row.TotalClusterTime])), "workunits.csv");
-            }
-        }
+        ...createCopyDownloadSelection(grid, selection, "workunits.csv")
     ];
 
     //  Grid ---
@@ -204,8 +193,8 @@ export const Workunits: React.FunctionComponent<WorkunitsProps> = ({
 
     //  Filter  ---
     const filterFields: Fields = {};
-    for (const field in FilterFields) {
-        filterFields[field] = { ...FilterFields[field], value: filter[field] };
+    for (const fieldID in FilterFields) {
+        filterFields[fieldID] = { ...FilterFields[fieldID], value: filter[fieldID] };
     }
 
     React.useEffect(() => {
diff --git a/esp/src/src-react/components/WorkunitsDashboard.tsx b/esp/src/src-react/components/WorkunitsDashboard.tsx
index 01afb3237..2e91530a3 100644
--- a/esp/src/src-react/components/WorkunitsDashboard.tsx
+++ b/esp/src/src-react/components/WorkunitsDashboard.tsx
@@ -6,7 +6,7 @@ import * as ESPWorkunit from "src/ESPWorkunit";
 import { WorkunitsService, WUQuery } from "@hpcc-js/comms";
 import { Area, Column, Pie, Bar } from "@hpcc-js/chart";
 import { chain, filter, group, map, sort } from "@hpcc-js/dataflow";
-import Chip from "@material-ui/core/Chip";
+import { Chip } from "./controls/Chip";
 import nlsHPCC from "src/nlsHPCC";
 import { Memory } from "src/Memory";
 import { pushParamExact } from "../util/history";
@@ -206,7 +206,7 @@ export const WorkunitsDashboard: React.FunctionComponent<WorkunitsDashboardProps
                                 <Card.Item>
                                     <Stack horizontal horizontalAlign="space-between">
                                         <Text variant="large" nowrap block styles={{ root: { fontWeight: "bold" } }}>{nlsHPCC.State}</Text>
-                                        {filterProps.state !== undefined && <Chip label={filterProps.state} clickable color="primary" onDelete={() => pushParamExact("state", undefined)} />}
+                                        {filterProps.state !== undefined && <Chip label={filterProps.state} onDelete={() => pushParamExact("state", undefined)} />}
                                     </Stack>
                                 </Card.Item>
                                 <Card.Item>
@@ -219,7 +219,7 @@ export const WorkunitsDashboard: React.FunctionComponent<WorkunitsDashboardProps
                                 <Card.Item>
                                     <Stack horizontal horizontalAlign="space-between">
                                         <Text variant="large" nowrap block styles={{ root: { fontWeight: "bold" } }}>{nlsHPCC.Day}</Text>
-                                        {filterProps.day !== undefined && <Chip label={filterProps.day} clickable color="primary" onDelete={() => pushParamExact("day", undefined)} />}
+                                        {filterProps.day !== undefined && <Chip label={filterProps.day} color="primary" onDelete={() => pushParamExact("day", undefined)} />}
                                         <Dropdown onChange={(evt, opt, idx) => { pushParamExact("lastNDays", opt.key); }}
                                             options={[
                                                 { key: 1, text: "1 Day", selected: filterProps.lastNDays === 1 },
@@ -243,7 +243,7 @@ export const WorkunitsDashboard: React.FunctionComponent<WorkunitsDashboardProps
                                 <Card.Item>
                                     <Stack horizontal horizontalAlign="space-between">
                                         <Text variant="large" nowrap block styles={{ root: { fontWeight: "bold" } }}>{nlsHPCC.Protected}</Text>
-                                        {filterProps.protected !== undefined && <Chip label={"" + filterProps.protected} clickable color="primary" onDelete={() => pushParamExact("protected", undefined)} />}
+                                        {filterProps.protected !== undefined && <Chip label={"" + filterProps.protected} color="primary" onDelete={() => pushParamExact("protected", undefined)} />}
                                     </Stack>
                                 </Card.Item>
                                 <Card.Item>
@@ -260,7 +260,7 @@ export const WorkunitsDashboard: React.FunctionComponent<WorkunitsDashboardProps
                                 <Card.Item>
                                     <Stack horizontal horizontalAlign="space-between">
                                         <Text variant="large" nowrap block styles={{ root: { fontWeight: "bold" } }}>{nlsHPCC.Owner}</Text>
-                                        {filterProps.owner !== undefined && <Chip label={filterProps.owner} clickable color="primary" onDelete={() => pushParamExact("owner", undefined)} />}
+                                        {filterProps.owner !== undefined && <Chip label={filterProps.owner} color="primary" onDelete={() => pushParamExact("owner", undefined)} />}
                                     </Stack>
                                 </Card.Item>
                                 <Card.Item>
@@ -273,7 +273,7 @@ export const WorkunitsDashboard: React.FunctionComponent<WorkunitsDashboardProps
                                 <Card.Item>
                                     <Stack horizontal horizontalAlign="space-between">
                                         <Text variant="large" nowrap block styles={{ root: { fontWeight: "bold" } }}>{nlsHPCC.Cluster}</Text>
-                                        {filterProps.cluster !== undefined && <Chip label={filterProps.cluster} clickable color="primary" onDelete={() => pushParamExact("cluster", undefined)} />}
+                                        {filterProps.cluster !== undefined && <Chip label={filterProps.cluster} color="primary" onDelete={() => pushParamExact("cluster", undefined)} />}
                                     </Stack>
                                 </Card.Item>
                                 <Card.Item>
diff --git a/esp/src/src-react/components/controls/Chip.tsx b/esp/src/src-react/components/controls/Chip.tsx
new file mode 100644
index 000000000..f58c584d4
--- /dev/null
+++ b/esp/src/src-react/components/controls/Chip.tsx
@@ -0,0 +1,127 @@
+import * as React from "react";
+import { styled } from "@fluentui/utilities";
+import { IStyleFunctionOrObject, classNamesFunction } from "@fluentui/react";
+import { IStyle, ITheme } from "@fluentui/style-utilities";
+import { StatusErrorFullIcon } from "@fluentui/react-icons-mdl2";
+
+interface IChipStyleProps {
+    className?: string;
+    theme: ITheme;
+    color: string,
+}
+
+interface IChipStyles {
+    root: IStyle;
+    chipLabel: IStyle;
+    chipCloseIcon: IStyle;
+}
+
+interface IChipProps extends React.RefAttributes<HTMLDivElement> {
+    label: string;
+    color?: string;
+    onDelete?: () => void;
+    className?: string;
+    theme?: ITheme;
+    styles?: IStyleFunctionOrObject<IChipStyleProps, IChipStyles>;
+}
+
+function getStyles(props: IChipStyleProps): IChipStyles {
+
+    const { theme, color, className } = props;
+
+    const classNames = {
+        root: "chip-container",
+        label: "chip-label",
+        closeIcon: "chip-close-icon"
+    };
+
+    let backgroundColor = theme.palette.themeDarker;
+    let textColor = theme.palette.white;
+    let iconColor = theme.palette.themePrimary;
+
+    switch (color) {
+        case "default":
+        case "neutral":
+            backgroundColor = theme.palette.neutralLight;
+            textColor = theme.palette.neutralDark;
+            iconColor = theme.palette.neutralPrimary;
+            break;
+        case "secondary":
+            backgroundColor = theme.palette.themeSecondary;
+            break;
+    }
+
+    const mergedStyles = {
+        root: [
+            classNames.root,
+            {
+                color: textColor,
+                backgroundColor: backgroundColor,
+                height: "30px",
+                minWidth: "5rem",
+                justifyContent: "center",
+                borderRadius: "1.25rem",
+                display: "inline-flex",
+                alignItems: "center"
+            },
+            className
+        ],
+        chipLabel: [
+            classNames.label,
+            {
+                fontSize: "0.8125rem",
+                padding: "0 0.85rem",
+                userSelect: "none"
+            }
+        ],
+        chipCloseIcon: [
+            classNames.closeIcon,
+            {
+                color: iconColor,
+                alignSelf: "baseline",
+                margin: "0.05rem 0.66rem 0 -0.2rem"
+            }
+        ]
+    };
+
+    return mergedStyles;
+}
+
+const getClassNames = classNamesFunction<IChipStyleProps, IChipStyles>();
+
+const ChipBase: React.FunctionComponent<IChipProps> = React.forwardRef<
+    HTMLDivElement,
+    IChipProps
+>((props, forwardedRef) => {
+    
+    const { label, onDelete, theme, color, className, styles } = props;
+
+    const ariaLabel = "Click to remove";
+
+    const classNames = getClassNames(styles!, {
+        theme: theme!,
+        className,
+        color
+    });
+
+    function handleCloseIconClick(evt) {
+        evt.preventDefault();
+        if (onDelete) {
+            onDelete();
+        }
+    }
+
+    return <div className={classNames.root}>
+        <span className={classNames.chipLabel}>{label}</span>
+        { onDelete !== undefined && 
+        <a href="" onClick={handleCloseIconClick} title={ariaLabel} aria-label={ariaLabel} className={classNames.chipCloseIcon}>
+            <StatusErrorFullIcon />
+        </a> }
+    </div>;
+});
+
+export const Chip: React.FunctionComponent<IChipProps> = styled<
+    IChipProps,
+    IChipStyleProps,
+    IChipStyles
+>(ChipBase, getStyles, undefined, { scope: "Chip" });
\ No newline at end of file
diff --git a/esp/src/src-react/components/Details.tsx b/esp/src/src-react/components/forms/Fields.tsx
similarity index 66%
rename from esp/src/src-react/components/Details.tsx
rename to esp/src/src-react/components/forms/Fields.tsx
index 940bc501d..568971716 100644
--- a/esp/src/src-react/components/Details.tsx
+++ b/esp/src/src-react/components/forms/Fields.tsx
@@ -1,5 +1,5 @@
 import * as React from "react";
-import { Checkbox, Dropdown, TextField, IDropdownProps, IDropdownOption, Label } from "@fluentui/react";
+import { Checkbox, Dropdown as DropdownBase, TextField, IDropdownOption, Link } from "@fluentui/react";
 import { TextField as MaterialUITextField } from "@material-ui/core";
 import { Topology, TpLogicalClusterQuery } from "@hpcc-js/comms";
 import { TpGroupQuery } from "src/WsTopology";
@@ -7,21 +7,112 @@ import { States } from "src/WsWorkunits";
 import { States as DFUStates } from "src/FileSpray";
 import nlsHPCC from "src/nlsHPCC";
 
-type FieldType = "string" | "checkbox" | "datetime" |
+interface DropdownProps {
+    key?: string;
+    label?: string;
+    options?: IDropdownOption[];
+    selectedKey?: string;
+    optional?: boolean;
+    onChange?: (event: React.FormEvent<HTMLDivElement>, option?: IDropdownOption, index?: number) => void;
+    placeholder?: string;
+    className?: string;
+}
+
+const Dropdown: React.FunctionComponent<DropdownProps> = ({
+    key,
+    label,
+    options = [],
+    selectedKey,
+    optional = false,
+    onChange,
+    placeholder,
+    className
+}) => {
+
+    const [selOptions, setSelOptions] = React.useState<IDropdownOption[]>([]);
+
+    React.useEffect(() => {
+        setSelOptions(optional ? [{ key: "", text: "" }, ...options] : [...options]);
+    }, [optional, options, selectedKey]);
+
+    return <DropdownBase key={key} label={label} className={className} defaultSelectedKey={selectedKey} onChange={onChange} placeholder={placeholder} options={selOptions} />;
+};
+
+export type FieldType = "string" | "checkbox" | "datetime" | "link" |
     "workunit-state" |
     "file-type" | "file-sortby" |
     "queries-suspend-state" | "queries-active-state" |
     "target-cluster" | "target-group" |
     "logicalfile-type" | "dfuworkunit-state";
 
-const states = Object.keys(States).map(s => States[s]);
-const dfustates = Object.keys(DFUStates).map(s => DFUStates[s]);
+export type Values = { [name: string]: string | number | boolean | (string | number | boolean)[] };
 
 interface BaseField {
     type: FieldType;
     label: string;
     disabled?: (params) => boolean;
     placeholder?: string;
+    readonly?: boolean;
+}
+
+interface StringField extends BaseField {
+    type: "string";
+    value?: string;
+}
+
+interface DateTimeField extends BaseField {
+    type: "datetime";
+    value?: string;
+}
+
+interface CheckboxField extends BaseField {
+    type: "checkbox";
+    value?: boolean;
+}
+
+interface WorkunitStateField extends BaseField {
+    type: "workunit-state";
+    value?: string;
+}
+
+interface FileTypeField extends BaseField {
+    type: "file-type";
+    value?: string;
+}
+
+interface FileSortByField extends BaseField {
+    type: "file-sortby";
+    value?: string;
+}
+
+interface QueriesSuspendStateField extends BaseField {
+    type: "queries-suspend-state";
+    value?: string;
+}
+
+interface QueriesActiveStateField extends BaseField {
+    type: "queries-active-state";
+    value?: string;
+}
+
+interface TargetClusterField extends BaseField {
+    type: "target-cluster";
+    value?: string;
+}
+
+interface TargetGroupField extends BaseField {
+    type: "target-group";
+    value?: string;
+}
+
+interface LogicalFileType extends BaseField {
+    type: "logicalfile-type";
+    value?: string;
+}
+
+interface DFUWorkunitStateField extends BaseField {
+    type: "dfuworkunit-state";
+    value?: string;
 }
 
 interface StringField extends BaseField {
@@ -36,6 +127,12 @@ interface DateTimeField extends BaseField {
     value?: string;
 }
 
+interface LinkField extends BaseField {
+    type: "link";
+    href: string;
+    value?: undefined;
+}
+
 interface CheckboxField extends BaseField {
     type: "checkbox";
     value?: boolean;
@@ -86,7 +183,7 @@ interface DFUWorkunitStateField extends BaseField {
     value?: string;
 }
 
-type Field = StringField | CheckboxField | DateTimeField |
+type Field = StringField | CheckboxField | DateTimeField | LinkField |
     WorkunitStateField |
     FileTypeField | FileSortByField |
     QueriesSuspendStateField | QueriesActiveStateField |
@@ -95,35 +192,61 @@ type Field = StringField | CheckboxField | DateTimeField |
 
 export type Fields = { [id: string]: Field };
 
-const TargetClusterTextField: React.FunctionComponent<IDropdownProps> = (props) => {
+export interface TargetClusterTextFieldProps extends DropdownProps {
+    key: string;
+    label?: string;
+    selectedKey?: string;
+    className?: string;
+    onChange?: (event: React.FormEvent<HTMLDivElement>, option?: IDropdownOption, index?: number) => void;
+    placeholder?: string;
+}
+
+export const TargetClusterTextField: React.FunctionComponent<TargetClusterTextFieldProps> = ({
+    key,
+    label,
+    selectedKey,
+    className,
+    onChange,
+    placeholder
+}) => {
 
     const [targetClusters, setTargetClusters] = React.useState<IDropdownOption[]>([]);
 
     React.useEffect(() => {
         const topology = new Topology({ baseUrl: "" });
         topology.fetchLogicalClusters().then((response: TpLogicalClusterQuery.TpLogicalCluster[]) => {
-            setTargetClusters(
-                [
-                    { Name: "", Type: "", LanguageVersion: "", Process: "", Queue: "" },
-                    ...response
-                ]
-                    .map(n => {
-                        return {
-                            key: n.Name,
-                            text: n.Name + (n.Name !== n.Type ? ` (${n.Type})` : "")
-                        };
-                    })
+            setTargetClusters(response
+                .map((n, i) => {
+                    return {
+                        key: n.Name || "unknown",
+                        text: n.Name + (n.Name !== n.Type ? ` (${n.Type})` : ""),
+                    };
+                })
             );
         });
+        // eslint-disable-next-line react-hooks/exhaustive-deps
     }, []);
 
-    return <Dropdown
-        {...props}
-        options={targetClusters}
-    />;
+    return <Dropdown key={key} label={label} selectedKey={selectedKey} optional className={className} onChange={onChange} placeholder={placeholder} options={targetClusters} />;
 };
 
-const TargetGroupTextField: React.FunctionComponent<IDropdownProps> = (props) => {
+export interface TargetGroupTextFieldProps {
+    key: string;
+    label?: string;
+    selectedKey?: string;
+    className?: string;
+    onChange?: (event: React.FormEvent<HTMLDivElement>, option?: IDropdownOption, index?: number) => void;
+    placeholder?: string;
+}
+
+export const TargetGroupTextField: React.FunctionComponent<TargetGroupTextFieldProps> = ({
+    key,
+    label,
+    selectedKey,
+    className,
+    onChange,
+    placeholder
+}) => {
 
     const [targetGroups, setTargetGroups] = React.useState<IDropdownOption[]>([]);
 
@@ -140,23 +263,14 @@ const TargetGroupTextField: React.FunctionComponent<IDropdownProps> = (props) =>
         });
     }, []);
 
-    return <Dropdown
-        {...props}
-        options={targetGroups}
-    />;
+    return <Dropdown key={key} label={label} selectedKey={selectedKey} className={className} onChange={onChange} placeholder={placeholder} options={targetGroups} />;
 };
 
-interface DetailsProps {
-    fields: Fields;
-    onChange: (id: string, newValue: any) => void;
-}
-
-export const Details: React.FunctionComponent<DetailsProps> = ({
-    fields,
-    onChange
-}) => {
+const states = Object.keys(States).map(s => States[s]);
+const dfustates = Object.keys(DFUStates).map(s => DFUStates[s]);
 
-    const formFields: { id: string, label: string, field: any }[] = [];
+export function createInputs(fields: Fields, onChange?: (id: string, newValue: any) => void) {
+    const retVal: { id: string, label: string, field: any }[] = [];
     for (const fieldID in fields) {
         const field = fields[fieldID];
         if (!field.disabled) {
@@ -165,7 +279,7 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
         switch (field.type) {
             case "string":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <TextField
@@ -183,7 +297,7 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                 break;
             case "checkbox":
                 field.value = field.value || false;
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <Checkbox
@@ -196,7 +310,7 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                 break;
             case "datetime":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <MaterialUITextField
@@ -213,14 +327,27 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                     />
                 });
                 break;
+            case "link":
+                field.href = field.href;
+                retVal.push({
+                    id: fieldID,
+                    label: field.label,
+                    field: <Link
+                        key={fieldID}
+                        href={field.href}
+                        target="_blank"
+                        style={{ paddingLeft: 8 }}>{field.href}</Link>
+                });
+                break;
             case "workunit-state":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <Dropdown
                         key={fieldID}
-                        defaultSelectedKey={field.value}
+                        selectedKey={field.value}
+                        optional
                         options={states.map(state => {
                             return {
                                 key: state,
@@ -234,12 +361,12 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                 break;
             case "file-type":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <Dropdown
                         key={fieldID}
-                        defaultSelectedKey={field.value}
+                        selectedKey={field.value}
                         options={[
                             { key: "", text: nlsHPCC.LogicalFilesAndSuperfiles },
                             { key: "Logical Files Only", text: nlsHPCC.LogicalFilesOnly },
@@ -253,14 +380,14 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                 break;
             case "file-sortby":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <Dropdown
                         key={fieldID}
-                        defaultSelectedKey={field.value}
+                        selectedKey={field.value}
+                        optional
                         options={[
-                            { key: "", text: "" },
                             { key: "Newest", text: nlsHPCC.Newest },
                             { key: "Oldest", text: nlsHPCC.Oldest },
                             { key: "Smallest", text: nlsHPCC.Smallest },
@@ -273,14 +400,14 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                 break;
             case "queries-suspend-state":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <Dropdown
                         key={fieldID}
-                        defaultSelectedKey={field.value}
+                        selectedKey={field.value}
+                        optional
                         options={[
-                            { key: "", text: "" },
                             { key: "Not suspended", text: nlsHPCC.NotSuspended },
                             { key: "Suspended", text: nlsHPCC.Suspended },
                             { key: "Suspended by user", text: nlsHPCC.SuspendedByUser },
@@ -294,14 +421,14 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                 break;
             case "queries-active-state":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <Dropdown
                         key={fieldID}
-                        defaultSelectedKey={field.value}
+                        selectedKey={field.value}
+                        optional
                         options={[
-                            { key: "", text: "" },
                             { key: "1", text: nlsHPCC.Active },
                             { key: "0", text: nlsHPCC.NotActive }
                         ]}
@@ -312,40 +439,38 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                 break;
             case "target-cluster":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <TargetClusterTextField
                         key={fieldID}
-                        defaultSelectedKey={field.value}
+                        selectedKey={field.value}
                         onChange={(ev, row) => onChange(fieldID, row.key)}
                         placeholder={field.placeholder}
-                        options={[]}
                     />
                 });
                 break;
             case "target-group":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <TargetGroupTextField
                         key={fieldID}
-                        defaultSelectedKey=""
+                        selectedKey={field.value}
                         onChange={(ev, row) => onChange(fieldID, row.key)}
                         placeholder={field.placeholder}
-                        options={[]}
                     />
                 });
                 break;
             case "dfuworkunit-state":
                 field.value = field.value || "";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <Dropdown
                         key={fieldID}
-                        defaultSelectedKey=""
+                        optional
                         options={dfustates.map(state => {
                             return {
                                 key: state,
@@ -359,12 +484,12 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                 break;
             case "logicalfile-type":
                 field.value = field.value || "Created";
-                formFields.push({
+                retVal.push({
                     id: fieldID,
                     label: field.label,
                     field: <Dropdown
                         key={fieldID}
-                        defaultSelectedKey=""
+                        optional
                         options={[
                             { key: "Created", text: nlsHPCC.CreatedByWorkunit },
                             { key: "Used", text: nlsHPCC.UsedByWorkunit }
@@ -376,15 +501,5 @@ export const Details: React.FunctionComponent<DetailsProps> = ({
                 break;
         }
     }
-
-    return <table style={{ padding: 4 }}>
-        <tbody>
-            {formFields.map((ff) => {
-                return <tr key={ff.id}>
-                    <td style={{ whiteSpace: "nowrap" }}><Label>{ff.label}</Label></td>
-                    <td style={{ width: "80%", paddingLeft: 8 }}>{ff.field}</td>
-                </tr>;
-            })}
-        </tbody>
-    </table>;
-};
+    return retVal;
+}
diff --git a/esp/src/src-react/components/forms/Filter.tsx b/esp/src/src-react/components/forms/Filter.tsx
new file mode 100644
index 000000000..f80c49ce6
--- /dev/null
+++ b/esp/src/src-react/components/forms/Filter.tsx
@@ -0,0 +1,138 @@
+import * as React from "react";
+import { getTheme, mergeStyleSets, FontWeights, IDragOptions, IIconProps, ContextualMenu, DefaultButton, PrimaryButton, IconButton, IStackStyles, Modal, Stack } from "@fluentui/react";
+import { useId } from "@fluentui/react-hooks";
+import nlsHPCC from "src/nlsHPCC";
+import { Fields, Values } from "./Fields";
+import { TableForm } from "./Forms";
+
+interface FilterProps {
+    filterFields: Fields;
+    onApply: (values: Values) => void;
+
+    showFilter: boolean;
+    setShowFilter: (_: boolean) => void;
+}
+
+export const Filter: React.FunctionComponent<FilterProps> = ({
+    filterFields,
+    onApply,
+    showFilter,
+    setShowFilter
+}) => {
+
+    const [doSubmit, setDoSubmit] = React.useState(false);
+    const [doReset, setDoReset] = React.useState(false);
+
+    const closeFilter = () => setShowFilter(false);
+
+    const titleId = useId("title");
+
+    const dragOptions: IDragOptions = {
+        moveMenuItemText: "Move",
+        closeMenuItemText: "Close",
+        menu: ContextualMenu,
+    };
+
+    const theme = getTheme();
+
+    const contentStyles = mergeStyleSets({
+        container: {
+            display: "flex",
+            flexFlow: "column nowrap",
+            alignItems: "stretch",
+        },
+        header: [
+            {
+                flex: "1 1 auto",
+                borderTop: `4px solid ${theme.palette.themePrimary}`,
+                color: theme.palette.neutralPrimary,
+                display: "flex",
+                alignItems: "center",
+                fontWeight: FontWeights.semibold,
+                padding: "12px 12px 14px 24px",
+            },
+        ],
+        body: {
+            flex: "4 4 auto",
+            padding: "0 24px 24px 24px",
+            overflowY: "hidden",
+            selectors: {
+                p: { margin: "14px 0" },
+                "p:first-child": { marginTop: 0 },
+                "p:last-child": { marginBottom: 0 },
+            },
+        },
+    });
+
+    const cancelIcon: IIconProps = { iconName: "Cancel" };
+    const iconButtonStyles = {
+        root: {
+            color: theme.palette.neutralPrimary,
+            marginLeft: "auto",
+            marginTop: "4px",
+            marginRight: "2px",
+        },
+        rootHovered: {
+            color: theme.palette.neutralDark,
+        },
+    };
+    const buttonStackStyles: IStackStyles = {
+        root: {
+            height: "56px",
+        },
+    };
+    return <Modal
+        titleAriaId={titleId}
+        isOpen={showFilter}
+        onDismiss={closeFilter}
+        isBlocking={false}
+        containerClassName={contentStyles.container}
+        dragOptions={dragOptions}
+    >
+        <div className={contentStyles.header}>
+            <span id={titleId}>Filter</span>
+            <IconButton
+                styles={iconButtonStyles}
+                iconProps={cancelIcon}
+                ariaLabel="Close popup modal"
+                onClick={closeFilter}
+            />
+        </div>
+        <div className={contentStyles.body}>
+            <Stack>
+                <TableForm
+                    fields={filterFields}
+                    doSubmit={doSubmit}
+                    doReset={doReset}
+                    onSubmit={fields => {
+                        setDoSubmit(false);
+                        onApply(fields);
+                    }}
+                    onReset={() => {
+                        setDoReset(false);
+                    }}
+                />
+            </Stack>
+            <Stack
+                horizontal
+                horizontalAlign="space-between"
+                verticalAlign="end"
+                styles={buttonStackStyles}
+            >
+                <DefaultButton
+                    text={nlsHPCC.Clear}
+                    onClick={() => {
+                        setDoReset(true);
+                    }}
+                />
+                <PrimaryButton
+                    text={nlsHPCC.Apply}
+                    onClick={() => {
+                        setDoSubmit(true);
+                        closeFilter();
+                    }}
+                />
+            </Stack>
+        </div>
+    </Modal>;
+};
diff --git a/esp/src/src-react/components/forms/Forms.tsx b/esp/src/src-react/components/forms/Forms.tsx
new file mode 100644
index 000000000..888157ea2
--- /dev/null
+++ b/esp/src/src-react/components/forms/Forms.tsx
@@ -0,0 +1,54 @@
+import * as React from "react";
+import { TableGroup } from "./Groups";
+import { Fields, Values } from "./Fields";
+
+const fieldsToRequest = (fields: Fields) => {
+    const retVal: Values = {};
+    for (const name in fields) {
+        if (!fields[name].disabled(fields)) {
+            retVal[name] = fields[name].value;
+        }
+    }
+    return retVal;
+};
+
+interface TableFormProps {
+    fields: Fields;
+    doSubmit: boolean;
+    doReset: boolean;
+    onSubmit: (fields: Values) => void;
+    onReset: (fields: Values) => void;
+}
+
+export const TableForm: React.FunctionComponent<TableFormProps> = ({
+    fields,
+    doSubmit,
+    doReset,
+    onSubmit,
+    onReset
+}) => {
+
+    const [localFields, setLocalFields] = React.useState<Fields>({ ...fields });
+
+    React.useEffect(() => {
+        if (doSubmit === false) return;
+        onSubmit(fieldsToRequest(localFields));
+        // eslint-disable-next-line react-hooks/exhaustive-deps
+    }, [doSubmit]);
+
+    React.useEffect(() => {
+        if (doReset === false) return;
+        for (const key in localFields) {
+            delete localFields[key].value;
+        }
+        setLocalFields(localFields);
+        onReset(fieldsToRequest(localFields));
+        // eslint-disable-next-line react-hooks/exhaustive-deps
+    }, [doReset]);
+
+    return <TableGroup fields={localFields} onChange={(id, value) => {
+        localFields[id].value = value;
+        setLocalFields({ ...localFields });
+    }} />;
+};
+
diff --git a/esp/src/src-react/components/forms/Groups.tsx b/esp/src/src-react/components/forms/Groups.tsx
new file mode 100644
index 000000000..51b2e2f47
--- /dev/null
+++ b/esp/src/src-react/components/forms/Groups.tsx
@@ -0,0 +1,46 @@
+import * as React from "react";
+import { Label } from "@fluentui/react";
+import { createInputs, Fields } from "./Fields";
+
+interface FieldsTableProps {
+    fields: Fields;
+    onChange?: (id: string, newValue: any) => void;
+}
+
+export const TableGroup: React.FunctionComponent<FieldsTableProps> = ({
+    fields,
+    onChange = (id: string, newValue: any) => { }
+}) => {
+
+    const formFields: { id: string, label: string, field: any }[] = createInputs(fields, onChange);
+
+    return <table style={{ padding: 4 }}>
+        <tbody>
+            {formFields.map((ff) => {
+                return <tr key={ff.id}>
+                    <td style={{ whiteSpace: "nowrap" }}><Label htmlFor={ff.id}>{ff.label}</Label></td>
+                    <td style={{ width: "80%", paddingLeft: 8 }}>{ff.field}</td>
+                </tr>;
+            })}
+        </tbody>
+    </table>;
+};
+
+export const SimpleGroup: React.FunctionComponent<FieldsTableProps> = ({
+    fields,
+    onChange = (id: string, newValue: any) => { }
+}) => {
+
+    const formFields: { id: string, label: string, field: any }[] = createInputs(fields, onChange);
+
+    return <>
+        {
+            formFields.map((ff) => {
+                return <>
+                    <Label htmlFor={ff.id}>{ff.label}</Label>
+                    {ff.field}
+                </>;
+            })
+        }
+    </>;
+};
diff --git a/esp/src/src-react/hooks/Workunit.ts b/esp/src/src-react/hooks/Workunit.ts
index 93adc78af..106b21d0a 100644
--- a/esp/src/src-react/hooks/Workunit.ts
+++ b/esp/src/src-react/hooks/Workunit.ts
@@ -2,6 +2,7 @@ import * as React from "react";
 import { useConst } from "@fluentui/react-hooks";
 import { Workunit, Result, WUStateID, WUInfo, WorkunitsService } from "@hpcc-js/comms";
 import nlsHPCC from "src/nlsHPCC";
+import * as Utility from "src/Utility";
 
 export function useCounter(): [number, () => void] {
 
@@ -55,6 +56,18 @@ export function useWorkunitResults(wuid: string): [Result[], Workunit, WUStateID
     return [results, workunit, state];
 }
 
+export function useWorkunitResult(wuid: string, resultName: string): [Result, Workunit, WUStateID] {
+
+    const [results, workunit, state] = useWorkunitResults(wuid);
+    const [result, setResult] = React.useState<Result>();
+
+    React.useEffect(() => {
+        setResult(results.filter(result => result.Name === resultName)[0]);
+    }, [resultName, results, state]);
+
+    return [result, workunit, state];
+}
+
 export interface Variable {
     Type: string;
     Name: string;
@@ -167,3 +180,108 @@ export function useWorkunitXML(wuid: string): [string] {
 
     return [xml];
 }
+
+export function useWorkunitExceptions(wuid: string): [WUInfo.ECLException[], Workunit, () => void] {
+
+    const [workunit, state] = useWorkunit(wuid);
+    const [exceptions, setExceptions] = React.useState<WUInfo.ECLException[]>([]);
+    const [count, increment] = useCounter();
+
+    React.useEffect(() => {
+        workunit?.fetchInfo({
+            IncludeExceptions: true
+        }).then(response => {
+            setExceptions(response?.Workunit?.Exceptions?.ECLException || []);
+        });
+    }, [workunit, state, count]);
+
+    return [exceptions, workunit, increment];
+}
+
+export function useWorkunitResources(wuid: string): [string[], Workunit, WUStateID] {
+
+    const [workunit, state] = useWorkunit(wuid);
+    const [resources, setResources] = React.useState<string[]>([]);
+
+    React.useEffect(() => {
+        workunit?.fetchInfo({
+            IncludeResourceURLs: true
+        }).then(response => {
+            setResources(response?.Workunit?.ResourceURLs?.URL || []);
+        });
+    }, [workunit, state]);
+
+    return [resources, workunit, state];
+}
+
+export interface HelperRow {
+    id: string;
+    Type: string;
+    Description?: string;
+    FileSize?: number;
+    Orig?: any;
+    workunit: Workunit;
+}
+
+function mapHelpers(workunit: Workunit, helpers: WUInfo.ECLHelpFile[] = []): HelperRow[] {
+    return helpers.map((helper, i): HelperRow => {
+        return {
+            id: "H:" + i,
+            Type: helper.Type,
+            Description: Utility.pathTail(helper.Name),
+            FileSize: helper.FileSize,
+            Orig: helper,
+            workunit
+        };
+    });
+}
+
+function mapThorLogInfo(workunit: Workunit, thorLogInfo: WUInfo.ThorLogInfo[] = []): HelperRow[] {
+    const retVal: HelperRow[] = [];
+    for (let i = 0; i < thorLogInfo.length; ++i) {
+        for (let j = 0; j < thorLogInfo[i].NumberSlaves; ++j) {
+            retVal.push({
+                id: "T:" + i + "_" + j,
+                Type: "ThorSlaveLog",
+                Description: thorLogInfo[i].ClusterGroup + "." + thorLogInfo[i].LogDate + ".log (slave " + (j + 1) + " of " + thorLogInfo[i].NumberSlaves + ")",
+                Orig: {
+                    SlaveNumber: j + 1,
+                    ...thorLogInfo[i]
+                },
+                workunit
+            });
+        }
+    }
+    return retVal;
+}
+
+export function useWorkunitHelpers(wuid: string): [HelperRow[]] {
+
+    const [workunit, state] = useWorkunit(wuid);
+    const [helpers, setHelpers] = React.useState<HelperRow[]>([]);
+
+    React.useEffect(() => {
+        workunit?.fetchInfo({
+            IncludeHelpers: true
+        }).then(response => {
+            setHelpers([{
+                id: "E:0",
+                Type: "ECL",
+                workunit
+            }, {
+                id: "X:0",
+                Type: "Workunit XML",
+                workunit
+            }, ...(workunit.HasArchiveQuery ? [{
+                id: "A:0",
+                Type: "Archive Query",
+                workunit
+            }] : []),
+            ...mapHelpers(workunit, response?.Workunit?.Helpers?.ECLHelpFile),
+            ...mapThorLogInfo(workunit, response?.Workunit?.ThorLogList?.ThorLogInfo)
+            ]);
+        });
+    }, [workunit, state]);
+
+    return [helpers];
+}
diff --git a/esp/src/src-react/layouts/HpccJSAdapter.css b/esp/src/src-react/layouts/HpccJSAdapter.css
index 261c53e24..28f9a945a 100644
--- a/esp/src/src-react/layouts/HpccJSAdapter.css
+++ b/esp/src/src-react/layouts/HpccJSAdapter.css
@@ -1,16 +1,14 @@
-:root{
-    --grid-font-family: "Segoe WPC", "Segoe UI", sans-serif;
+:root {
     --header-font-size: 14px;
     --row-font-size: 13px;
-    --grid-background:transparent;
-    --grid-selectionForeground:rgb(50, 49, 48);
+    --grid-background: transparent;
+    --grid-selectionForeground: rgb(50, 49, 48);
     --grid-selectionBackground: rgb(235, 235, 235);
     --grid-hoverBackground: rgb(247, 245, 243);
-    --grid-selectionHoverBackground:  rgb(227, 225, 223);
+    --grid-selectionHoverBackground: rgb(227, 225, 223);
 }
 
 .flat .dojo-component.dgrid.dgrid-grid {
-    font-family: var(--grid-font-family);
     border-style: hidden;
 }
 
@@ -21,7 +19,7 @@
 }
 
 .flat .dojo-component.dgrid .dgrid-header-row .dgrid-cell {
-    border-bottom-color:  var(--grid-selectionBackground);
+    border-bottom-color: var(--grid-selectionBackground);
 }
 
 .flat .dojo-component.dgrid .dgrid-header-row:focus {
@@ -33,7 +31,6 @@
 }
 
 .flat .dojo-component.dgrid .dgrid-row {
-    font-family: var(--grid-font-family);
     font-size: var(--row-font-size);
     line-height: 22px;
 }
@@ -61,6 +58,6 @@
 }
 
 .flat .dojo-component.dgrid .dgrid-fakeline {
-    border:0px;
-    margin:2px;
+    border: 0px;
+    margin: 2px;
 }
diff --git a/esp/src/src-react/routes.tsx b/esp/src/src-react/routes.tsx
index f85355262..ca1be92d0 100644
--- a/esp/src/src-react/routes.tsx
+++ b/esp/src/src-react/routes.tsx
@@ -60,7 +60,7 @@ const routes: Routes = [
             { path: "/dashboard", action: (ctx) => import("./components/WorkunitsDashboard").then(_ => <_.WorkunitsDashboard filterProps={parseSearch(ctx.search) as any} />) },
             { path: "/legacy", action: () => import("./layouts/DojoAdapter").then(_ => <_.DojoAdapter widgetClassID="WUQueryWidget" />) },
             { path: "/:Wuid/:Tab", action: (ctx, params) => import("./components/WorkunitDetails").then(_ => <_.WorkunitDetails wuid={params.Wuid as string} tab={params.Tab as string} />) },
-            { path: "/:Wuid/outputs/:Name", action: (ctx, params) => import("./layouts/DojoAdapter").then(_ => <_.DojoAdapter widgetClassID="ResultWidget" params={params} />) },
+            { path: "/:Wuid/outputs/:Name", action: (ctx, params) => import("./components/Result").then(_ => <_.Result wuid={params.Wuid as string} resultName={params.Name as string} filter={parseSearch(ctx.search) as any} />) },
             { path: "/:Wuid", action: (ctx, params) => import("./components/WorkunitDetails").then(_ => <_.WorkunitDetails wuid={params.Wuid as string} />) }
         ]
     },
@@ -118,7 +118,15 @@ const routes: Routes = [
     { path: "/esdl", action: () => import("./layouts/DojoAdapter").then(_ => <_.DojoAdapter widgetClassID="DynamicESDLQueryWidget" />) },
     { path: "/elk", action: () => import("./layouts/DojoAdapter").then(_ => <_.DojoAdapter widgetClassID="IFrameWidget&src=http%3A%2F%2F10.240.61.210%3A5601%2Fapp%2Fkibana%23%2Fdashboard%2FMetricbeat-system-overview-ecs%3F_g%3D(refreshInterval%253A(pause%253A!t%252Cvalue%253A300000)%252Ctime%253A(from%253Anow%252Fd%252Cto%253Anow%252Fd))&__filter=isTrusted%3Dfalse%26screenX%3D0%26screenY%3D0%26clientX%3D0%26clientY%3D0%26ctrlKey%3Dfalse%26shiftKey%3Dfalse%26altKey%3Dfalse%26metaKey%3Dfalse%26button%3D0%26buttons%3D0%26pageX%3D0%26pageY%3D0%26x%3D0%26y%3D0%26offsetX%3D0%26offsetY%3D0%26movementX%3D0%26movementY%3D0%26toElement%3D%255Bobject%2520HTMLInputElement%255D%26layerX%3D-1280%26layerY%3D9994%26getModifierState%3Dfunction%2520getModifierState()%2520%257B%2520%255Bnative%2520code%255D%2520%257D%26initMouseEvent%3Dfunction%2520initMouseEvent()%2520%257B%2520%255Bnative%2520code%255D%2520%257D%26view%3D%255Bobject%2520Window%255D%26detail%3D0%26which%3D1%26initUIEvent%3Dfunction%2520initUIEvent()%2520%257B%2520%255Bnative%2520code%255D%2520%257D%26NONE%3D0%26CAPTURING_PHASE%3D1%26AT_TARGET%3D2%26BUBBLING_PHASE%3D3%26type%3Dclick%26target%3D%255Bobject%2520HTMLInputElement%255D%26currentTarget%3D%255Bobject%2520HTMLInputElement%255D%26eventPhase%3D2%26bubbles%3Dtrue%26cancelable%3Dtrue%26defaultPrevented%3Dfalse%26composed%3Dtrue%26timeStamp%3D265185.10500000045%26srcElement%3D%255Bobject%2520HTMLInputElement%255D%26returnValue%3Dtrue%26cancelBubble%3Dfalse%26path%3D%255Bobject%2520HTMLInputElement%255D%26path%3D%255Bobject%2520HTMLSpanElement%255D%26path%3D%255Bobject%2520HTMLDivElement%255D%26path%3D%255Bobject%2520HTMLDivElement%255D%26path%3D%255Bobject%2520HTMLDivElement%255D%26path%3D%255Bobject%2520HTMLBodyElement%255D%26path%3D%255Bobject%2520HTMLHtmlElement%255D%26path%3D%255Bobject%2520HTMLDocument%255D%26path%3D%255Bobject%2520Window%255D%26composedPath%3Dfunction%2520composedPath()%2520%257B%2520%255Bnative%2520code%255D%2520%257D%26stopPropagation%3Dfunction%2520stopPropagation()%2520%257B%2520%255Bnative%2520code%255D%2520%257D%26stopImmediatePropagation%3Dfunction%2520stopImmediatePropagation()%2520%257B%2520%255Bnative%2520code%255D%2520%257D%26preventDefault%3Dfunction%2520preventDefault()%2520%257B%2520%255Bnative%2520code%255D%2520%257D%26initEvent%3Dfunction%2520initEvent()%2520%257B%2520%255Bnative%2520code%255D%2520%257D" />) },
     { path: "/errors", action: () => import("./layouts/DojoAdapter").then(_ => <_.DojoAdapter widgetClassID="InfoGridWidget" />) },
+    { path: "/config", action: () => import("./components/Configuration").then(_ => <_.Configuration />) },
     //  Other
+    { path: "/iframe", action: (ctx) => import("./components/IFrame").then(_ => <_.IFrame src={parseSearch(ctx.search).src as string} />) },
+    {
+        path: "/text", action: (ctx) => {
+            const params = parseSearch(ctx.search);
+            return import("./components/SourceEditor").then(_ => <_.FetchEditor mode={params.mode as any} url={params.src as string} />);
+        }
+    },
     { path: "(.*)", action: () => <h1>Not Found</h1> }
 ];
 
diff --git a/esp/src/src/ECLArchiveWidget.ts b/esp/src/src/ECLArchiveWidget.ts
index b8f576305..d8ef00a5c 100644
--- a/esp/src/src/ECLArchiveWidget.ts
+++ b/esp/src/src/ECLArchiveWidget.ts
@@ -104,14 +104,17 @@ export class ECLArchiveWidget {
             return ret;
         };
 
+        this.archiveViewer
+            .target(context.id + "EclContent")
+            ;
+
         const wu = Workunit.attach({ baseUrl: "" }, params.Wuid);
         wu.fetchQuery().then(function (query) {
             context.editor.text(query.Text);
             if (!wu.HasArchiveQuery) {
                 context.archiveViewer
-                    .target(context.id + "EclContent")
                     .addWidget(context.editor)
-                    .render()
+                    .lazyRender()
                     ;
             } else {
                 context.directoryTree
@@ -128,11 +131,10 @@ export class ECLArchiveWidget {
                     .rowItemPadding(2)
                     ;
                 context.archiveViewer
-                    .target(context.id + "EclContent")
                     .addWidget(context.directoryTree)
                     .addWidget(context.editor)
                     .relativeSizes([0.1, 0.9])
-                    .render()
+                    .lazyRender()
                     ;
                 const scopesOptions = {
                     ScopeFilter: {
diff --git a/esp/src/src/ESPBase.ts b/esp/src/src/ESPBase.ts
index b3595663d..f28b623cb 100644
--- a/esp/src/src/ESPBase.ts
+++ b/esp/src/src/ESPBase.ts
@@ -19,7 +19,7 @@ export class ESPBase {
         return config[key];
     }
 
-    getBaseURL(service) {
+    getBaseURL(service?) {
         if (!service) {
             service = "WsWorkunits";
         }
diff --git a/esp/src/src/ESPRequest.ts b/esp/src/src/ESPRequest.ts
index c710bbb51..b6a238b7d 100644
--- a/esp/src/src/ESPRequest.ts
+++ b/esp/src/src/ESPRequest.ts
@@ -35,7 +35,7 @@ class RequestHelper {
         return config[key];
     }
 
-    getBaseURL(service) {
+    getBaseURL(service?) {
         if (service === undefined) {
             service = "WsWorkunits";
         }
@@ -321,7 +321,7 @@ export function flattenMap(target, arrayName, _singularName?, supressAppName?, e
     return target;
 }
 
-export function getBaseURL(service) {
+export function getBaseURL(service?) {
     const helper = new RequestHelper();
     return helper.getBaseURL(service);
 }
diff --git a/esp/src/src/Utility.ts b/esp/src/src/Utility.ts
index 36cfa9d0d..b601c28f5 100644
--- a/esp/src/src/Utility.ts
+++ b/esp/src/src/Utility.ts
@@ -45,6 +45,7 @@ export function parseXML(val) {
 
 export function csvEncode(cell) {
     if (!isNaN(cell)) return cell;
+    if (cell === undefined) return "";
     return '"' + String(cell).replace('"', '""') + '"';
 }
 
@@ -209,6 +210,38 @@ export function espSkew2NumberTests() {
     }, this);
 }
 
+export function formatAsDelim(grid, rows: any, delim = ",") {
+    const headers = grid.columns;
+    const container: string[] = [];
+    const headerNames: string[] = [];
+
+    for (const key in headers) {
+        if (key !== headers[key].id && headers[key].selectorType !== "checkbox") {
+            if (!headers[key].label) {
+                const str = csvEncode(headers[key].field);
+                headerNames.push(str);
+            } else {
+                const str = csvEncode(headers[key].label);
+                headerNames.push(str);
+            }
+        }
+    }
+    container.push(headerNames.join(delim));
+
+    rows.forEach(row => {
+        const cells: any[] = [];
+        for (const key in headers) {
+            if (key !== headers[key].id && headers[key].selectorType !== "checkbox") {
+                const cell = row[headers[key].field];
+                cells.push(csvEncode(cell));
+            }
+        }
+        container.push(cells.join(delim));
+    });
+
+    return container.join("\n");
+}
+
 export function downloadToCSV(grid, rows, fileName) {
     let csvContent = "";
     const headers = grid.columns;
@@ -905,3 +938,65 @@ export class Persist {
 export function textColor(backgroundColor: string): string {
     return Palette.textColor(backgroundColor);
 }
+
+function toCSVCell(str) {
+    str = "" + str;
+    const mustQuote = (str.indexOf(",") >= 0 || str.indexOf("\"") >= 0 || str.indexOf("\r") >= 0 || str.indexOf("\n") >= 0);
+    if (mustQuote) {
+        let retVal = "\"";
+        for (let i = 0; i < str.length; ++i) {
+            const c = str.charAt(i);
+            retVal += c === "\"" ? "\"\"" : c;
+
+        }
+        retVal += "\"";
+        return retVal;
+    }
+    return str;
+}
+
+function csvFormatHeader(data, delim) {
+    let retVal = "";
+    if (data.length) {
+        for (const key in data[0]) {
+            if (retVal.length)
+                retVal += delim;
+            retVal += key;
+        }
+    }
+    return retVal;
+}
+
+function csvFormatRow(row, idx, delim) {
+    let retVal = "";
+    for (const key in row) {
+        if (retVal.length)
+            retVal += delim;
+        retVal += toCSVCell(row[key]);
+    }
+    return retVal;
+}
+
+function csvFormatFooter(data) {
+    return "";
+}
+
+export function toCSV(data, delim = ",") {
+    let retVal = csvFormatHeader(data, delim) + "\n";
+    data.forEach((item, idx) => {
+        retVal += csvFormatRow(item, idx, delim) + "\n";
+    });
+    retVal += csvFormatFooter(data);
+    return retVal;
+}
+
+export function downloadText(content: string, fileName: string) {
+    const encodedUri = "data:text/csv;charset=utf-8,\uFEFF" + encodeURI(content);
+    const link = document.createElement("a");
+    link.setAttribute("href", encodedUri);
+    link.setAttribute("download", fileName);
+    link.style.visibility = "hidden";
+    document.body.appendChild(link);
+    link.click();
+    document.body.removeChild(link);
+}
\ No newline at end of file
diff --git a/esp/src/src/nls/bs/hpcc.ts b/esp/src/src/nls/bs/hpcc.ts
index 0fda2b118..149cd2b22 100644
--- a/esp/src/src/nls/bs/hpcc.ts
+++ b/esp/src/src/nls/bs/hpcc.ts
@@ -125,8 +125,10 @@
     ContinueWorking: "Nastavite sa radom",
     Copied: "Kopirano!",
     Copy: "Kopirajte",
+    CopyLogicalFiles: "Kopirajte logiÄke fajlove u klipbord",
     CopyToClipboard: "Kopirajte u klipboard",
     CopyURLToClipboard: "Kopirajte URL u klipbord",
+    CopyWUID: "Kopirajte WUID",
     CopyWUIDs: "Kopiraj WUID-ove u klipbord",
     CopyWUIDToClipboard: "Kopirajte WUID u klipbord",
     Count: "Izbrojte",
@@ -295,6 +297,7 @@
     FirstN: "Prvih N",
     FirstName: "Ime",
     FirstNRows: "Prvih N Redova",
+    FirstNSortBy: "Sortirajte po",
     Fixed: "Fiksni",
     Folder: "Fascikla",
     Format: "Format",
@@ -393,8 +396,8 @@
     LocalFileSystemsOnly: "Samo Lokalni Fajl Sistemi",
     Location: "Lokacija",
     Lock: "ZakljuÄaj",
-    Log: "Dnevnik (Log)",
     log_analysis_1: "log_analysis_1*",
+    Log: "Dnevnik (Log)",
     LogDirectory: "Direktori za logiranje podataka",
     LogFile: "Datoteka Aktivnosti",
     LoggedInAs: "Prijavljen kao",
@@ -572,6 +575,7 @@
     Preflight: "Provjera prije isporuke",
     PreloadAllPackages: "UÄitajte sve pakete",
     PreserveCompression: "SaÄuvajte Kompresiju",
+    PreserveParts: "SaÄuvajte dijelove fajlova",
     PressCtrlCToCopy: "Pritisnite ctrl + c za kopiranje.",
     Preview: "Pregled",
     PrimaryLost: "Primarni Je Izgubljen",
@@ -871,6 +875,7 @@
     TotalParts: "Ukupan Broj Dijelova",
     TotalSize: "Totalna VeliÄina",
     TotalThorTime: "Ukupno Vrijeme Thor-a",
+    ToTime: "Do vremena",
     TransitionGuide: "VodiÄ",
     Tree: "Drvo",
     Type: "Tip",
diff --git a/esp/src/src/nls/hpcc.ts b/esp/src/src/nls/hpcc.ts
index e8b5bfaa2..f7984329c 100644
--- a/esp/src/src/nls/hpcc.ts
+++ b/esp/src/src/nls/hpcc.ts
@@ -129,6 +129,7 @@ export = {
         CopyWUIDs: "Copy WUIDs to clipboard",
         CopyWUIDToClipboard: "Copy WUID to clipboard",
         CopyLogicalFiles: "Copy Logical Files to clipboard",
+        CopySelectionToClipboard: "Copy selection to clipboard",
         Copied: "Copied!",
         Count: "Count",
         CPULoad: "CPU Load",
@@ -212,6 +213,7 @@ export = {
         Download: "Download",
         Downloads: "Downloads",
         DownloadToCSV: "Download to CSV",
+        DownloadSelectionAsCSV: "Download selection as CSV",
         DropZone: "Drop Zone",
         DueToInctivity: "You will be logged out of all ECL Watch sessions in 3 minutes due to inactivity.",
         Duration: "Duration",
@@ -333,6 +335,7 @@ export = {
         HideSpills: "Hide Spills",
         High: "High",
         History: "History",
+        Homepage: "Homepage",
         HPCCSystems: "HPCC SystemsÂ®",
         Icon: "Icon",
         ID: "ID",
@@ -340,6 +343,7 @@ export = {
         IncludeSlaveLogs: "Include slave logs",
         Index: "Index",
         Info: "Info",
+        Infos: "Info(s)",
         Informational: "Informational",
         InfoDialog: "Info Dialog",
         InheritedPermissions: "Inherited permission:",
@@ -514,6 +518,7 @@ export = {
         OrphanFile2: "Orphan File",
         OrphanMessage: "An orphan file has partial file parts on disk. However, a full set of parts is not available to construct a complete logical file. There is no reference to these file parts in the Dali server.",
         OSStats: "OS Stats",
+        Others: "Other(s)",
         Outputs: "Outputs",
         Overview: "Overview",
         Overwrite: "Overwrite",
diff --git a/esp/src/webpack.config.js b/esp/src/webpack.config.js
index 1f100a5e7..ecd2d1ee3 100644
--- a/esp/src/webpack.config.js
+++ b/esp/src/webpack.config.js
@@ -26,11 +26,9 @@ module.exports = function (env) {
 
     const entry = {
         stub: "eclwatch/stub",
-        dojoLib: "lib/src/dojoLib"
+        dojoLib: "lib/src/dojoLib",
+        index: "lib/src-react/index"
     };
-    if (!isProduction) {
-        entry.index = "lib/src-react/index"
-    }
 
     const plugins = [
         new DojoWebpackPlugin({
diff --git a/fs/dafsclient/rmtclient_impl.hpp b/fs/dafsclient/rmtclient_impl.hpp
index 4e6740251..9a36dea14 100644
--- a/fs/dafsclient/rmtclient_impl.hpp
+++ b/fs/dafsclient/rmtclient_impl.hpp
@@ -197,7 +197,8 @@ extern bool clientAsyncCopyFileSection(const char *uuid,    // from genUUID - mu
                         offset_t fromofs,
                         offset_t size,                      // (offset_t)-1 for all file
                         ICopyFileProgress *progress,
-                        unsigned timeout                    // 0 to start, non-zero to wait
+                        unsigned timeout,                   // 0 to start, non-zero to wait
+                        CFflags copyFlags
                         ); // returns true when done
 
 extern void clientSetRemoteFileTimeouts(unsigned maxconnecttime, unsigned maxreadtime);
diff --git a/fs/dafsclient/rmtfile.cpp b/fs/dafsclient/rmtfile.cpp
index c671e04ea..68f0d4255 100644
--- a/fs/dafsclient/rmtfile.cpp
+++ b/fs/dafsclient/rmtfile.cpp
@@ -1789,12 +1789,14 @@ extern bool clientAsyncCopyFileSection(const char *uuid,
                         offset_t fromOfs,
                         offset_t size,
                         ICopyFileProgress *progress,
-                        unsigned timeout)       // returns true when done
+                        unsigned timeout,
+                        CFflags copyFlags)       // returns true when done
 {
     CRemoteFile *cfile = QUERYINTERFACE(from,CRemoteFile);
-    if (!cfile) {
-        // local - do sync
-        from->copySection(to,toOfs,fromOfs,size,progress);
+    if (!cfile || to.isLocal()) {
+        //local - ensure that the file copy is run locally rather than remote
+        Owned<IFile> dest = createIFile(to);
+        copyFileSection(from,dest,toOfs,fromOfs,size,progress,copyFlags);
         return true;
     }
     return cfile->copySectionAsync(uuid,to,toOfs,fromOfs, size, progress, timeout);
@@ -1808,10 +1810,11 @@ bool asyncCopyFileSection(const char *uuid,                 // from genUUID - mu
                             offset_t fromofs,
                             offset_t size,                      // (offset_t)-1 for all file
                             ICopyFileProgress *progress,
-                            unsigned timeout                    // 0 to start, non-zero to wait
+                            unsigned timeout,                   // 0 to start, non-zero to wait
+                            CFflags copyFlags
                         )
 {
-    return  clientAsyncCopyFileSection(uuid,from,to,toofs,fromofs,size,progress,timeout);
+    return  clientAsyncCopyFileSection(uuid,from,to,toofs,fromofs,size,progress,timeout,copyFlags);
 }
 
 
diff --git a/fs/dafsclient/rmtfile.hpp b/fs/dafsclient/rmtfile.hpp
index dde010ae8..0515876be 100644
--- a/fs/dafsclient/rmtfile.hpp
+++ b/fs/dafsclient/rmtfile.hpp
@@ -73,7 +73,8 @@ extern DAFSCLIENT_API bool asyncCopyFileSection(const char *uuid,   // from genU
                             offset_t fromofs,
                             offset_t size,                      // (offset_t)-1 for all file
                             ICopyFileProgress *progress,
-                            unsigned timeout                    // 0 to start, non-zero to wait
+                            unsigned timeout,                   // 0 to start, non-zero to wait
+                            CFflags copyFlags
                         ); // returns true when done
 
 extern DAFSCLIENT_API void setRemoteFileTimeouts(unsigned maxconnecttime,unsigned maxreadtime);
diff --git a/fs/dafsserver/dafsserver.cpp b/fs/dafsserver/dafsserver.cpp
index ec04efcc1..c9134935d 100644
--- a/fs/dafsserver/dafsserver.cpp
+++ b/fs/dafsserver/dafsserver.cpp
@@ -2789,13 +2789,13 @@ class CRemoteFileServer : implements IRemoteFileServer, public CInterface
         StructArrayOf<OpenFileInfo> openFiles;
         Owned<IDirectoryIterator> opendir;
         unsigned            lasttick, lastInactiveTick;
-        atomic_t            &globallasttick;
+        std::atomic<unsigned> &globallasttick;
         unsigned            previdx;        // for debug
 
 
         IMPLEMENT_IINTERFACE;
 
-        CRemoteClientHandler(CRemoteFileServer *_parent,ISocket *_socket,atomic_t &_globallasttick, bool _calledByRowService)
+        CRemoteClientHandler(CRemoteFileServer *_parent,ISocket *_socket,std::atomic<unsigned> &_globallasttick, bool _calledByRowService)
             : socket(_socket), globallasttick(_globallasttick), calledByRowService(_calledByRowService)
         {
             previdx = (unsigned)-1;
@@ -3073,7 +3073,7 @@ class CRemoteFileServer : implements IRemoteFileServer, public CInterface
         void touch()
         {
             lastInactiveTick = lasttick = msTick();
-            atomic_set(&globallasttick,lasttick);
+            globallasttick = lasttick;
         }
 
         const char *queryPeerName()
@@ -3415,7 +3415,7 @@ class CRemoteFileServer : implements IRemoteFileServer, public CInterface
     CAsyncCommandManager asyncCommandManager;
     CThrottler stdCmdThrottler, slowCmdThrottler;
     CClientStatsTable clientStatsTable;
-    atomic_t globallasttick;
+    std::atomic<unsigned> globallasttick;
     unsigned targetActiveThreads;
     Linked<IPropertyTree> keyPairInfo;
 
@@ -3650,7 +3650,7 @@ public:
         stopping = false;
         clientcounttick = msTick();
         closedclients = 0;
-        atomic_set(&globallasttick,msTick());
+        globallasttick = msTick();
     }
 
     ~CRemoteFileServer()
@@ -5517,7 +5517,7 @@ public:
 
     unsigned idleTime()
     {
-        unsigned t = (unsigned)atomic_read(&globallasttick);
+        unsigned t = globallasttick;
         return msTick()-t;
     }
 
diff --git a/helm/examples/logging/README.md b/helm/examples/logging/README.md
index 0c4035d49..b6bf7f84f 100644
--- a/helm/examples/logging/README.md
+++ b/helm/examples/logging/README.md
@@ -26,7 +26,7 @@ As mentioned earlier, the HPCC Systems logs provide a wealth of information whic
 
 By default, the component logs are not filtered, and contain the following columns:
     
-    MessageID TargetAudience DateStamp TimeStamp ProcessId ThreadID QuotedLogMessage
+    MessageID TargetAudience LogEntryClass JobID DateStamp TimeStamp ProcessId ThreadID QuotedLogMessage
 
 The logs can be filtered by TargetAudience, Category or Detail Level, and the output columns can be configured. Logging configuration settings can be applied at the global, or component level.
 
@@ -40,7 +40,7 @@ The availble target audiences include operator(OPR), user(USR), programmer(PRO),
     
 ### Target Category Filtering
 
-The available target categories include disaster(DIS), error(ERR), warning(WRN),information(INF),progress(PRO). The category (or class) filter is controlled by the `<section>`.logging.classes value, comprised of 3 letter codes delimited by the aggregation operator (+) or the removal operator (-).
+The available target categories include disaster(DIS), error(ERR), warning(WRN),information(INF),progress(PRO),metrics(MET). The category (or class) filter is controlled by the `<section>`.logging.classes value, comprised of 3 letter codes delimited by the aggregation operator (+) or the removal operator (-).
     
     For example, the mydali instance's log output to include all classes except for progress:
     helm install myhpcc ./hpcc --set dali[0].logging.classes="ALL-PRO" --set dali[0].name="mydali"
@@ -55,8 +55,8 @@ Log output verbosity can be adjusted from "critical messages only" (1) up to "re
 
 The available log data columns include messageid(MID), audience(AUD), class(CLS), date(DAT), time(TIM), millitime(MLT), microtime(MCT), nanotime(NNT), processid(PID), threadid(TID), node(NOD), job(JOB), use(USE), session(SES), code(COD), component(COM), quotedmessage(QUO), prefix(PFX), all(ALL), and standard(STD). The log data columns (or fields) configuration is controlled by the `<section>`.logging.fields value, comprised of 3 letter codes delimited by the aggregation operator (+) or the removal operator (-).
     
-    For example, all component log output should include the standard columns and the log message class name:
-    helm install myhpcc ./hpcc --set global.logging.fields="STD+CLS"
+    For example, all component log output should include the standard columns except the job ID column:
+    helm install myhpcc ./hpcc --set global.logging.fields="STD-JOB"
     
 Adjustment of per-component logging values can require assertion of multiple component specific values, which can be inconvinient to do via the --set command line parameter. In these cases, a custom values file could be used to set all required fields.
 
diff --git a/helm/hpcc/Chart.yaml b/helm/hpcc/Chart.yaml
index b6e90a3f9..05695d64a 100644
--- a/helm/hpcc/Chart.yaml
+++ b/helm/hpcc/Chart.yaml
@@ -6,9 +6,9 @@ type: application
 
 # This is the chart version. This version number should be incremented each time you make changes
 # to the chart and its templates, including the app version.
-version: 8.0.16-rc1
+version: 0.1.0
 
 # This is the version number of the application being deployed. This version number should be
 # incremented each time you make changes to the application.
 
-appVersion: 8.0.16-rc1
+appVersion: 0.1.0
diff --git a/helm/hpcc/templates/_helpers.tpl b/helm/hpcc/templates/_helpers.tpl
index dedb9cc7a..314348381 100644
--- a/helm/hpcc/templates/_helpers.tpl
+++ b/helm/hpcc/templates/_helpers.tpl
@@ -704,6 +704,15 @@ securityContext:
 Generate instance queue names
 */}}
 {{- define "hpcc.generateConfigMapQueues" -}}
+{{- $storage := ($.Values.storage | default dict) -}}
+{{- $planes := ($storage.planes | default list) -}}
+{{- $firstPlane := dict -}}
+{{- range $plane := $planes -}}
+ {{- if and (not $firstPlane.plane) (or (not $plane.labels) (has "data" $plane.labels)) }}
+ {{- $_ := set $firstPlane "plane" $plane.name -}}
+ {{- end -}}
+{{- end -}}
+{{- $defaultDataPlane := ($storage.dataStorage.plane | default $firstPlane.plane | default "hpcc-data-plane") -}}
 {{- range $.Values.eclagent -}}
  {{- if not .disabled -}}
 - name: {{ .name }}
@@ -717,6 +726,7 @@ Generate instance queue names
   type: roxie 
   prefix: {{ .prefix | default "null" }}
   queriesOnly: true
+  storagePlane: {{ .storagePlane | default $defaultDataPlane }}
  {{- end }}
 {{ end -}}
 {{- range $.Values.thor -}}
@@ -826,7 +836,7 @@ apiVersion: v1
 metadata:
   name: {{ printf "%s-configmap" $configMapName }}
 data:
-  {{ $configMapName }}.yaml: |
+  {{ $configMapName }}.yaml:
     version: 1.0
     sasha:
 {{ toYaml (omit .me "logging") | indent 6 }}
@@ -1248,3 +1258,103 @@ Add a secret volume for a roxie udp key
 {{ end -}}
 {{- end -}}
 {{- end -}}
+
+{{/*
+A template to filter out a set of keys from a generated config yaml.
+Used to regenerate a configmap without the exclusions, so that it can be
+used to form an SHA as an annotation in a pod.
+This means pods only auto-restart if the non-excluded parts change.
+
+Pass in root, me, configMapHelper, component, excludeSectionRegexList and excludeKeyList
+excludeSectionRegexList is a list of regexp's that filter out top-level sections, e.g. [".*spec.yaml$" ]
+excludeKeyList is a list of key values to exclude from each section, e.g. [ "global", "esp.services" "esp.queues"]
+
+The configMap data section is reconstructed based on filtering out matches.
+
+Used to exclude parts of the config which are always allowed to change without causing a pod restart.
+e.g. a cache of secrets, with an auto reload/refresh mechanism, or 'replicas'.
+*/}}
+{{- define "hpcc.filterConfig" }}
+{{- $config := fromYaml (include .configMapHelper .) -}}
+{{- $configCtx := dict -}}
+{{- $excludeSectionRegexList := .excludeSectionRegexList -}}
+{{- $excludeKeyList := .excludeKeyList -}}
+{{- range $configElementName, $configElementDict := $config.data -}}
+  {{- $_ := set $configCtx "excludeSection" false -}}
+  {{- range $regex := $excludeSectionRegexList -}}
+    {{- if (regexMatch $regex $configElementName) -}}
+      {{- $_ := set $configCtx "excludeSection" true -}}
+    {{- end -}}
+  {{- end -}}
+  {{- if not $configCtx.excludeSection -}}
+    {{- $configDictCtx := dict -}}
+    {{- range $key := $excludeKeyList -}}
+      {{- $_ := set $configDictCtx "keyDictStr" (regexReplaceAll "(.*)\\..*$" $key "${1}") -}}
+      {{- if eq $configDictCtx.keyDictStr $key -}}{{/* single component key, e.g. "global"*/}}
+        {{- $configElementDict := (unset $configElementDict $key) -}}
+      {{- else -}}{{/* scopes component key, e.g. "eclccserver.queue"*/}}
+        {{- $_ := set $configDictCtx "keyKeyStr" (regexReplaceAll ".*\\.(.*)$" $key "${1}") -}}
+        {{- $subDict := get $configElementDict $configDictCtx.keyDictStr -}}
+        {{- if $subDict -}}
+          {{- $_ := set $configElementDict $configDictCtx.keyDictStr (unset $subDict $configDictCtx.keyKeyStr) -}}
+        {{- end -}}
+      {{- end -}}
+    {{- end -}}{{/*range $key*/}}
+    {{- $configYaml := toYaml $configElementDict -}}
+    {{- $_ := set $config.data $configElementName $configYaml -}}
+  {{- else -}}
+    {{- $configData := (unset $config.data $configElementName) -}}
+    {{- $_ := set $config "data" $configData -}}
+  {{- end -}}
+{{- end -}}{{/*range $configElementName*/}}
+{{ toYaml $config }}
+{{- end -}}
+
+{{/*
+A template to generate a component config
+Pass in root, me, configMapHelper
+*/}}
+{{- define "hpcc.generateConfig" }}
+{{- $config := fromYaml (include .configMapHelper .) -}}
+{{- range $configElementName, $configElementDict := $config.data -}}
+  {{- $configYaml := toYaml $configElementDict -}}
+  {{- $_ := set $config.data $configElementName $configYaml -}}
+{{- end }}
+{{ toYaml $config }}
+{{- end -}}
+
+{{/*
+A template to generate an SHA from a component config, to be used to annotate a Deployment,
+such that it will auto restart if the SHA changes.
+Uses filterConfig helper to select pertinent parts of the config to be part of the SHA.
+Pass in root, me, configMapHelper, component and excludeKeys
+excludeKeys is a comma separated list of key values to exclude from each section, e.g. "global,esp.services,esp.queues"
+
+globalExcludeSectionRegexList below is hard-coded list of section regexp's to exclude.
+globalExcludeList below is a hard-coded list of global keys to exclude.
+
+*/}}
+{{- define "hpcc.getConfigSHA" }}
+{{- $globalExcludeList := list (printf "%s.replicas" .component) -}}
+{{- $globalExcludeSectionRegexList := list ".*spec.yaml$" -}}
+{{- $combinedExcludeKeyList := concat (splitList "," (.excludeKeys | default "")) $globalExcludeList -}}
+{{- $ctx := merge (omit . "excludeKeys") (dict "excludeSectionRegexList" $globalExcludeSectionRegexList "excludeKeyList" $combinedExcludeKeyList) -}}
+{{- include "hpcc.filterConfig" $ctx | sha256sum }}
+{{- end -}}
+
+{{/*
+A template to ensure that the flag specifying whether kubernetes resource validation is allowed exists.  When running helm
+in template mode access to functions like "lookup" that need to access the kubernetes API are diabled.  We use that function
+to validate things like the existance of secrets we have dependencies on.  We also check the Capabilities.APIVersions for the
+existence of custom CRDS which are not updated when kubernetes API access is not allowed.
+
+By default the behavior should now be correct for both install and template.
+
+Setting the default requires an extra call to lookup.  To avoid a call to "lookup" every time we cache the value in
+global.noResourceValidation flag.  This behavior can be overriden by the caller using "--set global.noResourceValidation=true"
+*/}}
+{{- define "hpcc.ensureNoResourceValidationFlag" }}
+  {{- if not (hasKey .root.Values.global "noResourceValidation" )}}
+    {{- $_ := set .root.Values.global "noResourceValidation" (not (lookup "v1" "Namespace" "" "")) -}}
+  {{- end }}
+{{- end -}}
diff --git a/helm/hpcc/templates/dali.yaml b/helm/hpcc/templates/dali.yaml
index 0cbc2a1a4..8bca00f93 100644
--- a/helm/hpcc/templates/dali.yaml
+++ b/helm/hpcc/templates/dali.yaml
@@ -110,9 +110,9 @@ data:
 {{- if not $sasha.disabled -}}
 {{- $_ := set $sasha "name" $sashaName -}}
 kind: ConfigMap
-{{- with ($sasha | merge (pick $dali "logging") | merge (dict "inDaliPod" true "access" (splitList " " (include "hpcc.getSashaServiceAccess" $sasha)))) }}
-{{- $sashaSecretsCategories := append ((or (has "data" .access) (has "dalidata" .access)) | ternary (list "storage") list) "system" }}
-{{ include "hpcc.sashaConfigMap" (dict "root" $ "me" . "secretsCategories" $sashaSecretsCategories ) }}
+{{- with ($sasha | merge (pick $dali "logging") | merge (dict "inDaliPod" true "access" (splitList " " (include "hpcc.getSashaServiceAccess" $sasha)))) -}}
+{{- $sashaSecretsCategories := append ((or (has "data" .access) (has "dalidata" .access)) | ternary (list "storage") list) "system" -}}
+{{ include "hpcc.generateConfig" (dict "root" $ "me" . "secretsCategories" $sashaSecretsCategories "configMapHelper" "hpcc.sashaConfigMap") }}
 {{- end }}
 ---
 {{- if $sasha.servicePort -}}
diff --git a/helm/hpcc/templates/dfuserver.yaml b/helm/hpcc/templates/dfuserver.yaml
index cf759988d..33e179780 100644
--- a/helm/hpcc/templates/dfuserver.yaml
+++ b/helm/hpcc/templates/dfuserver.yaml
@@ -3,7 +3,7 @@ apiVersion: v1
 metadata:
   name: {{ .me.name }}-configmap
 data:
-  {{ .me.name }}.yaml: |
+  {{ .me.name }}.yaml:
     version: 1.0
     dfuserver:
 {{ toYaml (omit .me "logging") | indent 6 }}
@@ -16,7 +16,7 @@ data:
 {{- if not .disabled -}}
 {{- $secretsCategories := list "system" "storage" -}}
 {{- $commonCtx := dict "root" $ "me" . "secretsCategories" $secretsCategories "includeLabels" (list "lz" "data" "") }}
-{{- $configSHA := include "hpcc.dfuServerConfigMap" $commonCtx | sha256sum }}
+{{- $configSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.dfuServerConfigMap" "component" "dfuserver" "excludeKeys" "global")) -}}
 apiVersion: apps/v1
 kind: Deployment
 metadata:
@@ -57,7 +57,7 @@ spec:
 {{- include "hpcc.addVolumes" $commonCtx | indent 6 }}
 ---
 kind: ConfigMap
-{{ include "hpcc.dfuServerConfigMap" $commonCtx }}
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.dfuServerConfigMap")) }}
 ---
 {{- end }}
 {{- end }}
diff --git a/helm/hpcc/templates/eclagent.yaml b/helm/hpcc/templates/eclagent.yaml
index 1acb7f99e..4c00e6a55 100644
--- a/helm/hpcc/templates/eclagent.yaml
+++ b/helm/hpcc/templates/eclagent.yaml
@@ -4,12 +4,12 @@ Pass in dict with root and me
 */}}
 {{- define "hpcc.agentConfigMap" }}
 {{- $apptype := .me.type | default "hthor" -}}
-{{- $appJobName := printf "%s-%%jobname" $apptype }}
+{{- $appJobName := printf "%s-_HPCC_JOBNAME_" $apptype }}
 apiVersion: v1
 metadata:
   name: {{ .me.name }}-configmap
 data:
-  {{ .me.name }}.yaml: |
+  {{ .me.name }}.yaml:
     version: 1.0
     eclagent:
 {{ toYaml (omit .me "logging") | indent 6 }}
@@ -22,7 +22,7 @@ data:
 {{ include "hpcc.generateGlobalConfigMap" .root | indent 6 }}
 {{- if not .me.useChildProcesses }}
 {{- $misc := .root.Values.global.misc | default dict }}
-  {{ $apptype }}-jobspec.yaml: |
+  {{ $apptype }}-jobspec.yaml:
     apiVersion: batch/v1
     kind: Job
     metadata:
@@ -48,7 +48,7 @@ data:
 {{- include "hpcc.addSecurityContext" . | indent 12 }}
 {{ include "hpcc.addImageAttrs" . | indent 12 }}
 {{- include "hpcc.addResources" (dict "me" .me.resources) | indent 12 }}
-{{- $appCmd := printf "%s %s %s %%args" $apptype (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
+{{- $appCmd := printf "%s %s %s _HPCC_ARGS_" $apptype (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
 {{ include "hpcc.addCommandAndLifecycle" (. | merge (dict "command" $appCmd)) | indent 12 }}
             workingDir: /var/lib/HPCCSystems
             volumeMounts:
@@ -56,7 +56,7 @@ data:
 {{ include "hpcc.addDataVolumeMount" . | indent 12 }}
 {{ include "hpcc.addDllVolumeMount" . | indent 12 }}
 {{ include "hpcc.addSecretVolumeMounts" . | indent 12 }}
-{{ include "hpcc.addCertificateVolumeMount" (dict "root" .root "name" .me.name "component" .me.type) | indent 12 }}
+{{ include "hpcc.addCertificateVolumeMount" (dict "root" .root "name" .me.name "component" $apptype) | indent 12 }}
 {{- if $misc.postJobCommandViaSidecar }}
 {{ include "hpcc.addWaitAndRunVolumeMount" . | indent 12 }}
 {{- end }}
@@ -65,7 +65,7 @@ data:
 {{ include "hpcc.addDataVolume" . | indent 10 }}
 {{ include "hpcc.addDllVolume" . | indent 10 }}
 {{ include "hpcc.addSecretVolumes" . | indent 10 }}
-{{ include "hpcc.addCertificateVolume" (dict "root" .root "name" .me.name "component" .me.type) | indent 10 }}
+{{ include "hpcc.addCertificateVolume" (dict "root" .root "name" .me.name "component" $apptype) | indent 10 }}
 {{- if $misc.postJobCommandViaSidecar }}
 {{ include "hpcc.addWaitAndRunVolume" . | indent 10 }}
 {{- end }}
@@ -76,9 +76,10 @@ data:
 
 {{ range $.Values.eclagent -}}
 {{- if not .disabled -}}
+{{- $apptype := .type | default "hthor" -}}
 {{- $secretsCategories := list "system" "ecl-user" "ecl" "storage" }}
 {{- $commonCtx := dict "root" $ "me" . "secretsCategories" $secretsCategories }}
-{{- $configSHA := include "hpcc.agentConfigMap" $commonCtx | sha256sum }}
+{{- $configSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.agentConfigMap" "component" "eclagent" "excludeKeys" (print "global," $apptype ".replicas"))) }}
 {{- include "hpcc.checkDefaultStoragePlane" $commonCtx }}
 apiVersion: apps/v1
 kind: Deployment
@@ -132,10 +133,10 @@ spec:
 {{ include "hpcc.addCertificateVolume" (dict "root" $ "name" .name "component" "eclagent") | indent 6 }}
 ---
 kind: ConfigMap 
-{{ include "hpcc.agentConfigMap" $commonCtx }}
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.agentConfigMap")) }}
 ---
 {{ include "hpcc.addCertificate" (dict "root" $ "name" .name "component" "eclagent") }}
-{{ include "hpcc.addCertificate" (dict "root" $ "name" .name "component" .type) }}
+{{ include "hpcc.addCertificate" (dict "root" $ "name" .name "component" $apptype) }}
 
 {{- end }}
 {{- end }}
diff --git a/helm/hpcc/templates/eclccserver.yaml b/helm/hpcc/templates/eclccserver.yaml
index 43f8cfefc..2d294cf08 100644
--- a/helm/hpcc/templates/eclccserver.yaml
+++ b/helm/hpcc/templates/eclccserver.yaml
@@ -3,12 +3,12 @@ EclccServer configmap
 Pass in dict with root and me
 */}}
 {{- define "hpcc.eclccServerConfigMap" -}}
-{{- $compileJobName := printf "compile-%%jobname" }}
+{{- $compileJobName := printf "compile-_HPCC_JOBNAME_" }}
 apiVersion: v1
 metadata:
   name: {{ .me.name }}-configmap
 data:
-  {{ .me.name }}.yaml: |
+  {{ .me.name }}.yaml:
     version: 1.0
     eclccserver:
 {{ toYaml (omit .me "logging") | indent 6 }}
@@ -21,7 +21,7 @@ data:
 {{ include "hpcc.generateGlobalConfigMap" .root | indent 6 }}
 {{- if not .me.useChildProcesses }}
 {{- $misc := .root.Values.global.misc | default dict }}
-  compile-jobspec.yaml: |
+  compile-jobspec.yaml:
     apiVersion: batch/v1
     kind: Job
     metadata:
@@ -49,7 +49,7 @@ data:
 {{ include "hpcc.addImageAttrs" . | indent 12 }}
 {{- $misc := .root.Values.global.misc | default dict -}}
 {{- $postJobCommand := $misc.postJobCommand | default "" }}
-{{- $eclccserverCmd := printf "eclccserver %s %s %%args" (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
+{{- $eclccserverCmd := printf "eclccserver %s %s _HPCC_ARGS_" (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
 {{ include "hpcc.addCommandAndLifecycle" (. | merge (dict "command" $eclccserverCmd)) | indent 12 }}
             workingDir: /tmp
             volumeMounts:
@@ -80,7 +80,7 @@ data:
 {{- if not .disabled -}}
 {{- $secretsCategories := list "system" "codeVerify" }}
 {{- $commonCtx := dict "root" $ "me" . "secretsCategories" $secretsCategories }}
-{{- $configSHA := include "hpcc.eclccServerConfigMap" $commonCtx | sha256sum }}
+{{- $configSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.eclccServerConfigMap" "component" "eclccserver" "excludeKeys" "global,eclccserver.queues")) }}
 apiVersion: apps/v1
 kind: Deployment
 metadata:
@@ -139,8 +139,7 @@ spec:
         emptyDir: {}
 ---
 kind: ConfigMap 
-{{ include "hpcc.eclccServerConfigMap" $commonCtx }}
-
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.eclccServerConfigMap")) }}
 ---
 {{ include "hpcc.addCertificate" (dict "root" $ "name" .name "component" "eclccserver") }}
 {{ include "hpcc.addCertificate" (dict "root" $ "name" .name "component" "compile") }}
diff --git a/helm/hpcc/templates/eclscheduler.yaml b/helm/hpcc/templates/eclscheduler.yaml
index c6fffbea3..d9239a778 100644
--- a/helm/hpcc/templates/eclscheduler.yaml
+++ b/helm/hpcc/templates/eclscheduler.yaml
@@ -7,7 +7,7 @@ apiVersion: v1
 metadata:
   name: {{ .me.name }}-configmap
 data:
-  {{ .me.name }}.yaml: |
+  {{ .me.name }}.yaml:
     version: 1.0
     eclscheduler:
 {{ toYaml (omit .me "logging") | indent 6 }}
@@ -24,7 +24,7 @@ data:
 {{- if not .disabled -}}
 {{- $secretsCategories := list "system" }}
 {{- $commonCtx := dict "root" $ "me" . "secretsCategories" $secretsCategories }}
-{{- $configSHA := include "hpcc.eclSchedulerConfigMap" $commonCtx | sha256sum }}
+{{- $configSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.eclSchedulerConfigMap" "component" "eclscheduler" "excludeKeys" "global")) -}}
 apiVersion: apps/v1
 kind: Deployment
 metadata:
@@ -76,8 +76,7 @@ spec:
 {{ include "hpcc.addCertificateVolume" (dict "root" $ "name" .name "component" "eclscheduler") | indent 6 }}
 ---
 kind: ConfigMap
-{{ include "hpcc.eclSchedulerConfigMap" $commonCtx }}
-
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.eclSchedulerConfigMap")) }}
 ---
 
 {{ include "hpcc.addCertificate" (dict "root" $ "name" .name "component" "eclscheduler") }}
diff --git a/helm/hpcc/templates/esp.yaml b/helm/hpcc/templates/esp.yaml
index c8b0d64e0..6d96b0f76 100644
--- a/helm/hpcc/templates/esp.yaml
+++ b/helm/hpcc/templates/esp.yaml
@@ -7,7 +7,7 @@ apiVersion: v1
 metadata:
   name: {{ .me.name }}-configmap
 data:
-  {{ .me.name }}.yaml: |
+  {{ .me.name }}.yaml:
     version: 1.0
     esp:
 {{ toYaml (omit .me "logging" "metrics") | indent 6 }}
@@ -52,7 +52,7 @@ data:
 {{- $secretsCategories := ternary (list "storage" "esp" "codeSign" "codeVerify")  (list "storage" "esp") (eq $application "eclwatch") -}}
 {{- $includeStorageLabels := ternary (list "lz" "data" "") (list "data" "") (eq $application "eclwatch") -}}
 {{- $commonCtx := dict "root" $ "me" . "secretsCategories" $secretsCategories  "includeLabels" $includeStorageLabels -}}
-{{- $configSHA := include "hpcc.espConfigMap" $commonCtx | sha256sum }}
+{{- $configSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.espConfigMap" "component" "esp" "excludeKeys" "global,esp.services,esp.queues")) }}
 
 apiVersion: apps/v1
 kind: Deployment
@@ -101,8 +101,7 @@ spec:
 {{ include "hpcc.addCertificateVolume" (dict "root" $ "component" $application "name" .name "certificate" .certificate "external" (and (hasKey . "public") .public)) | indent 6 }}
 ---
 kind: ConfigMap
-{{ include "hpcc.espConfigMap" $commonCtx }}
-
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.espConfigMap")) }}
 ---
 apiVersion: v1
 kind: Service
diff --git a/helm/hpcc/templates/issuers.yaml b/helm/hpcc/templates/issuers.yaml
index e18c09ac7..4b40bdf0f 100644
--- a/helm/hpcc/templates/issuers.yaml
+++ b/helm/hpcc/templates/issuers.yaml
@@ -6,23 +6,29 @@ metadata:
   namespace: {{ .root.Release.Namespace | default "default" }}
    {{- if .me.spec }}
 spec:
+  {{- if not .root.Values.global.noResourceValidation -}}
   {{- if .me.spec.ca }}
    {{- if .me.spec.ca.secretName }}
     {{- if not (lookup "v1" "Secret" .root.Release.Namespace .me.spec.ca.secretName) }}
-      {{- $_ := fail (printf "Using a local certificate authority requires a CA certificate stored in the secret named '%s'. You can disable mTLS security by setting certificates.enabled=false" .me.spec.ca.secretName ) -}}
+      {{- $_ := fail (printf "\n\nUsing a local certificate authority requires a CA certificate stored in the secret named '%s'. To disable mTLS security set \"certificates.enabled=false\". To bypass this validation check set \"global.noResourceValidation=true\". \n" .me.spec.ca.secretName ) -}}
     {{- end }}
    {{- end }}
   {{- end }}
+  {{- end }}
 {{ toYaml .me.spec | indent 2 }}
 
  {{- end }}
 {{- end }}
 
+{{- template "hpcc.ensureNoResourceValidationFlag" ( dict "root" $ ) }}
+
 {{- if $.Values.certificates -}}
  {{- if $.Values.certificates.enabled -}}
+  {{- if not $.Values.global.noResourceValidation -}}
    {{- if not (.Capabilities.APIVersions.Has "cert-manager.io/v1") }}
-    {{- $_ := fail (printf "Enabling certificate generation requires cert-manager resources. Please intall cert-manager. You can disable mTLS security by setting certificates.enabled=false" ) -}}
+    {{- $_ := fail (printf "\n\nEnabling certificate generation requires cert-manager resources. Please intall cert-manager. To disable mTLS security set \"certificates.enabled=false\". To bypass this validation check set \"global.noResourceValidation=true\". \n" ) -}}
    {{- end -}}
+  {{- end -}}
   {{- range $k, $v := .Values.certificates.issuers }}
 {{- include "hpcc.issuers" (dict "root" $ "me" $v ) }}
 ---
diff --git a/helm/hpcc/templates/localroxie.yaml b/helm/hpcc/templates/localroxie.yaml
index e913d2c31..d6507bbf9 100644
--- a/helm/hpcc/templates/localroxie.yaml
+++ b/helm/hpcc/templates/localroxie.yaml
@@ -7,7 +7,7 @@ apiVersion: v1
 metadata:
   name: {{ .me.name }}-configmap
 data:
-  {{ .me.name }}.yaml: |
+  {{ .me.name }}.yaml:
     version: 1.0
     roxie:
 {{ toYaml (omit .me "logging") | indent 6 }}
@@ -21,7 +21,7 @@ data:
 {{- if not $roxie.disabled  -}}
 {{- $secretsCategories := list "system" "ecl-user" "ecl" "storage" }}
 {{- $commonCtx := dict "root" $ "me" $roxie "secretsCategories" $secretsCategories }}
-{{- $configSHA := include "hpcc.localroxieConfigMap" $commonCtx | sha256sum }}
+{{- $configSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.localroxieConfigMap" "component" "roxie" "excludeKeys" "global")) }}
 {{- include "hpcc.checkDefaultStoragePlane" $commonCtx }}
 {{- if $roxie.localAgent -}}
 {{- $name := $roxie.name -}}
@@ -112,7 +112,7 @@ spec:
 {{- end }}
 {{- end }}
 kind: ConfigMap 
-{{ include "hpcc.localroxieConfigMap" $commonCtx }}
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.localroxieConfigMap")) }}
 ---
 {{ include "hpcc.addCertificate" (dict "root" $ "name" $roxie.name "services" $roxie.services "component" "localroxie" "external" false) }}
 {{ include "hpcc.addCertificate" (dict "root" $ "name" $roxie.name "services" $roxie.services "component" "localroxie" "external" true) }}
diff --git a/helm/hpcc/templates/roxie.yaml b/helm/hpcc/templates/roxie.yaml
index 03585ad81..6a12b7151 100644
--- a/helm/hpcc/templates/roxie.yaml
+++ b/helm/hpcc/templates/roxie.yaml
@@ -7,7 +7,7 @@ apiVersion: v1
 metadata:
   name: {{ .me.name }}-configmap
 data:
-  {{ .me.name }}.yaml: |
+  {{ .me.name }}.yaml:
     version: 1.0
     roxie:
 {{ toYaml ( omit .me "logging" "topoServer" "encryptInTransit") | indent 6 }}
@@ -37,7 +37,7 @@ apiVersion: v1
 metadata:
   name: {{ .toponame }}-configmap
 data:
-  {{ .toponame }}.yaml: |
+  {{ .toponame }}.yaml:
     version: 1.0
     toposerver:
       port: {{ .topoport }}
@@ -54,8 +54,8 @@ data:
 {{- $_ := set $commonCtx "numChannels" ($roxie.numChannels | int | default 1) -}}
 {{- $_ := set $commonCtx "topoport" ($toposerver.port | int | default 9004) -}}
 {{- $_ := set $toposerver "name" $commonCtx.toponame -}}
-{{- $configSHA := include "hpcc.roxieConfigMap" $commonCtx | sha256sum }}
-{{- $topoconfigSHA := include "hpcc.roxieTopoConfigMap" $commonCtx | sha256sum }}
+{{- $configSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.roxieConfigMap" "component" "roxie" "excludeKeys" "global")) }}
+{{- $topoconfigSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.roxieTopoConfigMap" "component" "toposerver" "excludeKeys" "global")) }}
 {{- include "hpcc.checkDefaultStoragePlane" $commonCtx }}
 {{- if not $roxie.localAgent -}}
 {{- $_ := set $roxie "localAgent" false -}}
@@ -164,10 +164,10 @@ spec:
 
 ---
 kind: ConfigMap 
-{{ include "hpcc.roxieConfigMap" $commonCtx }}
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.roxieConfigMap")) }}
 ---
 kind: ConfigMap 
-{{ include "hpcc.roxieTopoConfigMap" $commonCtx }}
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.roxieTopoConfigMap")) }}
 ---
 
 {{ if $roxie.serverReplicas -}}
diff --git a/helm/hpcc/templates/sasha.yaml b/helm/hpcc/templates/sasha.yaml
index 208b7d412..a43f278f6 100644
--- a/helm/hpcc/templates/sasha.yaml
+++ b/helm/hpcc/templates/sasha.yaml
@@ -7,7 +7,7 @@
 {{- $_ := set $sasha "access" (splitList " " (include "hpcc.getSashaServiceAccess" $sasha)) -}}
 {{- $secretsCategories := append ((or (has "data" $sasha.access) (has "dalidata" $sasha.access)) | ternary (list "storage") list) "system" -}}
 {{- $commonCtx := dict "root" $ "me" $sasha "secretsCategories" $secretsCategories -}}
-{{- $configSHA := include "hpcc.sashaConfigMap" $commonCtx | sha256sum -}}
+{{- $configSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.sashaConfigMap" "component" "sasha" "excludeKeys" "global")) -}}
 {{- $serviceName := printf "sasha-%s" $sashaName -}}
 apiVersion: apps/v1
 kind: Deployment
@@ -46,7 +46,7 @@ spec:
 ---
 {{- end }}
 kind: ConfigMap 
-{{ include "hpcc.sashaConfigMap" $commonCtx }}
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.sashaConfigMap")) }}
 ---
 {{- if $sasha.storage }}
 {{- if and (not $sasha.storage.existingClaim) (not $sasha.storage.plane) }}
diff --git a/helm/hpcc/templates/thor.yaml b/helm/hpcc/templates/thor.yaml
index 8a907b149..f6931442b 100644
--- a/helm/hpcc/templates/thor.yaml
+++ b/helm/hpcc/templates/thor.yaml
@@ -11,14 +11,15 @@ Pass in dict with root and me
 {{- $thorScope := omit .me "eclagent" "thoragent" "hthor" "logging" "eclAgentResources" "eclAgentUseChildProcesses" "eclAgentReplicas" "thorAgentReplicas" "eclAgentType" }}
 {{- $misc := .root.Values.global.misc | default dict }}
 {{- $postJobCommand := $misc.postJobCommand | default "" }}
-{{- $eclAgentJobName := printf "%s-%%jobname" $eclAgentType }}
-{{- $thorManagerJobName := printf "thormanager-%%jobname" }}
-{{- $thorWorkerJobName := printf "thorworker-%%jobname" }}
+{{- $eclAgentJobName := printf "%s-_HPCC_JOBNAME_" $eclAgentType }}
+{{- $thorManagerJobName := printf "thormanager-_HPCC_JOBNAME_" }}
+{{- $thorWorkerJobName := printf "thorworker-_HPCC_JOBNAME_" }}
+{{- $thorNetworkPolicyName := printf "thornetworkpolicy-_HPCC_JOBNAME_" }}
 apiVersion: v1 
 metadata:
   name: {{ $thorScope.name }}-configmap
 data:
-  {{ $thorScope.name }}.yaml: |
+  {{ $thorScope.name }}.yaml:
     version: 1.0
     thor:
 {{ toYaml $thorScope | indent 6 }}
@@ -42,7 +43,7 @@ data:
 {{ include "hpcc.generateGlobalConfigMap" .root| indent 6 }}
 
 {{- if not .eclAgentUseChildProcesses }}
-  {{ $eclAgentType }}-jobspec.yaml: |
+  {{ $eclAgentType }}-jobspec.yaml:
     apiVersion: batch/v1
     kind: Job
     metadata:
@@ -70,7 +71,7 @@ data:
 {{- include "hpcc.addSecurityContext" . | indent 12 }}
 {{ include "hpcc.addImageAttrs" . | indent 12 }}
 {{- include "hpcc.addResources" (dict "me" .eclAgentResources) | indent 12 }}
-{{- $agentCmd := printf "%s %s %s %%args" $eclAgentType (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
+{{- $agentCmd := printf "%s %s %s _HPCC_ARGS_" $eclAgentType (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
 {{ include "hpcc.addCommandAndLifecycle" (. | merge (dict "command" $agentCmd)) | indent 12 }}
             workingDir: /var/lib/HPCCSystems
             volumeMounts:
@@ -95,7 +96,7 @@ data:
       backoffLimit: 0
 {{- end }}
 
-  thormanager-jobspec.yaml: |
+  thormanager-jobspec.yaml:
     apiVersion: batch/v1
     kind: Job
     metadata:
@@ -108,7 +109,7 @@ data:
             app: thor
             accessDali: "yes"
             accessEsp: "yes"
-            job: %jobname
+            job: "_HPCC_JOBNAME_"
         spec:
           {{- include "hpcc.placementsByJobTargetType" (dict "root" .root "job" $thorManagerJobName "target" .me.name "type" "thor") | indent 10 }}
           serviceAccountName: hpcc-agent
@@ -125,7 +126,7 @@ data:
 {{- include "hpcc.addSecurityContext" . | indent 12 }}
 {{ include "hpcc.addImageAttrs" . | indent 12 }}
 {{- include "hpcc.addResources" (dict "me" $thorScope.managerResources) | indent 12 }}
-{{- $thorManagerCmd := printf "thormaster_lcr %s %s %%args" (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
+{{- $thorManagerCmd := printf "thormaster_lcr %s %s _HPCC_ARGS_" (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
 {{ include "hpcc.addCommandAndLifecycle" (. | merge (dict "command" $thorManagerCmd)) | indent 12 }}
             workingDir: /var/lib/HPCCSystems
             volumeMounts:
@@ -149,20 +150,20 @@ data:
           restartPolicy: Never
       backoffLimit: 0
 
-  thorworker-jobspec.yaml: |
+  thorworker-jobspec.yaml:
     apiVersion: batch/v1
     kind: Job
     metadata:
       name: {{ $thorWorkerJobName }}
     spec:
-      parallelism: %numWorkers
+      parallelism: _HPCC_NUM_WORKERS_
       ttlSecondsAfterFinished: 100
       template:
         metadata:
           labels:
             app: thor
             accessEsp: "true"
-            job: %jobname
+            job: "_HPCC_JOBNAME_"
         spec:
           {{- include "hpcc.placementsByJobTargetType" (dict "root" .root "job" $thorWorkerJobName "target" .me.name "type" "thor") | indent 10 }}
           serviceAccountName: hpcc-default
@@ -177,7 +178,7 @@ data:
 {{- include "hpcc.addSecurityContext" . | indent 12 }}
 {{ include "hpcc.addImageAttrs" . | indent 12 }}
 {{- include "hpcc.addResources" (dict "me" $thorScope.workerResources) | indent 12 }}
-{{- $thorWorkerCmd := printf "thorslave_lcr %s %s %%args" (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
+{{- $thorWorkerCmd := printf "thorslave_lcr %s %s _HPCC_ARGS_" (include "hpcc.configArg" .me) (include "hpcc.daliArg" .root) }}
 {{ include "hpcc.addCommandAndLifecycle" (. | merge (dict "command" $thorWorkerCmd)) | indent 12 }}
             workingDir: /var/lib/HPCCSystems
             volumeMounts:
@@ -201,28 +202,28 @@ data:
           restartPolicy: Never
       backoffLimit: 0
 
-  thormanager-networkspec.yaml: |
+  thor-networkspec.yaml:
     apiVersion: networking.k8s.io/v1
     kind: NetworkPolicy
     metadata:
-      name: {{ $thorManagerJobName }}
+      name: {{ $thorNetworkPolicyName }}
     spec:
       podSelector:
         matchLabels:
           app: thor
-          job: %jobname
+          job: "_HPCC_JOBNAME_"
       ingress:
       - from:
         - podSelector:
             matchLabels:
               app: thor
-              job: %jobname
+              job: "_HPCC_JOBNAME_"
       egress:
       - to:
         - podSelector:
             matchLabels:
               app: thor
-              job: %jobname
+              job: "_HPCC_JOBNAME_"
 {{- end -}}
 
 {{- $local := dict "first" true }}
@@ -235,7 +236,7 @@ data:
 {{- $_ := set $commonCtx "eclAgentUseChildProcesses" (hasKey . "eclAgentUseChildProcesses" | ternary .eclAgentUseChildProcesses true) }}
 {{- $_ := set $commonCtx "eclAgentReplicas" (.eclAgentReplicas | default 1) }}
 {{- $_ := set $commonCtx "thorAgentReplicas" (.thorAgentReplicas | default 1) }}
-{{- $configSHA := include "hpcc.thorConfigMap" $commonCtx | sha256sum }}
+{{- $configSHA := include "hpcc.getConfigSHA" ($commonCtx | merge (dict "configMapHelper" "hpcc.thorConfigMap" "component" "thor" "excludeKeys" "global")) }}
 {{- include "hpcc.checkDefaultStoragePlane" $commonCtx }}
 apiVersion: apps/v1
 kind: Deployment
@@ -335,7 +336,7 @@ spec:
 {{ include "hpcc.addCertificateVolume" (dict "root" $ "name" $commonCtx.thorAgentName "component" "thoragent") | indent 6 }}
 ---
 kind: ConfigMap
-{{ include "hpcc.thorConfigMap" $commonCtx }}
+{{ include "hpcc.generateConfig" ($commonCtx | merge (dict "configMapHelper" "hpcc.thorConfigMap")) }}
 ---
 {{ include "hpcc.addCertificate" (dict "root" $ "name" $commonCtx.eclAgentName "component" "eclagent") }}
 {{ include "hpcc.addCertificate" (dict "root" $ "name" $commonCtx.thorAgentName "component" "thoragent") }}
diff --git a/helm/hpcc/values.schema.json b/helm/hpcc/values.schema.json
index 59036eddc..d8531a826 100644
--- a/helm/hpcc/values.schema.json
+++ b/helm/hpcc/values.schema.json
@@ -229,6 +229,9 @@
         "privileged": {
           "type": "boolean"
         },
+        "noResourceValidation": {
+          "type": "boolean"
+        },
         "image": {
           "$ref": "#/definitions/image"
         },
@@ -763,6 +766,11 @@
           "description": "The default storage plane to write data files to",
           "type": "string"
         },
+        "storagePlanes": {
+          "description": "A list of storage planes suitable for storing roxie data",
+          "type": "array",
+          "items": { "type": "string" }
+        },
         "spillPlane": {
           "description": "The storage plane to write spill files to",
           "type": "string"
diff --git a/plugins/couchbase/couchbaseembed.cpp b/plugins/couchbase/couchbaseembed.cpp
index ff6d55ccf..f3cf445f0 100644
--- a/plugins/couchbase/couchbaseembed.cpp
+++ b/plugins/couchbase/couchbaseembed.cpp
@@ -176,13 +176,11 @@ namespace couchbaseembed
         if (pQcmd)
         {
             size32_t utf8chars;
-            char *utf8;
-            rtlStrToUtf8X(utf8chars, utf8, len, value);
-            auto status = pQcmd->named_param(cbPlaceholder.str(), utf8);
+            rtlDataAttr utf8;
+            rtlStrToUtf8X(utf8chars, utf8.refstr(), len, value);
+            auto status = pQcmd->named_param(cbPlaceholder.str(), utf8.getstr());
             if (!status.success())
-                failx("Could not bind Param: %s val: %s", cbPlaceholder.str(), utf8);
-            if (utf8)
-                rtlFree(utf8);
+                failx("Could not bind Param: %s val: %s", cbPlaceholder.str(), utf8.getstr());
         }
         else
             failx("Internal error: detected invalid CouchbaseQueryCommand while attempting to bind to field: %s", cbPlaceholder.str());
@@ -211,14 +209,12 @@ namespace couchbaseembed
         if (pQcmd)
         {
             size32_t bytes;
-            void *data;
-            rtlStrToDataX(bytes, data, len, value);
+            rtlDataAttr data;
+            rtlStrToDataX(bytes, data.refdata(), len, value);
 
-            auto status = pQcmd->named_param(cbPlaceholder.str(), (char *)data);
+            auto status = pQcmd->named_param(cbPlaceholder.str(), data.getstr());
             if (!status.success())
-                failx("Could not bind Param: %s val: %s", cbPlaceholder.str(), (char *)data);
-            if (data)
-                rtlFree(data);
+                failx("Could not bind Param: %s val: %s", cbPlaceholder.str(), data.getstr());
         }
         else
             failx("Internal error: detected invalid CouchbaseQueryCommand while attempting to bind to field: %s", cbPlaceholder.str());
@@ -1126,13 +1122,11 @@ namespace couchbaseembed
         checkNextParam(name);
         VStringBuffer cbPlaceholder("$%s", name);
         size32_t bytes;
-        void *data;
-        rtlStrToDataX(bytes, data, len, val);
-        auto status = m_pQcmd->named_param(cbPlaceholder.str(), (char *)data);
+        rtlDataAttr data;
+        rtlStrToDataX(bytes, data.refdata(), len, val);
+        auto status = m_pQcmd->named_param(cbPlaceholder.str(), data.getstr());
         if (!status.success())
-            failx("Could not bind Param: %s val: %s", cbPlaceholder.str(), (char *)data);
-        if (data)
-            rtlFree(data);
+            failx("Could not bind Param: %s val: %s", cbPlaceholder.str(), data.getstr());
     }
 
     void CouchbaseEmbedFunctionContext::bindFloatParam(const char *name, float val)
@@ -1200,13 +1194,11 @@ namespace couchbaseembed
         checkNextParam(name);
         VStringBuffer cbPlaceholder("$%s", name);
         size32_t utf8chars;
-        char *utf8;
-        rtlStrToUtf8X(utf8chars, utf8, len, val);
-        auto status = m_pQcmd->named_param(cbPlaceholder.str(), utf8);
+        rtlDataAttr utf8;
+        rtlStrToUtf8X(utf8chars, utf8.refstr(), len, val);
+        auto status = m_pQcmd->named_param(cbPlaceholder.str(), utf8.getstr());
         if (!status.success())
-            failx("Could not bind Param: %s val: %s", cbPlaceholder.str(), utf8);
-        if (utf8)
-            rtlFree(utf8);
+            failx("Could not bind Param: %s val: %s", cbPlaceholder.str(), utf8.getstr());
     }
 
     void CouchbaseEmbedFunctionContext::bindVStringParam(const char *name, const char *val)
diff --git a/plugins/fileservices/fileservices.cpp b/plugins/fileservices/fileservices.cpp
index a1a04148b..eba8081ee 100644
--- a/plugins/fileservices/fileservices.cpp
+++ b/plugins/fileservices/fileservices.cpp
@@ -2897,12 +2897,14 @@ FILESERVICES_API void FILESERVICES_CALL fsDfuPlusExec(ICodeContext * ctx,const c
 FILESERVICES_API char * FILESERVICES_CALL fsGetEspURL(const char *username, const char *userPW)
 {
 #ifdef _CONTAINERIZED
-    const char *defaultEsp = queryComponentConfig().queryProp("@defaultEsp");
+    Owned<IPropertyTree> compConfig = getComponentConfig();
+    const char *defaultEsp = compConfig->queryProp("@defaultEsp");
+    Owned<IPropertyTree> globalConfig = getGlobalConfig();
     if (isEmptyString(defaultEsp))
-        defaultEsp = queryGlobalConfig().queryProp("@defaultEsp");
+        defaultEsp = globalConfig->queryProp("@defaultEsp");
     if (isEmptyString(defaultEsp))
     {
-        Owned<IPropertyTreeIterator> esps = queryGlobalConfig().getElements("esp");
+        Owned<IPropertyTreeIterator> esps = globalConfig->getElements("esp");
         ForEach(*esps)
         {
             const char *application = esps->query().queryProp("@application");
@@ -2929,7 +2931,7 @@ FILESERVICES_API char * FILESERVICES_CALL fsGetEspURL(const char *username, cons
         VStringBuffer espInfo("esp[@name='%s']", defaultEsp);
         const char *protocol = "https";
         unsigned port = 8010;
-        const IPropertyTree *espconfig = queryGlobalConfig().queryPropTree(espInfo);
+        const IPropertyTree *espconfig = globalConfig->queryPropTree(espInfo);
         if (espconfig)
         {
             if (!espconfig->getPropBool("@tls", true))
diff --git a/roxie/ccd/ccdcontext.cpp b/roxie/ccd/ccdcontext.cpp
index 867230d20..62f527410 100644
--- a/roxie/ccd/ccdcontext.cpp
+++ b/roxie/ccd/ccdcontext.cpp
@@ -1617,7 +1617,8 @@ public:
 
         if (realThor)
         {
-            executeThorGraph(name, *workUnit, queryComponentConfig());
+            Owned<IPropertyTree> compConfig = getComponentConfig();
+            executeThorGraph(name, *workUnit, *compConfig);
         }
         else
         {
diff --git a/roxie/ccd/ccdfile.cpp b/roxie/ccd/ccdfile.cpp
index f047840df..fa761391b 100644
--- a/roxie/ccd/ccdfile.cpp
+++ b/roxie/ccd/ccdfile.cpp
@@ -46,7 +46,7 @@
 #include "eclhelper_dyn.hpp"
 #include "rtldynfield.hpp"
 
-atomic_t numFilesOpen[2];
+std::atomic<unsigned> numFilesOpen[2];
 
 #define MAX_READ_RETRIES 2
 
@@ -206,7 +206,7 @@ public:
         {
             if (current.get()==&failure)
                 return;
-            atomic_dec(&numFilesOpen[remote]);
+            numFilesOpen[remote]--;
             mergeStats(fileStats, current);
             current.set(&failure); 
         }
@@ -314,8 +314,7 @@ public:
                 }
             }
             lastAccess = msTick();
-            atomic_inc(&numFilesOpen[remote]);
-            if ((unsigned) atomic_read(&numFilesOpen[remote]) > maxFilesOpen[remote])
+            if (++numFilesOpen[remote] > maxFilesOpen[remote])
                 queryFileCache().closeExpired(remote); // NOTE - this does not actually do the closing of expired files (which could deadlock, or could close the just opened file if we unlocked crit)
         }
     }
@@ -1221,12 +1220,13 @@ public:
         started = false;
         if (!selfTestMode && !allFilesDynamic)
         {
-            offset_t cacheTrackSize = queryComponentConfig().getPropInt64("@cacheTrackSize", (offset_t) -1);
+            Owned<IPropertyTree> compConfig = getComponentConfig();
+            offset_t cacheTrackSize = compConfig->getPropInt64("@cacheTrackSize", (offset_t) -1);
             if (cacheTrackSize == (offset_t) -1)
             {
-                const char *memLimit = queryComponentConfig().queryProp("resources/limits/@memory");
+                const char *memLimit = compConfig->queryProp("resources/limits/@memory");
                 if (!memLimit)
-                    memLimit = queryComponentConfig().queryProp("resources/requests/@memory");
+                    memLimit = compConfig->queryProp("resources/requests/@memory");
                 if (memLimit)
                 {
                     try
@@ -1654,7 +1654,7 @@ public:
         if (!closePending[remote])
         {
             closePending[remote] = true;
-            DBGLOG("closeExpired %s scheduled - %d files open", remote ? "remote" : "local", (int) atomic_read(&numFilesOpen[remote]));
+            DBGLOG("closeExpired %s scheduled - %d files open", remote ? "remote" : "local", (int) numFilesOpen[remote]);
             toClose.signal();
         }
     }
diff --git a/roxie/ccd/ccdmain.cpp b/roxie/ccd/ccdmain.cpp
index 6620ab4a8..ccfcfcd2e 100644
--- a/roxie/ccd/ccdmain.cpp
+++ b/roxie/ccd/ccdmain.cpp
@@ -550,17 +550,9 @@ void readStaticTopology()
 
 int CCD_API roxie_main(int argc, const char *argv[], const char * defaultYaml)
 {
-#ifndef _CONTAINERIZED
-    for (unsigned i=0;i<(unsigned)argc;i++) {
-        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-            if (daemon(1,0) || write_pidfile(argv[++i])) {
-                perror("Failed to daemonize");
-                return EXIT_FAILURE;
-            }
-            break;
-        }
-    }
-#endif
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
+
     EnableSEHtoExceptionMapping();
     setTerminateOnSEH();
     init_signals();
diff --git a/roxie/ccd/ccdserver.cpp b/roxie/ccd/ccdserver.cpp
index a5d6fd6c1..43647a410 100644
--- a/roxie/ccd/ccdserver.cpp
+++ b/roxie/ccd/ccdserver.cpp
@@ -2160,27 +2160,27 @@ public:
 
 //=====================================================================================================
 
-atomic_t nextInstanceId;
+static std::atomic<unsigned> nextInstanceId;
 
 extern unsigned getNextInstanceId()
 {
-    return atomic_add_exchange(&nextInstanceId, 1)+1;
+    return ++nextInstanceId;
 }
 
-atomic_t nextRuid;
+static std::atomic<unsigned> nextRuid;
 
 ruid_t getNextRuid()
 {
-    ruid_t ret = atomic_add_exchange(&nextRuid, 1)+1;
+    ruid_t ret = ++nextRuid;
     while (ret < RUID_FIRST)
-        ret = atomic_add_exchange(&nextRuid, 1)+1; // ruids 0 and 1 are reserved for pings/unwanted discarder.
+        ret = ++nextRuid; // ruids 0 and 1 are reserved for pings/unwanted discarder.
     return ret;
 }
 
 void setStartRuid(unsigned restarts)
 {
-    atomic_set(&nextRuid, restarts * 0x10000);
-    atomic_set(&nextInstanceId, restarts * 10000);
+    nextRuid = restarts * 0x10000;
+    nextInstanceId = restarts * 10000;
 }
 
 enum { LimitSkipErrorCode = 0, KeyedLimitSkipErrorCode = 1 };
@@ -11586,8 +11586,6 @@ protected:
             OwnedRoxieString cluster(helper.getCluster(clusterIdx));
             if(!cluster)
                 break;
-            if (isContainerized())
-                throw makeStringException(0, "Output clusters not supported in cloud environment");
             clusters.append(cluster);
             clusterIdx++;
         }
@@ -11598,12 +11596,9 @@ protected:
         }
         else
         {
-            if (isContainerized() && fileNameServiceDali)
-            {
-                StringBuffer nasGroupName;
-                queryNamedGroupStore().getNasGroupName(nasGroupName, 1);
-                clusters.append(nasGroupName);
-            }
+            StringBuffer defaultCluster;
+            if (getDefaultStoragePlane(defaultCluster))
+                clusters.append(defaultCluster);
             else if (roxieName.length())
                 clusters.append(roxieName.str());
             else
@@ -12078,20 +12073,15 @@ class CRoxieServerIndexWriteActivity : public CRoxieServerInternalSinkActivity,
             OwnedRoxieString cluster(helper.getCluster(clusterIdx));
             if(!cluster)
                 break;
-            if (isContainerized())
-                throw makeStringException(0, "Output clusters not supported in cloud environment");
             clusters.append(cluster);
             clusterIdx++;
         }
 
         if (!clusters.length())
         {
-            if (isContainerized() && fileNameServiceDali)
-            {
-                StringBuffer nasGroupName;
-                queryNamedGroupStore().getNasGroupName(nasGroupName, 1);
-                clusters.append(nasGroupName);
-            }
+            StringBuffer defaultCluster;
+            if (getDefaultStoragePlane(defaultCluster))
+                clusters.append(defaultCluster);
             else if (roxieName.length())
                 clusters.append(roxieName.str());
             else
@@ -25175,7 +25165,7 @@ class CJoinGroup : public CInterface
 protected:
     const void *left;                   // LHS row
     PointerArrayOf<KeyedJoinHeader> rows;           // matching RHS rows
-    atomic_t endMarkersPending; // How many agent responses still waiting for
+    std::atomic<unsigned> endMarkersPending; // How many agent responses still waiting for
     CJoinGroup *groupStart;     // Head of group, or NULL if not grouping
     unsigned lastPartNo;
     unsigned pos;
@@ -25209,9 +25199,9 @@ public:
         groupStart = _groupStart;
         if (_groupStart)
         {
-            atomic_inc(&_groupStart->endMarkersPending);
+            ++_groupStart->endMarkersPending;
         }
-        atomic_set(&endMarkersPending, 1);
+        endMarkersPending = 1;
     }
 
     ~CJoinGroup()
@@ -25234,7 +25224,7 @@ public:
 
     inline bool complete() const
     {
-        return atomic_read(&endMarkersPending) == 0;
+        return endMarkersPending == 0;
     }
 
 #ifdef TRACE_JOINGROUPS
@@ -25244,9 +25234,9 @@ public:
 #endif
     {
         assert(!complete());
-        atomic_inc(&endMarkersPending);
+        ++endMarkersPending;
 #ifdef TRACE_JOINGROUPS
-        DBGLOG("CJoinGroup::notePending %p from %d, count became %d group count %d", this, lineNo, atomic_read(&endMarkersPending), groupStart ? atomic_read(&groupStart->endMarkersPending) : 0);
+        DBGLOG("CJoinGroup::notePending %p from %d, count became %d group count %d", this, lineNo, endMarkersPending.load(), groupStart ? groupStart->endMarkersPending.load() : 0);
 #endif
     }
 
@@ -25274,16 +25264,16 @@ public:
             candidates += candidateCount;
         }
 #ifdef TRACE_JOINGROUPS
-        DBGLOG("CJoinGroup::noteEndReceived %p from %d, candidates %d + %d, my count was %d, group count was %d", this, lineNo, candidates, candidateCount, atomic_read(&endMarkersPending), groupStart ? atomic_read(&groupStart->endMarkersPending) : 0);
+        DBGLOG("CJoinGroup::noteEndReceived %p from %d, candidates %d + %d, my count was %d, group count was %d", this, lineNo, candidates, candidateCount, endMarkersPending.load(), groupStart ? groupStart->endMarkersPending.load() : 0);
 #endif
         // NOTE - as soon as endMarkersPending and groupStart->endMarkersPending are decremented to zero this object may get released asynchronously by other threads
         // There must therefore be nothing in this method after them that acceses member variables. Think of it as a delete this...
         // In particular, we can't safely reference groupStart after the dec_and_test of endMarkersPending, hence copy local first 
         CJoinGroup *localGroupStart = groupStart;
-        if (atomic_dec_and_test(&endMarkersPending))
+        if (--endMarkersPending == 0)
         {
             if (localGroupStart)
-                return atomic_dec_and_test(&localGroupStart->endMarkersPending);
+                return --localGroupStart->endMarkersPending == 0;
             else
                 return true;
         }
diff --git a/roxie/ccd/ccdstate.cpp b/roxie/ccd/ccdstate.cpp
index 3010a0710..d5d789a2e 100644
--- a/roxie/ccd/ccdstate.cpp
+++ b/roxie/ccd/ccdstate.cpp
@@ -734,7 +734,7 @@ public:
         else if (daliHelper)
             user = daliHelper->queryUserDescriptor();//predeployed query mode
 
-        Owned<ILocalOrDistributedFile> ldFile = createLocalOrDistributedFile(fileName, user, onlyLocal, onlyDFS, true, isPrivilegedUser);
+        Owned<ILocalOrDistributedFile> ldFile = createLocalOrDistributedFile(fileName, user, onlyLocal, onlyDFS, true, isPrivilegedUser, &clusters);
         if (!ldFile)
             throw MakeStringException(ROXIE_FILE_ERROR, "Cannot write %s", fileName.str());
         return createRoxieWriteHandler(daliHelper, ldFile.getClear(), clusters);
@@ -1867,8 +1867,8 @@ public:
             daliHelper.setown(connectToDali());
         else
             daliHelper.setown(connectToDali(ROXIE_DALI_CONNECT_TIMEOUT));
-        atomic_set(&autoPending, 0);
-        atomic_set(&autoSignalsPending, 0);
+        autoPending = 0;
+        autoSignalsPending = 0;
         forcePending = false;
         pSetsNotifier.setown(daliHelper->getPackageSetsSubscription(this));
         pMapsNotifier.setown(daliHelper->getPackageMapsSubscription(this));
@@ -1891,8 +1891,8 @@ public:
         if (force)
             forcePending = true;    
         if (signal)
-            atomic_inc(&autoSignalsPending);
-        atomic_inc(&autoPending);
+            ++autoSignalsPending;
+        ++autoPending;
         autoReloadTrigger.signal();
         if (signal)
             autoReloadComplete.wait();
@@ -1973,8 +1973,8 @@ private:
 
     Semaphore autoReloadTrigger;
     Semaphore autoReloadComplete;
-    atomic_t autoSignalsPending;
-    atomic_t autoPending;
+    std::atomic<unsigned> autoSignalsPending;
+    std::atomic<unsigned> autoPending;
     bool forcePending;
 
     class AutoReloadThread : public Thread
@@ -1997,12 +1997,12 @@ private:
                 owner.autoReloadTrigger.wait();
                 if (closing)
                     break;
-                unsigned signalsPending = atomic_read(&owner.autoSignalsPending);
+                unsigned signalsPending = owner.autoSignalsPending;
                 if (!signalsPending)
                     Sleep(500); // Typically notifications come in clumps - this avoids reloading too often
-                if (atomic_read(&owner.autoPending))
+                if (owner.autoPending)
                 {
-                    atomic_set(&owner.autoPending, 0);
+                    owner.autoPending = 0;
                     try
                     {
                         owner.reload(owner.forcePending);
@@ -2021,7 +2021,7 @@ private:
                 }
                 if (signalsPending)
                 {
-                    atomic_dec(&owner.autoSignalsPending);
+                    owner.autoSignalsPending--;
                     owner.autoReloadComplete.signal();
                 }
             }
diff --git a/roxie/roxiemem/roxiemem.cpp b/roxie/roxiemem/roxiemem.cpp
index bacbb961d..4aa53e5ab 100644
--- a/roxie/roxiemem/roxiemem.cpp
+++ b/roxie/roxiemem/roxiemem.cpp
@@ -1533,7 +1533,7 @@ public:
             return;
         //The function is to aid testing - it allows the cas code to be tested without a surrounding lock
         //Allocate all possible rows and add them to the free space map.
-        //This is not worth doing in general because it effectively replaces atomic_sets with atomic_cas
+        //This is not worth doing in general because it effectively replaces atomic sets with atomic cas
         //relaxed memory order since there will be no multi-threaded access
         unsigned nextFree = freeBase.load(std::memory_order_relaxed);
         unsigned nextBlock = r_blocks.load(std::memory_order_relaxed);
@@ -4275,7 +4275,7 @@ protected:
     unsigned backgroundReleaseCost;
     bool releaseWhenModifyCallback;
     bool releaseWhenModifyCallbackCritical;
-    volatile bool abortBufferThread;
+    std::atomic_bool abortBufferThread;
 };
 
 //Constants are here to ensure they can all be constant folded
diff --git a/roxie/topo/toposerver.cpp b/roxie/topo/toposerver.cpp
index cd2040b9e..c3d75c78f 100644
--- a/roxie/topo/toposerver.cpp
+++ b/roxie/topo/toposerver.cpp
@@ -295,6 +295,10 @@ int main(int argc, const char *argv[])
     EnableSEHtoExceptionMapping();
     setTerminateOnSEH();
     init_signals();
+
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
+
     // We need to do the above BEFORE we call InitModuleObjects
     try
     {
@@ -318,14 +322,6 @@ int main(int argc, const char *argv[])
                 topo_server_usage();
                 return EXIT_SUCCESS;
             }
-#ifndef _CONTAINERIZED
-            else if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-                if (daemon(1,0) || write_pidfile(argv[++i])) {
-                    perror("Failed to daemonize");
-                    return EXIT_FAILURE;
-                }
-            }
-#endif
         }
 
         // locate settings xml file in runtime dir
diff --git a/roxie/udplib/udptrs.cpp b/roxie/udplib/udptrs.cpp
index af8f17b16..f0bfe13a6 100644
--- a/roxie/udplib/udptrs.cpp
+++ b/roxie/udplib/udptrs.cpp
@@ -66,7 +66,7 @@ using roxiemem::DataBuffer;
 
  *
  * Data races to watch for
- * 1. Two agent threads add data at same time - only one should sent rts (use atomic_inc for the count)
+ * 1. Two agent threads add data at same time - only one should sent rts (use atomic inc for the count)
  * 2. We check for timeout and resend rts or fail just as permission comes in
  *    - resend rts is harmless ?
  *    - fail is acceptable
diff --git a/rtl/eclrtl/eclrtl.cpp b/rtl/eclrtl/eclrtl.cpp
index 02982da4a..66d9a1eac 100644
--- a/rtl/eclrtl/eclrtl.cpp
+++ b/rtl/eclrtl/eclrtl.cpp
@@ -6272,10 +6272,14 @@ void rtlBase64Decode(size32_t & tlen, void * & tgt, size32_t slen, const char *
 
 //---------------------------------------------------------------------------
 
-void RtlCInterface::Link() const            { atomic_inc(&xxcount); }
+void RtlCInterface::Link() const
+{
+    xxcount++;
+}
+
 bool RtlCInterface::Release(void) const
 {
-    if (atomic_dec_and_test(&xxcount))
+    if (--xxcount == 0)
     {
         delete this;
         return true;
diff --git a/rtl/eclrtl/eclrtl_imp.hpp b/rtl/eclrtl/eclrtl_imp.hpp
index b7bfa9079..f13c4c0d7 100644
--- a/rtl/eclrtl/eclrtl_imp.hpp
+++ b/rtl/eclrtl/eclrtl_imp.hpp
@@ -186,28 +186,16 @@ private:
     IUStrRegExprFindInstance * instance;
 };
 
-//Code is cloned from jiface.hpp + split into two to avoid including too much in generated code.
-#ifdef _WIN32
-typedef volatile long atomic_t;
-#define atomic_set(v,i) ((*v) = (i))
-#else
-#ifndef atomic_set
-typedef struct { volatile int counter; } atomic_t;
-#define atomic_set(v,i) (((v)->counter) = (i))
-#endif
-#endif
-
 class ECLRTL_API RtlCInterface
 {
 public:
-             RtlCInterface()        { atomic_set(&xxcount, 1); }
     virtual ~RtlCInterface()        { }
 //interface IInterface:
     void    Link() const;
     bool    Release(void) const;
 
 private:
-    mutable atomic_t    xxcount;
+    mutable std::atomic<unsigned> xxcount{1};
 };
 
 
diff --git a/rtl/eclrtl/rtldynfield.cpp b/rtl/eclrtl/rtldynfield.cpp
index ca32f0ce6..14f60d4ca 100644
--- a/rtl/eclrtl/rtldynfield.cpp
+++ b/rtl/eclrtl/rtldynfield.cpp
@@ -1902,6 +1902,146 @@ extern ECLRTL_API const IDynamicTransform *createRecordTranslatorViaCallback(con
     return new GeneralRecordTranslator(destRecInfo, srcRecInfo, false, rawType);
 }
 
+//---------------------------------------------------------------------------------------------------------------------
+
+class CloneVirtualRecordTranslator : public CInterfaceOf<IDynamicTransform>
+{
+public:
+    CloneVirtualRecordTranslator(const RtlRecord &_destRecInfo, IOutputMetaData & _sourceMeta)
+        : destRecInfo(_destRecInfo), sourceMeta(_sourceMeta)
+    {
+        init();
+    }
+// IDynamicTransform impl.
+    virtual void describe() const override
+    {
+        doDescribe(0);
+    }
+    virtual size32_t translate(ARowBuilder &builder, IVirtualFieldCallback & callback, const byte *sourceRec) const override
+    {
+        size32_t sourceSize = sourceMeta.getRecordSize(sourceRec);
+        return doAppendVirtuals(builder, callback, 0, sourceSize, sourceRec);
+    }
+    virtual size32_t translate(ARowBuilder &builder, IVirtualFieldCallback & callback, const RtlRow &sourceRow) const override
+    {
+        const byte * source = sourceRow.queryRow();
+        size32_t sourceSize = sourceMeta.getRecordSize(source);
+        return doAppendVirtuals(builder, callback, 0, sourceSize, source);
+    }
+    virtual size32_t translate(ARowBuilder &builder, IVirtualFieldCallback & callback, const IDynamicFieldValueFetcher & fetcher) const override
+    {
+        throwUnexpected();
+    }
+    virtual bool canTranslate() const override
+    {
+        return true;
+    }
+    virtual bool needsTranslate() const override
+    {
+        return true;
+    }
+    virtual bool needsNonVirtualTranslate() const override
+    {
+        return false;
+    }
+    virtual bool keyedTranslated() const override
+    {
+        return false;
+    }
+private:
+    void doDescribe(unsigned indent) const
+    {
+        for (unsigned idx = firstVirtual; idx < destRecInfo.getNumFields(); idx++)
+        {
+            const RtlFieldInfo *field = destRecInfo.queryField(idx);
+            const char * dest = destRecInfo.queryName(idx);
+            const char * result = "";
+            switch (getVirtualInitializer(field->initializer))
+            {
+            case FVirtualFilePosition:
+                result = "FILEPOSITION";
+                break;
+            case FVirtualLocalFilePosition:
+                result = "LOCALFILEPOSITION";
+                break;
+            case FVirtualFilename:
+                result = "LOGICALFILENAME";
+                break;
+            }
+            DBGLOG("Use virtual(%s) for field %s", result, dest);
+        }
+    }
+    size32_t doAppendVirtuals(ARowBuilder &builder, IVirtualFieldCallback & callback, size32_t offset, size32_t sourceSize, const void *sourceRow) const
+    {
+        size32_t estimate = sourceSize + fixedVirtualSize;
+        builder.ensureCapacity(offset+estimate, "record");
+        memcpy(builder.getSelf() + offset, sourceRow, sourceSize);
+
+        unsigned destOffset = offset + sourceSize;
+        for (unsigned idx = firstVirtual; idx < destRecInfo.getNumFields(); idx++)
+        {
+            const RtlFieldInfo *field = destRecInfo.queryField(idx);
+            const RtlTypeInfo *type = field->type;
+            switch (getVirtualInitializer(field->initializer))
+            {
+            case FVirtualFilePosition:
+                destOffset = type->buildInt(builder, destOffset, field, callback.getFilePosition(sourceRow));
+                break;
+            case FVirtualLocalFilePosition:
+                destOffset = type->buildInt(builder, destOffset, field, callback.getLocalFilePosition(sourceRow));
+                break;
+            case FVirtualFilename:
+                {
+                    const char * filename = callback.queryLogicalFilename(sourceRow);
+                    destOffset = type->buildString(builder, destOffset, field, strlen(filename), filename);
+                    break;
+                }
+            default:
+                throwUnexpected();
+            }
+        }
+        return destOffset;
+    }
+
+    void init()
+    {
+        unsigned idx = 0;
+        for (; idx < destRecInfo.getNumFields(); idx++)
+        {
+            const RtlFieldInfo *field = destRecInfo.queryField(idx);
+            const byte * initializer = (const byte *) field->initializer;
+            if (isVirtualInitializer(initializer))
+                break;
+        }
+        firstVirtual = idx;
+
+        size32_t size = 0;
+        for (; idx < destRecInfo.getNumFields(); idx++)
+        {
+            const RtlFieldInfo *field = destRecInfo.queryField(idx);
+            const RtlTypeInfo *type = field->type;
+            const byte * initializer = (const byte *) field->initializer;
+            assertex(isVirtualInitializer(initializer));
+            size += type->getMinSize();
+        }
+
+        fixedVirtualSize = size;
+    }
+
+protected:
+    const RtlRecord &destRecInfo;
+    IOutputMetaData & sourceMeta;
+    unsigned firstVirtual = 0;
+    size32_t fixedVirtualSize = 0;
+};
+
+
+extern ECLRTL_API const IDynamicTransform *createCloneVirtualRecordTranslator(const RtlRecord &_destRecInfo, IOutputMetaData & _source)
+{
+    return new CloneVirtualRecordTranslator(_destRecInfo, _source);
+}
+
+//---------------------------------------------------------------------------------------------------------------------
 extern ECLRTL_API void throwTranslationError(const RtlRecord & destRecInfo, const RtlRecord & srcRecInfo, const char * filename)
 {
     Owned<const IDynamicTransform> translator = createRecordTranslator(destRecInfo, srcRecInfo);
diff --git a/rtl/eclrtl/rtldynfield.hpp b/rtl/eclrtl/rtldynfield.hpp
index 3df339980..2e7ae6f1d 100644
--- a/rtl/eclrtl/rtldynfield.hpp
+++ b/rtl/eclrtl/rtldynfield.hpp
@@ -133,8 +133,8 @@ interface IDynamicTransform : public IInterface
 {
     virtual void describe() const = 0;
     virtual size32_t translate(ARowBuilder &builder, IVirtualFieldCallback & callback, const byte *sourceRec) const = 0;
-    virtual size32_t translate(ARowBuilder &builder, IVirtualFieldCallback & callback, const RtlRow &sourceRow) const = 0;
-    virtual size32_t translate(ARowBuilder &builder, IVirtualFieldCallback & callback, const IDynamicFieldValueFetcher & fetcher) const = 0;
+    virtual size32_t translate(ARowBuilder &builder, IVirtualFieldCallback & callback, const RtlRow &sourceRow) const = 0;  // allows offsets to be reused if already calculated
+    virtual size32_t translate(ARowBuilder &builder, IVirtualFieldCallback & callback, const IDynamicFieldValueFetcher & fetcher) const = 0; // called when reading from non binary e.g. xml/csv
     virtual bool canTranslate() const = 0;
     virtual bool needsTranslate() const = 0;
     virtual bool keyedTranslated() const = 0;
@@ -181,6 +181,7 @@ interface IDynamicTransformViaCallback : public IInterface
 };
 
 extern ECLRTL_API const IDynamicTransform *createRecordTranslator(const RtlRecord &_destRecInfo, const RtlRecord &_srcRecInfo);
+extern ECLRTL_API const IDynamicTransform *createCloneVirtualRecordTranslator(const RtlRecord &_destRecInfo, IOutputMetaData & _source);
 extern ECLRTL_API const IDynamicTransform *createRecordTranslatorViaCallback(const RtlRecord &_destRecInfo, const RtlRecord &_srcRecInfo, type_vals rawType);
 extern ECLRTL_API void throwTranslationError(const RtlRecord &_destRecInfo, const RtlRecord &_srcRecInfo, const char * filename);
 
diff --git a/rtl/eclrtl/rtlformat.cpp b/rtl/eclrtl/rtlformat.cpp
index 76787328e..4176c4c27 100644
--- a/rtl/eclrtl/rtlformat.cpp
+++ b/rtl/eclrtl/rtlformat.cpp
@@ -832,8 +832,9 @@ void CPropertyTreeWriter::outputString(unsigned len, const char *field, const ch
         len = rtlTrimStrLen(len, field);
     if ((flags & XWFopt) && (rtlTrimStrLen(len, field) == 0))
         return;
-    StringBuffer tmp(len, field);
-    target->setProp(fieldname, tmp.str());
+    StringBuffer tmp;
+    appendStringAsUtf8(tmp, len, field);
+    target->addProp(fieldname, tmp.str());
 }
 
 
@@ -897,8 +898,14 @@ void CPropertyTreeWriter::outputUnicode(unsigned len, const UChar *field, const
         len = rtlTrimUnicodeStrLen(len, field);
     if ((flags & XWFopt) && (rtlTrimUnicodeStrLen(len, field) == 0))
         return;
+
     StringBuffer fieldStr;
-    outputXmlUnicode(len, field, fieldname, fieldStr);
+    char * buff = 0;
+    unsigned bufflen = 0;
+    rtlUnicodeToCodepageX(bufflen, buff, len, field, "utf-8");
+    fieldStr.append(bufflen, buff);
+    rtlFree(buff);
+
     target->setProp(fieldname, fieldStr);
 }
 
@@ -909,8 +916,8 @@ void CPropertyTreeWriter::outputUtf8(unsigned len, const char *field, const char
     if ((flags & XWFopt) && (rtlTrimUtf8StrLen(len, field) == 0))
         return;
     StringBuffer fieldStr;
-    outputXmlUtf8(len, field, nullptr, fieldStr);
-    target->setProp(fieldname, fieldStr);
+    fieldStr.append(rtlUtf8Size(len, field), field);
+    target->setProp(fieldname, fieldStr); //MORE: addProp - discuss in code review!
 }
 
 void CPropertyTreeWriter::outputXmlns(const char *name, const char *uri)
diff --git a/rtl/include/eclhelper.hpp b/rtl/include/eclhelper.hpp
index 4a803daad..b04515e46 100644
--- a/rtl/include/eclhelper.hpp
+++ b/rtl/include/eclhelper.hpp
@@ -1110,6 +1110,7 @@ enum
     TDXupdateaccessed   = 0x0010,
     TDXdynamicfilename  = 0x0020,
     TDXjobtemp          = 0x0040,       // stay around while a wu is being executed.
+    TDXgeneric          = 0x0080,       // generic form of disk read/write
 
 //disk read flags
     TDRoptional         = 0x00000100,
@@ -1122,7 +1123,7 @@ enum
     TDRcountkeyedlimit  = 0x00008000,
     TDRkeyedlimitskips  = 0x00010000,
     TDRlimitskips       = 0x00020000,
-    //unused              0x00040000,
+    TDRfileposcallback  = 0x00040000,
     TDRaggregateexists  = 0x00080000,       // only aggregate is exists()
     TDRgroupmonitors    = 0x00100000,       // are segement monitors created for all group by conditions.
     TDRlimitcreates     = 0x00200000,
@@ -1132,6 +1133,8 @@ enum
     TDRtransformvirtual = 0x02000000,       // transform uses a virtual field.
     TDRdynformatoptions = 0x04000000,
     TDRinvariantfilename= 0x08000000,       // filename is non constant but has the same value for the whole query
+    TDRprojectleading   = 0x10000000,       // The projeted format matches leading fields of the source row (so no need to project if disappearing quickly)
+    TDRcloneappendvirtual = 0x20000000,     // Can clone the disk record and then append the virtual fields.
 
 //disk write flags
     TDWextend           = 0x0100,
@@ -2404,6 +2407,28 @@ struct IHThorIndexReadBaseArg : extends IHThorCompoundBaseArg
     virtual IHThorSteppedSourceExtra *querySteppingExtra() = 0;
 };
 
+
+/*
+ queryDiskRecordSize()
+    This is the expected record on disk.  It is always the serialialized form.  With the new disk reading implementation it may contain
+    the virtual fields as well as real fields.
+
+ queryProjectedDiskRecordSize()
+    This is the format that the transsform/match function expect as input.  It is generally the deserialized vesion of
+    the expected record with any fields that are not required removed.  If not transform is required then the row is
+    will match the queryOutputMetaData()
+
+There are some record formats that are not supported by the translation code (see canDefinitelyProcessWithTranslator() in hqlattr):
+    alien data types
+    dataset(record, count(x))
+    dataset(record, sizeof(x))
+    ifblock(complex-expression)
+
+    If these occur then the compound disk operations are disabled - field projection will not happen.  The projectedDiskRecordSize
+    will match the queryDiskRecordSize() and the transform will perform the deserialization.  The generated queryDiskRecordSize()
+    function will need to be used for calculating the size of the input record.
+
+*/
 struct IHThorDiskReadBaseArg : extends IHThorCompoundBaseArg
 {
     virtual const char * getFileName() = 0;
diff --git a/system/jlib/jatomic.hpp b/system/jlib/jatomic.hpp
index dab52ad69..b9f938b5f 100644
--- a/system/jlib/jatomic.hpp
+++ b/system/jlib/jatomic.hpp
@@ -155,193 +155,13 @@ bool compare_exchange_efficient(x & value, decltype(value.load()) expected, decl
 
 #ifdef _WIN32
 
-#include <intrin.h>
-
-extern "C"
-{
-   LONG  __cdecl _InterlockedIncrement(LONG volatile *Addend);
-   LONG  __cdecl _InterlockedDecrement(LONG volatile *Addend);
-   LONG  __cdecl _InterlockedCompareExchange(LONG volatile * Dest, LONG Exchange, LONG Comp);
-}
-
-#pragma intrinsic (_InterlockedCompareExchange)
-#define InterlockedCompareExchange _InterlockedCompareExchange
-#pragma intrinsic (_InterlockedIncrement)
-#define InterlockedIncrement _InterlockedIncrement
-#pragma intrinsic (_InterlockedDecrement)
-#define InterlockedDecrement _InterlockedDecrement
-#pragma intrinsic (_InterlockedExchangeAdd)
-#define InterlockedExchangeAdd _InterlockedExchangeAdd
-
-typedef volatile long atomic_t;
-#define ATOMIC_INIT(i)                  (i)
-#define atomic_inc(v)                   InterlockedIncrement(v)
-#define atomic_inc_and_test(v)          (InterlockedIncrement(v) == 0)
-#define atomic_dec(v)                   InterlockedDecrement(v)
-#define atomic_dec_and_test(v)          (InterlockedDecrement(v) == 0)
-#define atomic_dec_and_read(v)           InterlockedDecrement(v)
-#define atomic_read(v)                  (*v)
-#define atomic_set(v,i)                 ((*v) = (i))
-#define atomic_xchg(i, v)               InterlockedExchange(v, i)
-#define atomic_add(v,i)                 InterlockedExchangeAdd(v,i)
-#define atomic_add_and_read(v,i)        InterlockedAdd(v,i)
-#define atomic_add_exchange(v, i)       InterlockedExchangeAdd(v,i)
-#define atomic_xchg_ptr(p, v)           InterlockedExchangePointer(v,p)
-#if defined (_MSC_VER) && (_MSC_VER <= 1200)
-#define atomic_cas(v,newvalue,expectedvalue)    (InterlockedCompareExchange((PVOID *)(v),(PVOID)(long)(newvalue),(PVOID)(long)(expectedvalue))==(PVOID)(long)(expectedvalue))
-#define atomic_cas_ptr(v, newvalue,expectedvalue)       atomic_cas(v,(long)newvalue,(long)expectedvalue)
-#else
-#define atomic_cas(v,newvalue,expectedvalue)    (InterlockedCompareExchange(v,newvalue,expectedvalue)==expectedvalue)
-#define atomic_cas_ptr(v, newvalue,expectedvalue)       (InterlockedCompareExchangePointer(v,newvalue,expectedvalue)==expectedvalue)
-#endif
-
 //Used to prevent a compiler reordering volatile and non-volatile loads/stores
 #define compiler_memory_barrier()           _ReadWriteBarrier()
 
-#define atomic_acquire(v)               atomic_cas(v, 1, 0)
-#define atomic_release(v)               { compiler_memory_barrier(); atomic_set(v, 0); }
-
-#elif defined(__GNUC__)
-
-typedef struct { volatile int counter; } atomic_t;
-#define ATOMIC_INIT(i)          { (i) }
-#define atomic_read(v)          ((v)->counter)
-#define atomic_set(v,i)         (((v)->counter) = (i))
-
-static __inline__ bool atomic_dec_and_test(atomic_t *v)
-{   
-    // returns (--*v==0)
-    return (__sync_add_and_fetch(&v->counter,-1)==0);
-}
-
-static __inline__ bool atomic_inc_and_test(atomic_t *v)
-{
-    // returns (++*v==0)
-    return (__sync_add_and_fetch(&v->counter,1)==0);
-}
-
-static __inline__ void atomic_inc(atomic_t *v)
-{
-    // (*v)++
-    __sync_add_and_fetch(&v->counter,1);
-}
-
-static __inline__ void atomic_dec(atomic_t *v)
-{
-    // (*v)--
-    __sync_add_and_fetch(&v->counter,-1);
-}
-
-static __inline__ int atomic_dec_and_read(atomic_t *v)
-{
-    // (*v)--, return *v;
-    return __sync_add_and_fetch(&v->counter,-1);
-}
-
-static __inline__ int atomic_xchg(int i, atomic_t *v)
-{
-    // int ret = *v; *v = i; return v;
-    return __sync_lock_test_and_set(&v->counter,i);  // actually an xchg
-}
-
-
-
-static __inline__ void atomic_add(atomic_t *v,int i)
-{
-    // (*v) += i;
-    __sync_add_and_fetch(&v->counter,i);
-}
-
-static __inline__ int atomic_add_and_read(atomic_t *v,int i)
-{
-    // (*v) += i; return *v;
-    return __sync_add_and_fetch(&v->counter,i);
-}
-
-static __inline__ int atomic_add_exchange(atomic_t *v,int i)
-{
-    // int ret = *v; (*v) += i; return ret;
-    return __sync_fetch_and_add(&v->counter,i);
-}
-
-static __inline__ bool atomic_cas(atomic_t *v,int newvalue, int expectedvalue)
-{
-    // bool ret = (*v==expectedvalue); if (ret) *v = newvalue; return ret;
-    return __sync_bool_compare_and_swap(&v->counter, expectedvalue, newvalue);
-}
-
-static __inline__ void * atomic_xchg_ptr(void *p, void **v)
-{
-    // void * ret = *v; (*v) = p; return ret;
-    return (void *)__sync_lock_test_and_set((memsize_t *)v,(memsize_t)p);
-}
-
-static __inline__ bool atomic_cas_ptr(void **v,void *newvalue, void *expectedvalue)
-{
-    // bool ret = (*v==expectedvalue); if (ret) *v = newvalue; return ret;
-    return __sync_bool_compare_and_swap((memsize_t *)v, (memsize_t)expectedvalue, (memsize_t)newvalue);
-}
-
-#define compiler_memory_barrier() asm volatile("": : :"memory")
-
-static __inline__ bool atomic_acquire(atomic_t *v)
-{
-#if defined(_ARCH_X86_64_) || defined(_ARCH_X86_)
-    //For some reason gcc targeting x86 generates code for atomic_cas() that requires fewer registers
-    return atomic_cas(v, 1, 0);
 #else
-    return __sync_lock_test_and_set(&v->counter, 1) == 0;
-#endif
-}
 
-static __inline__ void atomic_release(atomic_t *v)
-{
-#if defined(_ARCH_X86_64_) || defined(_ARCH_X86_)
-    //x86 has a strong memory model, so the following code is sufficient, and some older gcc compilers generate
-    //an unnecessary mfence instruction, so for x86 use the following which generates better code.
-    compiler_memory_barrier();
-    atomic_set(v, 0);
-#else
-    __sync_lock_release(&v->counter);
-#endif
-}
-
-#else // other unix
-
-//Truely awful implementations of atomic operations...
-typedef volatile int atomic_t;
-int jlib_decl poor_atomic_dec_and_read(atomic_t * v);
-bool jlib_decl poor_atomic_inc_and_test(atomic_t * v);
-int jlib_decl poor_atomic_xchg(int i, atomic_t * v);
-void jlib_decl poor_atomic_add(atomic_t * v, int i);
-int jlib_decl poor_atomic_add_and_read(atomic_t * v, int i);
-int jlib_decl poor_atomic_add_exchange(atomic_t * v, int i);
-bool jlib_decl poor_atomic_cas(atomic_t * v, int newvalue, int expectedvalue);
-void jlib_decl *poor_atomic_xchg_ptr(void *p, void **v);
-bool   jlib_decl poor_atomic_cas_ptr(void ** v, void *newvalue, void *expectedvalue);
-void jlib_decl poor_compiler_memory_barrier();
-
-#define ATOMIC_INIT(i)                  (i)
-#define atomic_inc(v)                   (void)poor_atomic_inc_and_test(v)
-#define atomic_inc_and_test(v)          poor_atomic_inc_and_test(v)
-#define atomic_dec(v)                   (void)poor_atomic_dec_and_read(v)
-#define atomic_dec_and_read(v)          poor_atomic_dec_and_read(v)
-#define atomic_dec_and_test(v)          (poor_atomic_dec_and_read(v)==0)
-#define atomic_read(v)                  (*v)
-#define atomic_set(v,i)                 ((*v) = (i))
-#define atomic_xchg(i, v)               poor_atomic_xchg(i, v)
-#define atomic_add(v,i)                 poor_atomic_add(v, i)
-#define atomic_add_and_read(v,i)        poor_atomic_add_and_read(v, i)
-#define atomic_add_exchange(v, i)       poor_atomic_add_exchange(v, i)
-#define atomic_cas(v,newvalue,expectedvalue)    poor_atomic_cas(v,newvalue,expectedvalue)
-#define atomic_xchg_ptr(p, v)               poor_atomic_xchg_ptr(p, v)
-#define atomic_cas_ptr(v,newvalue,expectedvalue)    poor_atomic_cas_ptr(v,newvalue,expectedvalue)
-#define compiler_memory_barrier()       poor_compiler_memory_barrier()
-
-#define atomic_acquire(v)               atomic_cas(v, 1, 0)
-#define atomic_release(v)               { compiler_memory_barrier(); atomic_set(v, 0); }
+#define compiler_memory_barrier() asm volatile("": : :"memory")
 
 #endif
 
-
 #endif
diff --git a/system/jlib/jfile.cpp b/system/jlib/jfile.cpp
index ee49f8290..ffeb29255 100644
--- a/system/jlib/jfile.cpp
+++ b/system/jlib/jfile.cpp
@@ -858,16 +858,15 @@ bool CFile::fastCopyFile(CFile &target, size32_t buffersize, ICopyFileProgress *
 }
 
 
-void CFile::copySection(const RemoteFilename &dest, offset_t toOfs, offset_t fromOfs, offset_t size, ICopyFileProgress *progress, CFflags copyFlags)
+void copyFileSection(IFile * src, IFile * target, offset_t toOfs, offset_t fromOfs, offset_t size, ICopyFileProgress *progress, CFflags copyFlags)
 {
     // check to see if src and target are remote
 
-    Owned<IFile> target = createIFile(dest);
     const size32_t buffersize = DEFAULT_COPY_BLKSIZE;
     IFOmode omode = IFOwrite;
     if (toOfs==(offset_t)-1) {
         if (fromOfs==0) {
-            copyFile(target,this,buffersize,progress,copyFlags);
+            copyFile(target,src,buffersize,progress,copyFlags);
             return;
         }
         omode = IFOcreate;
@@ -884,9 +883,9 @@ void CFile::copySection(const RemoteFilename &dest, offset_t toOfs, offset_t fro
     IFEflags srcFlags = IFEnone;
     if (copyFlags & CFflush_read)
         srcFlags = IFEnocache;
-    OwnedIFileIO sourceIO = open(IFOread, srcFlags);
+    OwnedIFileIO sourceIO = src->open(IFOread, srcFlags);
     if (!sourceIO)
-        throw MakeStringException(-1, "copySection: source '%s' not found", queryFilename());
+        throw MakeStringException(-1, "copySection: source '%s' not found", src->queryFilename());
     
     offset_t offset = 0;
     offset_t total;
@@ -913,7 +912,7 @@ void CFile::copySection(const RemoteFilename &dest, offset_t toOfs, offset_t fro
     catch (IException *e)
     {
         StringBuffer s;
-        s.append("copyFile target=").append(target->queryFilename()).append(" source=").append(queryFilename()).append("; read/write failure").append(": ");
+        s.append("copyFile target=").append(target->queryFilename()).append(" source=").append(src->queryFilename()).append("; read/write failure").append(": ");
         e->errorMessage(s);
         IException *e2 = makeOsExceptionV(e->errorCode(), "%s", s.str());
         e->Release();
@@ -921,6 +920,12 @@ void CFile::copySection(const RemoteFilename &dest, offset_t toOfs, offset_t fro
     }
 }
 
+void CFile::copySection(const RemoteFilename &dest, offset_t toOfs, offset_t fromOfs, offset_t size, ICopyFileProgress *progress, CFflags copyFlags)
+{
+    Owned<IFile> target = createIFile(dest);
+    copyFileSection(this, target, toOfs, fromOfs, size, progress, copyFlags);
+}
+
 void CFile::copyTo(IFile *dest, size32_t buffersize, ICopyFileProgress *progress,bool usetmp,CFflags copyFlags)
 {
     doCopyFile(dest,this,buffersize,progress,NULL,usetmp,copyFlags);
diff --git a/system/jlib/jfile.hpp b/system/jlib/jfile.hpp
index e53f037c7..a21c57c39 100644
--- a/system/jlib/jfile.hpp
+++ b/system/jlib/jfile.hpp
@@ -635,6 +635,9 @@ const static bool filenamesAreCaseSensitive = true;
 extern jlib_decl IDirectoryIterator *getSortedDirectoryIterator(IFile *directory, SortDirectoryMode mode = SD_byname, bool rev = false, const char *mask = nullptr, bool sub = false, bool includedirs = false);
 extern jlib_decl IDirectoryIterator *getSortedDirectoryIterator(const char *dirName, SortDirectoryMode mode = SD_byname, bool rev = false, const char *mask = nullptr, bool sub = false, bool includedirs = false);
 
+//Locally copy from the source to the target
+extern jlib_decl void copyFileSection(IFile * src, IFile * target, offset_t toOfs, offset_t fromOfs, offset_t size, ICopyFileProgress *progress, CFflags copyFlags);
+
 //--------------------------------------------------------------------------------------------------------------------
 
 class jlib_decl FileIOStats
diff --git a/system/jlib/jiface.cpp b/system/jlib/jiface.cpp
index 9ffc8f1d4..62c4494bc 100644
--- a/system/jlib/jiface.cpp
+++ b/system/jlib/jiface.cpp
@@ -32,112 +32,3 @@ bool CInterface::Release() const
 {
     return CInterfaceOf<CEmptyClass>::Release();
 }
-
-//===========================================================================
-
-#if !defined(_WIN32) && !defined(__GNUC__)
-
-static CriticalSection *ICrit;
-
-MODULE_INIT(INIT_PRIORITY_JIFACE)
-{
-    ICrit = new CriticalSection();
-    return true;
-}
-MODULE_EXIT()
-{
-//  delete ICrit;  - need to make sure this is deleted after anything that uses it
-}
-
-int poor_atomic_dec_and_read(atomic_t * v)
-{
-    ICrit->enter();
-    int ret = --(*v);
-    ICrit->leave();
-    return ret;
-}
-
-bool poor_atomic_inc_and_test(atomic_t * v)
-{
-    ICrit->enter();
-    bool ret = (++(*v) == 0);
-    ICrit->leave();
-    return ret;
-}
-
-int poor_atomic_xchg(int i, atomic_t * v)
-{
-    ICrit->enter();
-    int prev = (*v);
-    (*v)=i;
-    ICrit->leave();
-    return prev;
-}
-
-void poor_atomic_add(atomic_t * v, int i)
-{
-    ICrit->enter();
-    (*v) += i;
-    ICrit->leave();
-}
-
-int poor_atomic_add_and_read(atomic_t * v, int i)
-{
-    ICrit->enter();
-    (*v) += i;
-    int ret = (*v);
-    ICrit->leave();
-    return ret;
-}
-
-int poor_atomic_add_exchange(atomic_t * v, int i)       
-{
-    ICrit->enter();
-    int prev = (*v);
-    (*v)=prev+i;
-    ICrit->leave();
-    return prev;
-}
-
-bool poor_atomic_cas(atomic_t * v, int newvalue, int expectedvalue)
-{
-    ICrit->enter();
-    bool ret = false;
-    if ((*v)==expectedvalue)
-    {
-        *v=newvalue;
-        ret = true;
-    }
-    ICrit->leave();
-    return ret;
-}
-
-void *poor_atomic_xchg_ptr(void *p, void** v)
-{
-    ICrit->enter();
-    void * prev = (*v);
-    (*v)=p;
-    ICrit->leave();
-    return prev;
-}
-
-bool poor_atomic_cas_ptr(void ** v, void * newvalue, void * expectedvalue)
-{
-    ICrit->enter();
-    bool ret = false;
-    if ((*v)==expectedvalue)
-    {
-        *v=newvalue;
-        ret = true;
-    }
-    ICrit->leave();
-    return ret;
-}
-
-//Hopefully the function call will be enough to stop the compiler reordering any operations
-void poor_compiler_memory_barrier()
-{
-}
-
-
-#endif
diff --git a/system/jlib/jlog.cpp b/system/jlib/jlog.cpp
index 0f31ad9e2..a1f388e5f 100644
--- a/system/jlib/jlog.cpp
+++ b/system/jlib/jlog.cpp
@@ -197,7 +197,7 @@ const char * LogMsgJobInfo::queryJobIDStr() const
     if (isDeserialized)
         return jobIDStr;
     else if (jobID == UnknownJob)
-        return "Unknown";
+        return "UNK";
     else
         return theManager->queryJobId(jobID);
 }
@@ -2548,7 +2548,7 @@ static constexpr bool useSysLogDefault = false;
 
 void setupContainerizedLogMsgHandler()
 {
-    IPropertyTree * logConfig = queryComponentConfig().queryPropTree("logging");
+    Owned<IPropertyTree> logConfig = getComponentConfigSP()->getPropTree("logging");
     if (logConfig)
     {
         if (logConfig->getPropBool(logQueueDisabledAtt, false))
diff --git a/system/jlib/jlog.hpp b/system/jlib/jlog.hpp
index bdd437fb5..52440cc56 100644
--- a/system/jlib/jlog.hpp
+++ b/system/jlib/jlog.hpp
@@ -310,7 +310,12 @@ typedef enum
 #define MSGFIELD_STANDARD LogMsgField(MSGFIELD_timeDate | MSGFIELD_msgID | MSGFIELD_process | MSGFIELD_thread | MSGFIELD_code | MSGFIELD_quote | MSGFIELD_prefix | MSGFIELD_audience)
 #define MSGFIELD_LEGACY LogMsgField(MSGFIELD_timeDate | MSGFIELD_milliTime | MSGFIELD_msgID | MSGFIELD_process | MSGFIELD_thread | MSGFIELD_code | MSGFIELD_quote | MSGFIELD_prefix)
 #else
+
+#ifdef _CONTAINERIZED
+#define MSGFIELD_STANDARD LogMsgField(MSGFIELD_job | MSGFIELD_timeDate | MSGFIELD_milliTime | MSGFIELD_msgID | MSGFIELD_process | MSGFIELD_thread | MSGFIELD_code | MSGFIELD_quote | MSGFIELD_class | MSGFIELD_audience)
+#else
 #define MSGFIELD_STANDARD LogMsgField(MSGFIELD_timeDate | MSGFIELD_milliTime | MSGFIELD_msgID | MSGFIELD_process | MSGFIELD_thread | MSGFIELD_code | MSGFIELD_quote | MSGFIELD_prefix | MSGFIELD_audience)
+#endif
 #define MSGFIELD_LEGACY LogMsgField(MSGFIELD_timeDate | MSGFIELD_milliTime | MSGFIELD_msgID | MSGFIELD_process | MSGFIELD_thread | MSGFIELD_code | MSGFIELD_quote | MSGFIELD_prefix)
 #endif
 
diff --git a/system/jlib/jmutex.cpp b/system/jlib/jmutex.cpp
index b9939a27a..00c8a854b 100644
--- a/system/jlib/jmutex.cpp
+++ b/system/jlib/jmutex.cpp
@@ -466,20 +466,6 @@ void ThreadYield()
 #endif
 }
 
-void spinUntilReady(atomic_t &value)
-{
-    unsigned i = 0;
-    const unsigned maxSpins = 10;
-    while (atomic_read(&value))
-    {
-        if (i++ == maxSpins)
-        {
-            i = 0;
-            ThreadYield();
-        }
-    }
-}
-
 void spinUntilReady(std::atomic_uint &value)
 {
     unsigned i = 0;
diff --git a/system/jlib/jmutex.hpp b/system/jlib/jmutex.hpp
index 110c66900..172528122 100644
--- a/system/jlib/jmutex.hpp
+++ b/system/jlib/jmutex.hpp
@@ -26,7 +26,6 @@
 #include "jsem.hpp"
 
 extern jlib_decl void ThreadYield();
-extern jlib_decl void spinUntilReady(atomic_t &value);
 extern jlib_decl void spinUntilReady(std::atomic_uint &value);
 
 
diff --git a/system/jlib/jptree.cpp b/system/jlib/jptree.cpp
index 4daa62df9..fea691fb0 100644
--- a/system/jlib/jptree.cpp
+++ b/system/jlib/jptree.cpp
@@ -18,6 +18,7 @@
 #include <unordered_map>
 #include <unordered_set>
 #include <string>
+#include <tuple>
 
 #include "platform.h"
 #include "jarray.hpp"
@@ -8499,8 +8500,10 @@ static void applyCommandLineOption(IPropertyTree * config, const char * option,
     applyCommandLineOption(config, option, val);
 }
 
+static CriticalSection configCS;
 static Owned<IPropertyTree> componentConfiguration;
 static Owned<IPropertyTree> globalConfiguration;
+
 MODULE_INIT(INIT_PRIORITY_STANDARD)
 {
     return true;
@@ -8511,18 +8514,30 @@ MODULE_EXIT()
     globalConfiguration.clear();
 }
 
-IPropertyTree & queryComponentConfig()
+IPropertyTree * getComponentConfig()
 {
+    CriticalBlock b(configCS);
     if (!componentConfiguration)
         throw makeStringException(99, "Configuration file has not yet been processed");
-    return *componentConfiguration;
+    return componentConfiguration.getLink();
 }
 
-IPropertyTree & queryGlobalConfig()
+IPropertyTree * getGlobalConfig()
 {
+    CriticalBlock b(configCS);
     if (!globalConfiguration)
         throw makeStringException(99, "Configuration file has not yet been processed");
-    return *globalConfiguration;
+    return globalConfiguration.getLink();
+}
+
+Owned<IPropertyTree> getComponentConfigSP()
+{
+    return getComponentConfig();
+}
+
+Owned<IPropertyTree> getGlobalConfigSP()
+{
+    return getGlobalConfig();
 }
 
 jlib_decl IPropertyTree * loadArgsIntoConfiguration(IPropertyTree *config, const char * * argv, std::initializer_list<const char *> ignoreOptions)
@@ -8546,12 +8561,128 @@ static void holdLoop()
 }
 #endif
 
-jlib_decl IPropertyTree * loadConfiguration(IPropertyTree *componentDefault, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute)
+#if defined(__linux__)
+static std::tuple<std::string, IPropertyTree *, IPropertyTree *> doLoadConfiguration(IPropertyTree *componentDefault, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute);
+
+class CConfigUpdater : public CInterface
 {
-    if (componentConfiguration)
-        throw makeStringExceptionV(99, "Configuration for component %s has already been initialised", componentTag);
+    StringAttr absoluteConfigFilename;
+    StringAttr configFilename;
+    Linked<IPropertyTree> componentDefault;
+    StringArray args;
+    StringAttr componentTag, envPrefix, legacyFilename;
+    IPropertyTree * (*mapper)(IPropertyTree *);
+    StringAttr altNameAttribute;
+    Owned<IFileEventWatcher> fileWatcher;
+    CriticalSection notifyFuncCS;
+    unsigned notifyFuncId = 0;
+    std::unordered_map<unsigned, ConfigUpdateFunc> notifyConfigUpdates;
+
+public:
+    CConfigUpdater(const char *_absoluteConfigFilename, IPropertyTree *_componentDefault, const char * * argv, const char * _componentTag, const char * _envPrefix, const char *_legacyFilename, IPropertyTree * (_mapper)(IPropertyTree *), const char *_altNameAttribute)
+        : absoluteConfigFilename(_absoluteConfigFilename), componentDefault(_componentDefault), componentTag(_componentTag), envPrefix(_envPrefix), legacyFilename(_legacyFilename), mapper(_mapper), altNameAttribute(_altNameAttribute)
+    {
+        while (const char *arg = *argv++)
+            args.append(arg);
+        args.append(nullptr);
+
+        auto updateFunc = [&](const char *filename, FileWatchEvents events)
+        {
+            bool changed = containsFileWatchEvents(events, FileWatchEvents::closedWrite) && streq(filename, configFilename);
+#ifdef _CONTAINERIZED
+            // NB: in k8s, it's a little strange, the config file is in a linked dir, a new dir is created and swapped in.
+            changed = changed | containsFileWatchEvents(events, FileWatchEvents::movedTo) && streq(filename, "..data");
+#endif
+            if (changed)
+            {
+                auto result = doLoadConfiguration(componentDefault, args.getArray(), componentTag, envPrefix, legacyFilename, mapper, altNameAttribute);
+
+                // NB: block calls to get*Config*() until callbacks notified and new swapped in
+                CriticalBlock b(configCS);
+                Owned<IPropertyTree> oldComponentConfiguration = componentConfiguration.getClear();
+                Owned<IPropertyTree> oldGlobalConfiguration = globalConfiguration.getClear();
+
+                /* swapin before callbacks called, but before releasing crit.
+                 * That way the CB can see the old/diffs and act on them, but any
+                 * code calling e.g. getComponentConfig() will see new.
+                 */
+                componentConfiguration.setown(std::get<1>(result));
+                globalConfiguration.setown(std::get<2>(result));
+
+                /* NB: we are still holding 'configCS' at this point, blocking all other thread access.
+                   However code in callbacks may call e.g. getComponentConfig() and re-enter the crit */
+                for (const auto &item: notifyConfigUpdates)
+                    item.second(oldComponentConfiguration, oldGlobalConfiguration);
+
+                absoluteConfigFilename.set(std::get<0>(result).c_str());
+            }
+        };
+
+        fileWatcher.setown(createFileEventWatcher(updateFunc));
+
+        // watch the path, not the filename, because the filename might not be seen if directories are moved, softlinks are changed..
+        StringBuffer path, filename;
+        splitFilename(absoluteConfigFilename, nullptr, &path, &filename, &filename);
+        configFilename.set(filename);
+        fileWatcher->add(path, FileWatchEvents::anyChange);
+        fileWatcher->start();
+    }
+    unsigned addNotifyFunc(ConfigUpdateFunc notifyFunc)
+    {
+        CriticalBlock b(notifyFuncCS);
+        notifyFuncId++;
+        notifyConfigUpdates[notifyFuncId] = notifyFunc;
+        return notifyFuncId;
+    }
+    bool removeNotifyFunc(unsigned funcId)
+    {
+        CriticalBlock b(notifyFuncCS);
+        return notifyConfigUpdates.erase(funcId) > 0;
+    }
+};
+
+static Owned<CConfigUpdater> configFileUpdater;
+
+unsigned installConfigUpdateHook(ConfigUpdateFunc notifyFunc)
+{
+#ifdef _CONTAINERIZED
+    if (!configFileUpdater)
+        WARNLOG("installConfigUpdateHook(): configuration updater not installed");
+    else
+        return configFileUpdater->addNotifyFunc(notifyFunc);
+#endif
+    return 0;
+}
 
-    Linked<IPropertyTree> config(componentDefault);
+void removeConfigUpdateHook(unsigned notifyFuncId)
+{
+#ifdef _CONTAINERIZED
+    if (!configFileUpdater)
+    {
+        WARNLOG("removeConfigUpdateHook(): configuration updater not installed");
+        return;
+    }
+    if (!configFileUpdater->removeNotifyFunc(notifyFuncId))
+        WARNLOG("removeConfigUpdateHook(): notifyFuncId %u not installed", notifyFuncId);
+#endif
+}
+#else
+unsigned installConfigUpdateHook(ConfigUpdateFunc notifyFunc)
+{
+    return 0;
+}
+
+void removeConfigUpdateHook(unsigned notifyFuncId)
+{
+}
+#endif // __linux__
+
+
+static std::tuple<std::string, IPropertyTree *, IPropertyTree *> doLoadConfiguration(IPropertyTree *componentDefault, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute)
+{
+    Owned<IPropertyTree> newComponentConfig = createPTreeFromIPT(componentDefault);
+    Owned<IPropertyTree> newGlobalConfig;
+    StringBuffer absConfigFilename;
     const char * optConfig = nullptr;
     bool outputConfig = false;
 #ifdef _DEBUG
@@ -8605,6 +8736,14 @@ jlib_decl IPropertyTree * loadConfiguration(IPropertyTree *componentDefault, con
         }
     }
 
+    const char *config = optConfig ? optConfig : legacyFilename;
+    if (!isEmptyString(config) && !isAbsolutePath(config))
+    {
+        appendCurrentDirectory(absConfigFilename, false);
+        addNonEmptyPathSepChar(absConfigFilename);
+    }
+    absConfigFilename.append(config);
+
     Owned<IPropertyTree> delta;
     if (optConfig)
     {
@@ -8614,15 +8753,8 @@ jlib_decl IPropertyTree * loadConfiguration(IPropertyTree *componentDefault, con
         //--config= with no filename can be used to ignore the legacy configuration file
         if (!isEmptyString(optConfig))
         {
-            StringBuffer fullpath;
-            if (!isAbsolutePath(optConfig))
-            {
-                appendCurrentDirectory(fullpath, false);
-                addNonEmptyPathSepChar(fullpath);
-            }
-            fullpath.append(optConfig);
-            delta.setown(loadConfiguration(fullpath, componentTag, true, altNameAttribute));
-            globalConfiguration.setown(loadConfiguration(fullpath, "global", false, altNameAttribute));
+            delta.setown(loadConfiguration(absConfigFilename, componentTag, true, altNameAttribute));
+            newGlobalConfig.setown(loadConfiguration(absConfigFilename, "global", false, altNameAttribute));
         }
     }
     else
@@ -8635,49 +8767,80 @@ jlib_decl IPropertyTree * loadConfiguration(IPropertyTree *componentDefault, con
     }
 
     if (delta)
-        mergeConfiguration(*config, *delta, altNameAttribute);
+        mergeConfiguration(*newComponentConfig, *delta, altNameAttribute);
 
     const char * * environment = const_cast<const char * *>(getSystemEnv());
     for (const char * * cur = environment; *cur; cur++)
     {
-        applyEnvironmentConfig(*config, envPrefix, *cur);
+        applyEnvironmentConfig(*newComponentConfig, envPrefix, *cur);
     }
 
     if (outputConfig)
     {
-        loadArgsIntoConfiguration(config, argv, { "config", "outputconfig" });
+        loadArgsIntoConfiguration(newComponentConfig, argv, { "config", "outputconfig" });
 
         Owned<IPropertyTree> recreated = createPTree();
         recreated->setProp("@version", currentVersion);
-        recreated->addPropTree(componentTag, LINK(config));
-        if (globalConfiguration)
-            recreated->addPropTree("global", globalConfiguration.getLink());
+        recreated->addPropTree(componentTag, LINK(newComponentConfig));
+        if (newGlobalConfig)
+            recreated->addPropTree("global", newGlobalConfig.getLink());
         StringBuffer yamlText;
         toYAML(recreated, yamlText, 0, YAML_SortTags);
         printf("%s\n", yamlText.str());
         exit(0);
     }
     else
-        loadArgsIntoConfiguration(config, argv);
+        loadArgsIntoConfiguration(newComponentConfig, argv);
 
     //For legacy (and other weird cases) ensure there is a global section
-    if (!globalConfiguration)
-        globalConfiguration.setown(createPTree("global"));
+    if (!newGlobalConfig)
+        newGlobalConfig.setown(createPTree("global"));
 
 #ifdef _DEBUG
     // NB: don't re-hold, if CLI --hold already held.
-    if (!held && config->getPropBool("@hold"))
+    if (!held && newComponentConfig->getPropBool("@hold"))
         holdLoop();
 #endif
 
-    unsigned ptreeMappingThreshold = globalConfiguration->getPropInt("@ptreeMappingThreshold", defaultSiblingMapThreshold);
+    unsigned ptreeMappingThreshold = newGlobalConfig->getPropInt("@ptreeMappingThreshold", defaultSiblingMapThreshold);
     setPTreeMappingThreshold(ptreeMappingThreshold);
 
-    componentConfiguration.set(config);
-    return config.getClear();
+    return std::make_tuple(std::string(absConfigFilename.str()), newComponentConfig.getClear(), newGlobalConfig.getClear());
+}
+
+jlib_decl IPropertyTree * loadConfiguration(IPropertyTree *componentDefault, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute, bool monitor)
+{
+    if (componentConfiguration)
+        throw makeStringExceptionV(99, "Configuration for component %s has already been initialised", componentTag);
+    auto result = doLoadConfiguration(componentDefault, argv, componentTag, envPrefix, legacyFilename, mapper, altNameAttribute);
+
+    componentConfiguration.setown(std::get<1>(result));
+    globalConfiguration.setown(std::get<2>(result));
+
+    /* In k8s, pods auto-restart by default on monitored ConfigMap settings/areas
+     * ConfigMap settings/areas deliberately not monitored will rely on this config updater mechanism,
+     * and if necessary, installed hooks that are called on an update, to perform updates of cached state.
+     * See installConfigUpdateHook()
+     * 
+     * NB: most uses of config do not rely on being notified to update state, i.e. most query the config
+     * on-demand, which means this mechanism is sufficient to cover most cases.
+     */
+
+#if defined(__linux__) && defined(_CONTAINERIZED)
+    /* In bare-metal - there is no auto process/component restart mechanism, so everything would need to be
+     * hooked to ensure state is reflected correctly. Therefore this mechanism is disabled in bare-metal for now.
+     */ 
+    if (monitor)
+    {
+        // If modern generated config, track and monitor updates
+        if (std::get<0>(result).length()) // config filename
+            configFileUpdater.setown(new CConfigUpdater(std::get<0>(result).c_str(), componentDefault, argv, componentTag, envPrefix, legacyFilename, mapper, altNameAttribute));
+    }
+#endif
+    return componentConfiguration.getLink();
 }
 
-jlib_decl IPropertyTree * loadConfiguration(const char * defaultYaml, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute)
+jlib_decl IPropertyTree * loadConfiguration(const char * defaultYaml, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute, bool monitor)
 {
     if (componentConfiguration)
         throw makeStringExceptionV(99, "Configuration for component %s has already been initialised", componentTag);
@@ -8693,7 +8856,7 @@ jlib_decl IPropertyTree * loadConfiguration(const char * defaultYaml, const char
     else
         componentDefault.setown(createPTree(componentTag));
 
-    return loadConfiguration(componentDefault, argv, componentTag, envPrefix, legacyFilename, mapper, altNameAttribute);
+    return loadConfiguration(componentDefault, argv, componentTag, envPrefix, legacyFilename, mapper, altNameAttribute, monitor);
 }
 
 class CYAMLBufferReader : public CInterfaceOf<IPTreeReader>
@@ -9246,7 +9409,22 @@ void saveYAML(IIOStream &stream, const IPropertyTree *tree, unsigned indent, uns
     toYAML(tree, stream, indent, flags);
 }
 
-jlib_decl IPropertyTree * queryCostsConfiguration()
+jlib_decl IPropertyTree * getCostsConfiguration()
 {
-    return queryComponentConfig().queryPropTree("costs");
+    return getComponentConfigSP()->getPropTree("costs");
+}
+
+void copyPropIfMissing(IPropertyTree & target, const char * targetName, IPropertyTree & source, const char * sourceName)
+{
+    if (source.hasProp(sourceName) && !target.hasProp(targetName))
+    {
+        if (source.isBinary(sourceName))
+        {
+            MemoryBuffer value;
+            source.getPropBin(sourceName, value);
+            target.setPropBin(targetName, value.length(), value.toByteArray());
+        }
+        else
+            target.setProp(targetName, source.queryProp(sourceName));
+    }
 }
diff --git a/system/jlib/jptree.hpp b/system/jlib/jptree.hpp
index 55834769d..790978deb 100644
--- a/system/jlib/jptree.hpp
+++ b/system/jlib/jptree.hpp
@@ -19,6 +19,9 @@
 #ifndef _PTREE_HPP
 #define _PTREE_HPP
 
+#include <vector>
+#include <functional>
+
 #include "jlib.hpp"
 #include "jexcept.hpp"
 #include "jiter.hpp"
@@ -306,13 +309,20 @@ inline static bool isValidXPathChr(char c)
 jlib_decl void mergeConfiguration(IPropertyTree & target, const IPropertyTree & source, const char *altNameAttribute=nullptr, bool overwriteAttr=true);
 
 jlib_decl IPropertyTree * loadArgsIntoConfiguration(IPropertyTree *config, const char * * argv, std::initializer_list<const char *> ignoreOptions = {});
-jlib_decl IPropertyTree * loadConfiguration(IPropertyTree * defaultConfig, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute=nullptr);
-jlib_decl IPropertyTree * loadConfiguration(const char * defaultYaml, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute=nullptr);
-jlib_decl IPropertyTree * queryCostsConfiguration();
+jlib_decl IPropertyTree * loadConfiguration(IPropertyTree * defaultConfig, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute=nullptr, bool monitor=true);
+jlib_decl IPropertyTree * loadConfiguration(const char * defaultYaml, const char * * argv, const char * componentTag, const char * envPrefix, const char * legacyFilename, IPropertyTree * (mapper)(IPropertyTree *), const char *altNameAttribute=nullptr, bool monitor=true);
+jlib_decl IPropertyTree * getCostsConfiguration();
 
 //The following can only be called after loadConfiguration has been called.  All components must call loadConfiguration().
-jlib_decl IPropertyTree & queryGlobalConfig();
-jlib_decl IPropertyTree & queryComponentConfig();
+jlib_decl IPropertyTree * getGlobalConfig();
+jlib_decl IPropertyTree * getComponentConfig();
+jlib_decl Owned<IPropertyTree> getGlobalConfigSP(); // get smart pointer
+jlib_decl Owned<IPropertyTree> getComponentConfigSP(); // get smart pointer
+
+// ConfigUpdateFunc calls are made in a mutex, but after new confis are swapped in
+typedef std::function<void (const IPropertyTree *oldComponentConfiguration, const IPropertyTree *oldGlobalConfiguration)> ConfigUpdateFunc;
+jlib_decl unsigned installConfigUpdateHook(ConfigUpdateFunc notifyFunc);
+jlib_decl void removeConfigUpdateHook(unsigned notifyFuncId);
 
 /*
  YAML to PTree support
@@ -365,4 +375,6 @@ jlib_decl void dbglogYAML(const IPropertyTree *tree, unsigned indent = 0, unsign
 // Defines the threshold where attribute value maps are created for sibling ptrees for fast lookups
 jlib_decl void setPTreeMappingThreshold(unsigned threshold);
 
+jlib_decl void copyPropIfMissing(IPropertyTree & target, const char * targetName, IPropertyTree & source, const char * sourceName);
+
 #endif
diff --git a/system/jlib/jregexp.cpp b/system/jlib/jregexp.cpp
index 7a488f8af..4e34cc575 100644
--- a/system/jlib/jregexp.cpp
+++ b/system/jlib/jregexp.cpp
@@ -1557,6 +1557,8 @@ bool StringMatcher::queryAddEntry(unsigned len, const char * text, unsigned acti
         entry & curElement = curTable[c];
         if (--len == 0)
         {
+            if (curElement.value == action)
+                return true;
             if (curElement.value != 0)
                 return false;
             curElement.value = action;
diff --git a/system/jlib/jscm.hpp b/system/jlib/jscm.hpp
index e212d51f0..8ecc9f2db 100644
--- a/system/jlib/jscm.hpp
+++ b/system/jlib/jscm.hpp
@@ -60,6 +60,7 @@ public:
     inline Shared(const Shared & other)          { ptr = other.getLink(); }
 #if defined(__cplusplus) && __cplusplus >= 201100
     inline Shared(Shared && other)               { ptr = other.getClear(); }
+    explicit operator bool() const               { return ptr != nullptr; }
 #endif
     inline ~Shared()                             { ::Release(ptr); }
     inline Shared<CLASS> & operator = (const Shared<CLASS> & other) { this->set(other.get()); return *this;  }
diff --git a/system/jlib/jsecrets.cpp b/system/jlib/jsecrets.cpp
index 56b66b62e..5c3ca8091 100644
--- a/system/jlib/jsecrets.cpp
+++ b/system/jlib/jsecrets.cpp
@@ -438,10 +438,10 @@ private:
 public:
     CVaultManager()
     {
-        IPropertyTree *config = nullptr;
+        Owned<const IPropertyTree> config;
         try
         {
-            config = queryComponentConfig().queryPropTree("vaults");
+            config.setown(getComponentConfigSP()->getPropTree("vaults"));
         }
         catch (IException * e)
         {
diff --git a/system/jlib/jstats.cpp b/system/jlib/jstats.cpp
index 0a99181b2..a52a3303d 100644
--- a/system/jlib/jstats.cpp
+++ b/system/jlib/jstats.cpp
@@ -410,7 +410,7 @@ public:
     std::locale * createMoneyLocale() const
     {
         StringBuffer localestr;
-        queryGlobalConfig().getProp("cost/@moneyLocale", localestr);
+        getGlobalConfigSP()->getProp("cost/@moneyLocale", localestr);
         std::locale * loc = nullptr;
         try
         {
diff --git a/system/jlib/jutil.cpp b/system/jlib/jutil.cpp
index efea99be9..bd8446ac8 100644
--- a/system/jlib/jutil.cpp
+++ b/system/jlib/jutil.cpp
@@ -3140,6 +3140,21 @@ void jlib_decl atomicWriteFile(const char *fileName, const char *output)
 
 //---------------------------------------------------------------------------------------------------------------------
 
+bool checkCreateDaemon(unsigned argc, const char * * argv)
+{
+#ifndef _CONTAINERIZED
+    for (unsigned i=0;i<(unsigned)argc;i++) {
+        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
+            if (daemon(1,0) || write_pidfile(argv[++i])) {
+                perror("Failed to daemonize");
+                return false;
+            }
+            break;
+        }
+    }
+#endif
+    return true;
+}
 
 //#define TESTURL
 #ifdef TESTURL
diff --git a/system/jlib/jutil.hpp b/system/jlib/jutil.hpp
index bf9ab7647..7eeeaef6c 100644
--- a/system/jlib/jutil.hpp
+++ b/system/jlib/jutil.hpp
@@ -622,6 +622,7 @@ struct HPCCBuildInfo
 };
 
 extern jlib_decl HPCCBuildInfo hpccBuildInfo;
+extern jlib_decl bool checkCreateDaemon(unsigned argc, const char * * argv);
 
 
 #endif
diff --git a/system/mp/mpcomm.cpp b/system/mp/mpcomm.cpp
index 81c291e88..e5db41e62 100644
--- a/system/mp/mpcomm.cpp
+++ b/system/mp/mpcomm.cpp
@@ -789,7 +789,7 @@ class CMPChannel: public CInterface
     CriticalSection attachsect;
     unsigned __int64 attachaddrval = 0;
     SocketEndpoint attachep, attachPeerEp;
-    atomic_t attachchk;
+    std::atomic<unsigned> attachchk;
 
 protected: friend class CMPServer;
     SocketEndpoint remoteep;
@@ -888,9 +888,9 @@ protected: friend class CMPPacketReader;
                     {
                         CriticalBlock block(attachsect);
 #ifdef _TRACE
-                        PROGLOG("MP: connect got attachsect, attachchk = %d, loopCnt = %u", atomic_read(&attachchk), loopCnt);
+                        PROGLOG("MP: connect got attachsect, attachchk = %d, loopCnt = %u", attachchk.load(), loopCnt);
 #endif
-                        if (atomic_read(&attachchk) > 0)
+                        if (attachchk > 0)
                         {
                             if (remoteep.equals(attachep))
                             {
@@ -1237,7 +1237,7 @@ public:
                 attachaddrval = 0;
                 attachep.set(nullptr);
                 attachPeerEp.set(nullptr);
-                atomic_set(&attachchk, 0);
+                attachchk = 0;
             }
             if (!keepsocket) {
                 try {
@@ -1684,7 +1684,7 @@ CMPChannel::CMPChannel(CMPServer *_parent,SocketEndpoint &_remoteep) : parent(_p
     localep.set(parent->getPort());
     reader = new CMPPacketReader(this);
     attachep.set(nullptr);
-    atomic_set(&attachchk, 0);
+    attachchk = 0;
     lastxfer = msTick();
 }
 
@@ -1702,7 +1702,7 @@ void CMPChannel::reset()
     attachaddrval = 0;
     attachep.set(nullptr);
     attachPeerEp.set(nullptr);
-    atomic_set(&attachchk, 0);
+    attachchk = 0;
     lastxfer = msTick();
 }
 
@@ -1718,9 +1718,9 @@ bool CMPChannel::attachSocket(ISocket *newsock,const SocketEndpoint &_remoteep,c
 {
     struct attachdTor
     {
-        atomic_t &attchk;
-        attachdTor(atomic_t &_attchk) : attchk(_attchk) { }
-        ~attachdTor() { atomic_dec(&attchk); }
+        std::atomic<unsigned> &attchk;
+        attachdTor(std::atomic<unsigned> &_attchk) : attchk(_attchk) { }
+        ~attachdTor() { --attchk; }
     } attachChk (attachchk);
 
 #ifdef _FULLTRACE       
@@ -1733,7 +1733,7 @@ bool CMPChannel::attachSocket(ISocket *newsock,const SocketEndpoint &_remoteep,c
         attachep = _remoteep;
         if (newsock)
             newsock->getPeerEndpoint(attachPeerEp);
-        atomic_inc(&attachchk);
+        ++attachchk;
     }
 
     CriticalBlock block(connectsect);
diff --git a/testing/regress/ecl/alien2.ecl b/testing/regress/ecl/alien2.ecl
index d21af29fe..43b86d436 100644
--- a/testing/regress/ecl/alien2.ecl
+++ b/testing/regress/ecl/alien2.ecl
@@ -1,6 +1,6 @@
 /*##############################################################################
 
-    HPCC SYSTEMS software Copyright (C) 2017 HPCC SystemsÂ®.
+    HPCC SYSTEMS software Copyright (C) 2021 HPCC SystemsÂ®.
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
diff --git a/testing/regress/ecl/fileposition.ecl b/testing/regress/ecl/fileposition.ecl
new file mode 100644
index 000000000..5e3d557be
--- /dev/null
+++ b/testing/regress/ecl/fileposition.ecl
@@ -0,0 +1,38 @@
+/*##############################################################################
+
+    HPCC SYSTEMS software Copyright (C) 2019 HPCC SystemsÂ®.
+
+    Licensed under the Apache License, Version 2.0 (the "License");
+    you may not use this file except in compliance with the License.
+    You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
+############################################################################## */
+
+//version multiPart=false
+//xversion multiPart=true           // cannot use this because results depend on the number of thor slaves
+//noroxie      - see HPCC-22629
+
+import ^ as root;
+multiPart := #IFDEFINED(root.multiPart, true);
+optRemoteRead := #IFDEFINED(root.optRemoteRead, false);
+
+import $.setup;
+import Std.System.ThorLib;
+Files := setup.Files(multiPart, false);
+
+// Roxie needs this to resolve files at run time
+#option ('allowVariableRoxieFilenames', 1);
+#option('forceRemoteRead', optRemoteRead);
+
+inDs := Files.seqDupFile;
+
+sequential(
+    output(inDs, { seq, filepos, unsigned part := (localfilepos - 0x8000000000000000) >> 48,  unsigned offset := (localfilepos & 0xFFFFFFFFFFFF) })
+);
diff --git a/testing/regress/ecl/key/fileposition.xml b/testing/regress/ecl/key/fileposition.xml
new file mode 100644
index 000000000..3471fb724
--- /dev/null
+++ b/testing/regress/ecl/key/fileposition.xml
@@ -0,0 +1,34 @@
+<Dataset name='Result 1'>
+ <Row><seq>1</seq><filepos>0</filepos><part>0</part><offset>0</offset></Row>
+ <Row><seq>2</seq><filepos>8</filepos><part>0</part><offset>8</offset></Row>
+ <Row><seq>3</seq><filepos>16</filepos><part>0</part><offset>16</offset></Row>
+ <Row><seq>4</seq><filepos>24</filepos><part>0</part><offset>24</offset></Row>
+ <Row><seq>5</seq><filepos>32</filepos><part>0</part><offset>32</offset></Row>
+ <Row><seq>6</seq><filepos>40</filepos><part>0</part><offset>40</offset></Row>
+ <Row><seq>7</seq><filepos>48</filepos><part>0</part><offset>48</offset></Row>
+ <Row><seq>8</seq><filepos>56</filepos><part>0</part><offset>56</offset></Row>
+ <Row><seq>9</seq><filepos>64</filepos><part>0</part><offset>64</offset></Row>
+ <Row><seq>10</seq><filepos>72</filepos><part>0</part><offset>72</offset></Row>
+ <Row><seq>11</seq><filepos>80</filepos><part>0</part><offset>80</offset></Row>
+ <Row><seq>12</seq><filepos>88</filepos><part>0</part><offset>88</offset></Row>
+ <Row><seq>13</seq><filepos>96</filepos><part>0</part><offset>96</offset></Row>
+ <Row><seq>14</seq><filepos>104</filepos><part>0</part><offset>104</offset></Row>
+ <Row><seq>15</seq><filepos>112</filepos><part>0</part><offset>112</offset></Row>
+ <Row><seq>16</seq><filepos>120</filepos><part>0</part><offset>120</offset></Row>
+ <Row><seq>1</seq><filepos>128</filepos><part>1</part><offset>0</offset></Row>
+ <Row><seq>2</seq><filepos>136</filepos><part>1</part><offset>8</offset></Row>
+ <Row><seq>3</seq><filepos>144</filepos><part>1</part><offset>16</offset></Row>
+ <Row><seq>4</seq><filepos>152</filepos><part>1</part><offset>24</offset></Row>
+ <Row><seq>5</seq><filepos>160</filepos><part>1</part><offset>32</offset></Row>
+ <Row><seq>6</seq><filepos>168</filepos><part>1</part><offset>40</offset></Row>
+ <Row><seq>7</seq><filepos>176</filepos><part>1</part><offset>48</offset></Row>
+ <Row><seq>8</seq><filepos>184</filepos><part>1</part><offset>56</offset></Row>
+ <Row><seq>9</seq><filepos>192</filepos><part>1</part><offset>64</offset></Row>
+ <Row><seq>10</seq><filepos>200</filepos><part>1</part><offset>72</offset></Row>
+ <Row><seq>11</seq><filepos>208</filepos><part>1</part><offset>80</offset></Row>
+ <Row><seq>12</seq><filepos>216</filepos><part>1</part><offset>88</offset></Row>
+ <Row><seq>13</seq><filepos>224</filepos><part>1</part><offset>96</offset></Row>
+ <Row><seq>14</seq><filepos>232</filepos><part>1</part><offset>104</offset></Row>
+ <Row><seq>15</seq><filepos>240</filepos><part>1</part><offset>112</offset></Row>
+ <Row><seq>16</seq><filepos>248</filepos><part>1</part><offset>120</offset></Row>
+</Dataset>
diff --git a/testing/regress/ecl/key/setup.xml b/testing/regress/ecl/key/setup.xml
index 82945ae49..39b0585b3 100644
--- a/testing/regress/ecl/key/setup.xml
+++ b/testing/regress/ecl/key/setup.xml
@@ -34,3 +34,5 @@
 </Dataset>
 <Dataset name='Result 18'>
 </Dataset>
+<Dataset name='Result 26'>
+</Dataset>
diff --git a/testing/regress/ecl/setup/files.ecl b/testing/regress/ecl/setup/files.ecl
index c70bc355b..7a2d55a25 100644
--- a/testing/regress/ecl/setup/files.ecl
+++ b/testing/regress/ecl/setup/files.ecl
@@ -80,6 +80,8 @@ EXPORT DG_DictFilename      := filePrefix + 'SerialLibraryDict';
 EXPORT DG_DictKeyFilename   := indexPrefix + 'SerialLibraryKeyDict';
 EXPORT DG_BookKeyFilename   := indexPrefix + 'SerialBookKey';
 
+EXPORT SEQ_Filename              := filePrefix + 'Sequence';
+
 //record structures
 EXPORT DG_FetchRecord := RECORD
   INTEGER8 sequence;
@@ -207,4 +209,14 @@ EXPORT getSearchIndex() := INDEX(TS.textSearchIndex, NameSearchIndex);
 EXPORT getSearchSuperIndex() := INDEX(TS.textSearchIndex, '{' + NameSearchIndex + ',' + NameWordIndex() + '}');
 EXPORT getSearchSource() := DATASET(NameSearchSource, TS.textSourceRecord, THOR);
 
+EXPORT SeqRecord := { unsigned seq; };
+EXPORT SeqReadRecord :=
+  RECORD(SeqRecord)
+    unsigned8 filepos{virtual(fileposition)};
+    unsigned8 localfilepos{virtual(localfileposition)};
+  END;
+
+EXPORT SeqFile := DATASET(SEQ_Filename, SeqReadRecord, THOR);
+EXPORT SeqDupFile := DATASET('{' + SEQ_Filename + ',' + SEQ_Filename + '}', SeqReadRecord, THOR);
+
 END;
diff --git a/testing/regress/ecl/setup/setup.ecl b/testing/regress/ecl/setup/setup.ecl
index 28705c8e5..c54ac6376 100644
--- a/testing/regress/ecl/setup/setup.ecl
+++ b/testing/regress/ecl/setup/setup.ecl
@@ -141,3 +141,6 @@ IF (createMultiPart,
         buildindex(LocalFiles.DG_IntIndex, overwrite,NOROOT,BLOOM(DG_parentId), PARTITION(DG_parentId));
    )
 );
+
+seqDs := DATASET(16, transform(Files.SeqRecord, self.seq := counter), DISTRIBUTED);
+OUTPUT(seqDs, , Files.Seq_Filename, OVERWRITE);
diff --git a/testing/regress/ecl/setup/thor/setup.xml b/testing/regress/ecl/setup/thor/setup.xml
index c67f46ba2..0abfeffba 100644
--- a/testing/regress/ecl/setup/thor/setup.xml
+++ b/testing/regress/ecl/setup/thor/setup.xml
@@ -48,3 +48,5 @@
 </Dataset>
 <Dataset name='Result 25'>
 </Dataset>
+<Dataset name='Result 26'>
+</Dataset>
diff --git a/thorlcr/activities/hashdistrib/thhashdistribslave.cpp b/thorlcr/activities/hashdistrib/thhashdistribslave.cpp
index eaa270823..96694a528 100644
--- a/thorlcr/activities/hashdistrib/thhashdistribslave.cpp
+++ b/thorlcr/activities/hashdistrib/thhashdistribslave.cpp
@@ -480,8 +480,8 @@ protected:
         bool senderFull, doDedup, aborted, initialized;
         Semaphore senderFullSem;
         Linked<IException> exception;
-        atomic_t numFinished;
-        atomic_t stoppedTargets;
+        std::atomic<unsigned> numFinished;
+        std::atomic<unsigned> stoppedTargets;
         unsigned dedupSamples, dedupSuccesses, self;
         Owned<IThreadPool> writerPool;
         unsigned totalActiveWriters;
@@ -492,8 +492,8 @@ protected:
         {
             totalSz = 0;
             senderFull = false;
-            atomic_set(&numFinished, 0);
-            atomic_set(&stoppedTargets, 0);
+            numFinished = 0;
+            stoppedTargets = 0;
             dedupSamples = dedupSuccesses = 0;
             doDedup = owner.doDedup;
             writerPool.setown(createThreadPool("HashDist writer pool", this, this, owner.writerPoolSize, 5*60*1000));
@@ -528,8 +528,8 @@ protected:
                 sendersFinished[dest] = false;
             totalSz = 0;
             senderFull = false;
-            atomic_set(&numFinished, 0);
-            atomic_set(&stoppedTargets, 0);
+            numFinished = 0;
+            stoppedTargets = 0;
             aborted = false;
         }
         unsigned queryInactiveWriters() const
@@ -599,7 +599,7 @@ protected:
             if (owner.sendBlock(target, msg))
                 return;
             markStopped(target); // Probably a bit pointless if target is 'self' - process loop will have done already
-            ::ActPrintLog(owner.activity, thorDetailedLogLevel, "CSender::sendBlock stopped slave %d (finished=%d)", target+1, atomic_read(&numFinished));
+            ::ActPrintLog(owner.activity, thorDetailedLogLevel, "CSender::sendBlock stopped slave %d (finished=%d)", target+1, numFinished.load());
         }
         void closeWrite()
         {
@@ -680,9 +680,9 @@ protected:
         void checkSendersFinished()
         {
             // check if any target has stopped and clear out partial now defunct buckets taking space.
-            if (atomic_read(&stoppedTargets) == 0) // cheap compared to atomic_xchg, so saves a few cycles in common case.
+            if (stoppedTargets == 0) // cheap compared to atomic_xchg, so saves a few cycles in common case.
                return;
-            int numStopped = atomic_xchg(0, &stoppedTargets);
+            int numStopped = stoppedTargets.exchange(0);
             if (numStopped)
             {
                 /* this will be infrequent, scan all.
@@ -714,7 +714,7 @@ protected:
             rowcount_t totalSent = 0;
             try
             {
-                while (!aborted && (unsigned)atomic_read(&numFinished) < owner.numnodes)
+                while (!aborted && numFinished < owner.numnodes)
                 {
                     while (queryTotalSz() >= owner.inputBufferSize)
                     {
@@ -817,7 +817,7 @@ protected:
                         for (;;)
                         {
                             if (timer.elapsedCycles() >= queryOneSecCycles()*10)
-                                owner.ActPrintLog("HD sender, waiting for space, inactive writers = %d, totalSz = %d, numFinished = %d", queryInactiveWriters(), queryTotalSz(), atomic_read(&numFinished));
+                                owner.ActPrintLog("HD sender, waiting for space, inactive writers = %d, totalSz = %d, numFinished = %d", queryInactiveWriters(), queryTotalSz(), numFinished.load());
                             timer.reset();
 
                             if (senderFullSem.wait(10000))
@@ -905,8 +905,8 @@ protected:
         {
             if (queryMarkSenderFinished(target))
             {
-                atomic_inc(&numFinished);
-                atomic_inc(&stoppedTargets);
+                ++numFinished;
+                ++stoppedTargets;
             }
         }
         void markSelfStopped() { markStopped(self); }
diff --git a/thorlcr/activities/indexwrite/thindexwrite.cpp b/thorlcr/activities/indexwrite/thindexwrite.cpp
index 0aba1bd5e..2f7ef4fbe 100644
--- a/thorlcr/activities/indexwrite/thindexwrite.cpp
+++ b/thorlcr/activities/indexwrite/thindexwrite.cpp
@@ -94,8 +94,8 @@ public:
         }
         if (idx == 0)
         {
-            const char * defaultCluster = queryDefaultStoragePlane();
-            if (defaultCluster)
+            StringBuffer defaultCluster;
+            if (getDefaultStoragePlane(defaultCluster))
                 clusters.append(defaultCluster);
         }
 
diff --git a/thorlcr/activities/keyedjoin/thkeyedjoinslave-legacy.cpp b/thorlcr/activities/keyedjoin/thkeyedjoinslave-legacy.cpp
index 50bc16552..2191e7c8e 100644
--- a/thorlcr/activities/keyedjoin/thkeyedjoinslave-legacy.cpp
+++ b/thorlcr/activities/keyedjoin/thkeyedjoinslave-legacy.cpp
@@ -97,7 +97,7 @@ interface IJoinProcessor
     virtual void onComplete(CJoinGroup * jg) = 0;
     virtual bool leftCanMatch(const void *_left) = 0;
 #ifdef TRACE_USAGE
-     virtual atomic_t &getdebug(unsigned w) = 0;
+     virtual std::atomic<unsigned> &getdebug(unsigned w) = 0;
 #endif
      virtual CActivityBase *queryOwner() = 0;
 };
@@ -173,7 +173,7 @@ public:
     CJoinGroup(CActivityBase &_activity, const void *_left, IJoinProcessor *_join, CJoinGroup *_groupStart) : activity(_activity), join(_join), rows(_activity, NULL)
     {
 #ifdef TRACE_USAGE
-        atomic_inc(&join->getdebug(0));
+        ++join->getdebug(0);
 #endif
 #ifdef TRACE_JOINGROUPS
         ActPrintLog(join->queryOwner(), "Creating joinGroup %x, groupstart %x", this, _groupStart);
@@ -201,7 +201,7 @@ public:
     {
 #ifdef TRACE_USAGE
         if (groupStart)
-            atomic_dec(&join->getdebug(0));
+            --join->getdebug(0);
 #endif
 #ifdef TRACE_JOINGROUPS
         if (groupStart)
@@ -570,7 +570,7 @@ class CKeyedJoinSlave : public CSlaveActivity, implements IJoinProcessor, implem
     MemoryBuffer rawFetchMb;
 
 #ifdef TRACE_USAGE
-    atomic_t debugats[10];
+    std::atomic<unsigned> debugats[10];
     unsigned lastTick;
 #endif
 
@@ -1670,7 +1670,7 @@ public:
 #ifdef TRACE_USAGE
         unsigned it=0;
         for (; it<10; it++)
-            atomic_set(&debugats[it],0);
+            debugats[it] = 0;
         lastTick = 0;
 #endif
         helper = (IHThorKeyedJoinArg *)queryHelper();
@@ -1703,7 +1703,7 @@ public:
     {
         StringBuffer s;
         { CriticalBlock b(onCompleteCrit);
-            s.appendf("CJoinGroups=%d, doneGroups=%d, ",atomic_read(&debugats[0]), doneGroups.ordinality());
+            s.appendf("CJoinGroups=%d, doneGroups=%d, ",debugats[0].load(), doneGroups.ordinality());
             pool->getStats(s);
         }
         ActPrintLog(s.str());
@@ -1811,7 +1811,7 @@ public:
     virtual bool leftCanMatch(const void *_left) { UNIMPLEMENTED; return false; }
 
 #ifdef TRACE_USAGE
-    virtual atomic_t &getdebug(unsigned w)
+    virtual std::atomic<unsigned> &getdebug(unsigned w)
     {
         return debugats[w];
     }
diff --git a/thorlcr/activities/lookupjoin/thlookupjoinslave.cpp b/thorlcr/activities/lookupjoin/thlookupjoinslave.cpp
index 1639383bb..86ab4552b 100644
--- a/thorlcr/activities/lookupjoin/thlookupjoinslave.cpp
+++ b/thorlcr/activities/lookupjoin/thlookupjoinslave.cpp
@@ -2237,7 +2237,7 @@ protected:
             IChannelDistributor **channelDistributors;
             unsigned nextSpillChannel;
             CriticalSection crit;
-            atomic_t spilt;
+            std::atomic<unsigned> spilt;
         public:
             CChannelDistributor(CLookupJoinActivityBase &_owner, ICompare *cmp) : owner(_owner)
             {
@@ -2247,7 +2247,7 @@ protected:
                 channelDistributors = ((CLookupJoinActivityBase *)owner.channels[0])->channelDistributors;
                 channelDistributors[owner.queryJobChannelNumber()] = this;
                 nextSpillChannel = 0;
-                atomic_set(&spilt, 0);
+                spilt = 0;
                 //NB: all channels will have done this, before rows are added
             }
 #define HPCC_17331 // Whilst under investigation. Should be solved by fix for HPCC-21091
@@ -2342,7 +2342,8 @@ protected:
         // IChannelDistributor impl.
             virtual void putRow(const void *row)
             {
-                if (atomic_cas(&spilt, 0, 1))
+                unsigned expected = 1;
+                if (spilt.compare_exchange_strong(expected, 0))
                 {
                     StringBuffer traceInfo;
                     if (channelCollector->shrink(&traceInfo)) // grab back some valuable table array space
@@ -2354,7 +2355,7 @@ protected:
             {
                 if (!channelCollector->spill(critical))
                     return false;
-                atomic_set(&spilt, 1);
+                spilt = 1;
                 return true;
             }
             virtual roxiemem::IBufferedRowCallback *queryCallback() { return this; }
diff --git a/thorlcr/activities/thdiskbase.cpp b/thorlcr/activities/thdiskbase.cpp
index 87c498fa5..91771191e 100644
--- a/thorlcr/activities/thdiskbase.cpp
+++ b/thorlcr/activities/thdiskbase.cpp
@@ -156,8 +156,8 @@ void CWriteMasterBase::init()
 
         if (idx == 0)
         {
-            const char * defaultCluster = queryDefaultStoragePlane();
-            if (defaultCluster)
+            StringBuffer defaultCluster;
+            if (getDefaultStoragePlane(defaultCluster))
                 clusters.append(defaultCluster);
         }
 
diff --git a/thorlcr/master/thdemonserver.cpp b/thorlcr/master/thdemonserver.cpp
index 30d2ea6ec..6bca88db5 100644
--- a/thorlcr/master/thdemonserver.cpp
+++ b/thorlcr/master/thdemonserver.cpp
@@ -251,7 +251,7 @@ public:
         IConstWorkUnit & wu =  graph->queryJob().queryWorkUnit();
         workunitCost = aggregateCost(&wu);
 
-        const IPropertyTree *costs = queryCostsConfiguration();
+        Owned<const IPropertyTree> costs = getCostsConfiguration();
         double softLimit = 0.0, hardLimit = 0.0;
         if (costs)
         {
diff --git a/thorlcr/master/thgraphmanager.cpp b/thorlcr/master/thgraphmanager.cpp
index 7a5df004b..28e1b82fd 100644
--- a/thorlcr/master/thgraphmanager.cpp
+++ b/thorlcr/master/thgraphmanager.cpp
@@ -59,7 +59,7 @@ class CJobManager : public CSimpleInterface, implements IJobManager, implements
     Owned<IException> exitException;
 
     Owned<IDeMonServer> demonServer;
-    atomic_t            activeTasks;
+    std::atomic<unsigned> activeTasks;
     StringAttr          currentWuid;
     ILogMsgHandler *logHandler;
 
@@ -259,7 +259,7 @@ CJobManager::CJobManager(ILogMsgHandler *_logHandler) : logHandler(_logHandler)
         demonServer.setown(createDeMonServer());
     else
         globals->setPropBool("@watchdogProgressEnabled", false);
-    atomic_set(&activeTasks, 0);
+    activeTasks = 0;
     setJobManager(this);
     debugListener.setown(new CThorDebugListener(*this));
 }
@@ -973,9 +973,9 @@ bool CJobManager::executeGraph(IConstWorkUnit &workunit, const char *graphName,
     {
         struct CounterBlock
         {
-            atomic_t &counter;
-            CounterBlock(atomic_t &_counter) : counter(_counter) { atomic_inc(&counter); }
-            ~CounterBlock() { atomic_dec(&counter); }
+            std::atomic<unsigned> &counter;
+            CounterBlock(std::atomic<unsigned> &_counter) : counter(_counter) { ++counter; }
+            ~CounterBlock() { --counter; }
         } cBlock(activeTasks);
 
         {
diff --git a/thorlcr/master/thmastermain.cpp b/thorlcr/master/thmastermain.cpp
index 8f50671f8..72adfcca0 100644
--- a/thorlcr/master/thmastermain.cpp
+++ b/thorlcr/master/thmastermain.cpp
@@ -569,17 +569,9 @@ bool ControlHandler(ahType type)
 #include "thactivitymaster.hpp"
 int main( int argc, const char *argv[]  )
 {
-#ifndef _CONTAINERIZED
-    for (unsigned i=0;i<(unsigned)argc;i++) {
-        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-            if (daemon(1,0) || write_pidfile(argv[++i])) {
-                perror("Failed to daemonize");
-                return EXIT_FAILURE;
-            }
-            break;
-        }
-    }
-#endif
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
+
 #if defined(WIN32) && defined(_DEBUG)
     int tmpFlag = _CrtSetDbgFlag( _CRTDBG_REPORT_FLAG );
     tmpFlag |= _CRTDBG_LEAK_CHECK_DF;
@@ -590,7 +582,7 @@ int main( int argc, const char *argv[]  )
     InitModuleObjects();
     NoQuickEditSection xxx;
     {
-        globals.setown(loadConfiguration(thorDefaultConfigYaml, argv, "thor", "THOR", "thor.xml", nullptr));
+        globals.setown(loadConfiguration(thorDefaultConfigYaml, argv, "thor", "THOR", "thor.xml", nullptr, nullptr, false));
     }
 #ifdef _DEBUG
     unsigned holdSlave = globals->getPropInt("@holdSlave", NotFound);
@@ -957,7 +949,7 @@ int main( int argc, const char *argv[]  )
         StringBuffer myEp;
         queryMyNode()->endpoint().getUrlStr(myEp);
 
-        applyK8sYaml("thorworker", workunit, cloudJobName, "jobspec", { { "graphName", graphName}, { "master", myEp.str() }, { "%numWorkers", std::to_string(numWorkers)} }, false);
+        applyK8sYaml("thorworker", workunit, cloudJobName, "jobspec", { { "graphName", graphName}, { "master", myEp.str() }, { "_HPCC_NUM_WORKERS_", std::to_string(numWorkers)} }, false);
 #else
         StringBuffer thorEpStr;
         LOG(MCdebugProgress, thorJob, "ThorMaster version %d.%d, Started on %s", THOR_VERSION_MAJOR,THOR_VERSION_MINOR,thorEp.getUrlStr(thorEpStr).str());
@@ -1025,7 +1017,7 @@ int main( int argc, const char *argv[]  )
                 StringBuffer uniqueGrpName;
                 queryNamedGroupStore().addUnique(&queryProcessGroup(), uniqueGrpName);
                 // change default plane
-                queryComponentConfig().setProp("storagePlane", uniqueGrpName);
+                getComponentConfigSP()->setProp("storagePlane", uniqueGrpName);
                 PROGLOG("Persistent Thor group created with group name: %s", uniqueGrpName.str());
             }
 #endif
diff --git a/thorlcr/slave/thslavemain.cpp b/thorlcr/slave/thslavemain.cpp
index 9929bc95b..70dfcc2f7 100644
--- a/thorlcr/slave/thslavemain.cpp
+++ b/thorlcr/slave/thslavemain.cpp
@@ -326,16 +326,9 @@ void setSlaveAffinity(unsigned processOnNode)
 
 int main( int argc, const char *argv[]  )
 {
-    // If using systemd, we will be using daemon code, writing own pid
-    for (unsigned i=0;i<(unsigned)argc;i++) {
-        if (streq(argv[i],"--daemon") || streq(argv[i],"-d")) {
-            if (daemon(1,0) || write_pidfile(argv[++i])) {
-                perror("Failed to daemonize");
-                return EXIT_FAILURE;
-            }
-            break;
-        }
-    }
+    if (!checkCreateDaemon(argc, argv))
+        return EXIT_FAILURE;
+
 #if defined(WIN32) && defined(_DEBUG)
     int tmpFlag = _CrtSetDbgFlag( _CRTDBG_REPORT_FLAG );
     tmpFlag |= _CRTDBG_LEAK_CHECK_DF;
@@ -370,7 +363,7 @@ int main( int argc, const char *argv[]  )
         }
         cmdArgs = argv+1;
 #ifdef _CONTAINERIZED
-        globals.setown(loadConfiguration(thorDefaultConfigYaml, argv, "thor", "THOR", nullptr, nullptr));
+        globals.setown(loadConfiguration(thorDefaultConfigYaml, argv, "thor", "THOR", nullptr, nullptr, nullptr, false));
 #else
         loadArgsIntoConfiguration(globals, cmdArgs);
 #endif
diff --git a/thorlcr/slave/traceslave.hpp b/thorlcr/slave/traceslave.hpp
index 7e9a6a5a1..95ba66a69 100644
--- a/thorlcr/slave/traceslave.hpp
+++ b/thorlcr/slave/traceslave.hpp
@@ -156,14 +156,14 @@ private:
     const unsigned traceQueueSize;
     CTraceQueue buffers[2];
     CTraceQueue rowBufferLogCache;
-    atomic_t rowBufInUse;
+    std::atomic<unsigned> rowBufInUse;
     IThorDataLink *thorDataLink;
     IEngineRowStream *inputStream;
     IHThorArg *helper;
 
     inline void enqueueRowForTrace(const void *row)
     {
-        buffers[atomic_read(&rowBufInUse)].enqueue(row, thorDataLink->queryEndCycles());
+        buffers[rowBufInUse].enqueue(row, thorDataLink->queryEndCycles());
     }
 public:
     IMPLEMENT_IINTERFACE_USING(CSimpleInterfaceOf<IEngineRowStream>);
@@ -173,7 +173,7 @@ public:
         // NOTE - cannot be called by more than one thread
         buffers[1].init(traceQueueSize+1);
         rowBufferLogCache.init(traceQueueSize);
-        int bufToDump = atomic_read(&rowBufInUse);
+        int bufToDump = rowBufInUse;
         int inactiveBuf = 1 - bufToDump;
 
         // Queue any remaining rows from inactive buffer as the oldest row is skipped
@@ -181,7 +181,7 @@ public:
         // may have been formerly an active buffer)
         buffers[inactiveBuf].queueOut(rowBufferLogCache, false);
 
-        atomic_set(&rowBufInUse, inactiveBuf);// Swap Active & inactiveBuf
+        rowBufInUse = inactiveBuf;// Swap Active & inactiveBuf
         buffers[bufToDump].queueOut(rowBufferLogCache, true);
         rowBufferLogCache.dump(mb, helper);
     }
@@ -202,7 +202,7 @@ public:
     CTracingStream(IThorDataLink *_thorDataLink, IEngineRowStream *_inputStream, IHThorArg *_helper, unsigned _traceQueueSize)
         : thorDataLink(_thorDataLink), inputStream(_inputStream), helper(_helper), traceQueueSize(_traceQueueSize)
     {
-        atomic_set(&rowBufInUse, 0);
+        rowBufInUse = 0;
         buffers[0].init(traceQueueSize+1);
     }
 };
diff --git a/version.cmake b/version.cmake
index 1616b95c6..573b781cd 100644
--- a/version.cmake
+++ b/version.cmake
@@ -4,8 +4,8 @@
 set ( HPCC_NAME "Community Edition" )
 set ( HPCC_PROJECT "community" )
 set ( HPCC_MAJOR 8 )
-set ( HPCC_MINOR 0 )
-set ( HPCC_POINT 16 )
-set ( HPCC_MATURITY "rc" )
-set ( HPCC_SEQUENCE 1 )
+set ( HPCC_MINOR 1 )
+set ( HPCC_POINT 0 )
+set ( HPCC_MATURITY "trunk" )
+set ( HPCC_SEQUENCE 0 )
 ###
